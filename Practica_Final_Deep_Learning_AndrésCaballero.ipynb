{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewsknight/DeepLearning-Models/blob/main/Practica_Final_Deep_Learning_Andr%C3%A9sCaballero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T1J130e6ZJw",
        "outputId": "abdeb5c2-c250-4c72-8640-9223bfd35fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-02-11 20:51:18--  https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\n",
            "Resolving public.opendatasoft.com (public.opendatasoft.com)... 34.249.199.226, 34.248.20.69\n",
            "Connecting to public.opendatasoft.com (public.opendatasoft.com)|34.249.199.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/csv]\n",
            "Saving to: ‘airbnb-listings.csv’\n",
            "\n",
            "airbnb-listings.csv     [   <=>              ]  54.31M  3.09MB/s    in 18s     \n",
            "\n",
            "2023-02-11 20:51:37 (2.99 MB/s) - ‘airbnb-listings.csv’ saved [56950929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O \"airbnb-listings.csv\" \"https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&disjunctive.host_verifications=true&disjunctive.amenities=true&disjunctive.features=true&refine.country=Spain&q=Madrid&timezone=Europe/London&use_labels_for_header=true&csv_separator=%3B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdW3LrqOamnI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "df = pd.read_csv('airbnb-listings.csv', sep = ';')\n",
        "pd.options.display.max_columns = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "AtNdA5gIwfMS",
        "outputId": "9be3acf8-0014-4bb5-c2ca-ebe1ef2897ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-659d2eda-432f-4e18-815b-57f6bce0c4ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>3150371</td>\n",
              "      <td>3378181</td>\n",
              "      <td>2070750</td>\n",
              "      <td>9832499</td>\n",
              "      <td>1868170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Listing Url</th>\n",
              "      <td>https://www.airbnb.com/rooms/3150371</td>\n",
              "      <td>https://www.airbnb.com/rooms/3378181</td>\n",
              "      <td>https://www.airbnb.com/rooms/2070750</td>\n",
              "      <td>https://www.airbnb.com/rooms/9832499</td>\n",
              "      <td>https://www.airbnb.com/rooms/1868170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scrape ID</th>\n",
              "      <td>20170407214119</td>\n",
              "      <td>20170407214119</td>\n",
              "      <td>20170407214119</td>\n",
              "      <td>20170407214119</td>\n",
              "      <td>20170407214119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Last Scraped</th>\n",
              "      <td>2017-04-08</td>\n",
              "      <td>2017-04-08</td>\n",
              "      <td>2017-04-08</td>\n",
              "      <td>2017-04-08</td>\n",
              "      <td>2017-04-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <td>Double room + bathroom - La Latina</td>\n",
              "      <td>Ópera/Plz Mayor -- A/C, elevator</td>\n",
              "      <td>Centric room with a balcony</td>\n",
              "      <td>PLAZA DE ESPAÑA - Único - Gimnasio.</td>\n",
              "      <td>Loft/duplex 150m2, 3 double rooms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cancellation Policy</th>\n",
              "      <td>flexible</td>\n",
              "      <td>strict</td>\n",
              "      <td>flexible</td>\n",
              "      <td>strict</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calculated host listings count</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reviews per Month</th>\n",
              "      <td>2.33</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.56</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geolocation</th>\n",
              "      <td>40.41010608050749,-3.714754034177323</td>\n",
              "      <td>40.416968822636726,-3.7094389211089993</td>\n",
              "      <td>40.40970517560235,-3.7135611928841086</td>\n",
              "      <td>40.42319271738103,-3.7112486513892</td>\n",
              "      <td>40.416513932601625,-3.7178427529546973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Features</th>\n",
              "      <td>Host Has Profile Pic,Host Identity Verified,Is...</td>\n",
              "      <td>Host Has Profile Pic,Host Identity Verified,Is...</td>\n",
              "      <td>Host Has Profile Pic,Host Identity Verified,Is...</td>\n",
              "      <td>Host Is Superhost,Host Has Profile Pic,Host Id...</td>\n",
              "      <td>Host Is Superhost,Host Has Profile Pic,Host Id...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-659d2eda-432f-4e18-815b-57f6bce0c4ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-659d2eda-432f-4e18-815b-57f6bce0c4ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-659d2eda-432f-4e18-815b-57f6bce0c4ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                0  \\\n",
              "ID                                                                        3150371   \n",
              "Listing Url                                  https://www.airbnb.com/rooms/3150371   \n",
              "Scrape ID                                                          20170407214119   \n",
              "Last Scraped                                                           2017-04-08   \n",
              "Name                                           Double room + bathroom - La Latina   \n",
              "...                                                                           ...   \n",
              "Cancellation Policy                                                      flexible   \n",
              "Calculated host listings count                                                  1   \n",
              "Reviews per Month                                                            2.33   \n",
              "Geolocation                                  40.41010608050749,-3.714754034177323   \n",
              "Features                        Host Has Profile Pic,Host Identity Verified,Is...   \n",
              "\n",
              "                                                                                1  \\\n",
              "ID                                                                        3378181   \n",
              "Listing Url                                  https://www.airbnb.com/rooms/3378181   \n",
              "Scrape ID                                                          20170407214119   \n",
              "Last Scraped                                                           2017-04-08   \n",
              "Name                                             Ópera/Plz Mayor -- A/C, elevator   \n",
              "...                                                                           ...   \n",
              "Cancellation Policy                                                        strict   \n",
              "Calculated host listings count                                                  2   \n",
              "Reviews per Month                                                            2.69   \n",
              "Geolocation                                40.416968822636726,-3.7094389211089993   \n",
              "Features                        Host Has Profile Pic,Host Identity Verified,Is...   \n",
              "\n",
              "                                                                                2  \\\n",
              "ID                                                                        2070750   \n",
              "Listing Url                                  https://www.airbnb.com/rooms/2070750   \n",
              "Scrape ID                                                          20170407214119   \n",
              "Last Scraped                                                           2017-04-08   \n",
              "Name                                                  Centric room with a balcony   \n",
              "...                                                                           ...   \n",
              "Cancellation Policy                                                      flexible   \n",
              "Calculated host listings count                                                  4   \n",
              "Reviews per Month                                                             0.6   \n",
              "Geolocation                                 40.40970517560235,-3.7135611928841086   \n",
              "Features                        Host Has Profile Pic,Host Identity Verified,Is...   \n",
              "\n",
              "                                                                                3  \\\n",
              "ID                                                                        9832499   \n",
              "Listing Url                                  https://www.airbnb.com/rooms/9832499   \n",
              "Scrape ID                                                          20170407214119   \n",
              "Last Scraped                                                           2017-04-08   \n",
              "Name                                          PLAZA DE ESPAÑA - Único - Gimnasio.   \n",
              "...                                                                           ...   \n",
              "Cancellation Policy                                                        strict   \n",
              "Calculated host listings count                                                  9   \n",
              "Reviews per Month                                                            3.56   \n",
              "Geolocation                                    40.42319271738103,-3.7112486513892   \n",
              "Features                        Host Is Superhost,Host Has Profile Pic,Host Id...   \n",
              "\n",
              "                                                                                4  \n",
              "ID                                                                        1868170  \n",
              "Listing Url                                  https://www.airbnb.com/rooms/1868170  \n",
              "Scrape ID                                                          20170407214119  \n",
              "Last Scraped                                                           2017-04-08  \n",
              "Name                                            Loft/duplex 150m2, 3 double rooms  \n",
              "...                                                                           ...  \n",
              "Cancellation Policy                                                      moderate  \n",
              "Calculated host listings count                                                  1  \n",
              "Reviews per Month                                                            1.13  \n",
              "Geolocation                                40.416513932601625,-3.7178427529546973  \n",
              "Features                        Host Is Superhost,Host Has Profile Pic,Host Id...  \n",
              "\n",
              "[89 rows x 5 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1ZsV2It61Ou"
      },
      "outputs": [],
      "source": [
        "#Creo una copiar que necesitaré mas adelante para cargar las imágenes.\n",
        "df_img = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7xG4To6dNZ",
        "outputId": "9fdecd07-0220-4195-ca5d-fcb7490d4ed9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14001, 89)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vamos a ver de cuantos registros disponemos y de cuantas variables\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hN9luI06kqv"
      },
      "source": [
        "**Análisis exploratorio y limpieza del dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqpT_DTW86Gy"
      },
      "outputs": [],
      "source": [
        "#Creo una lista con las columnas que a simple vista o indagando un poco , apenas influyen en el modelo\n",
        "\n",
        "drop_columns = [\n",
        "    'ID', 'Listing Url', 'Scrape ID', 'Last Scraped', 'Thumbnail Url', 'Medium Url',\n",
        "    'Picture Url', 'XL Picture Url', 'Host ID', 'Host URL', 'Host Name',\n",
        "    'Host Thumbnail Url', 'Host Picture Url', 'Host Neighbourhood', 'Weekly Price',\n",
        "    'Monthly Price', 'Calendar Updated', 'Calendar last Scraped', 'First Review',\n",
        "    'Last Review', 'Reviews per Month', 'Geolocation', 'Calculated host listings count',\n",
        "    'Host Listings Count', 'Host Total Listings Count', 'Street', 'State', 'Market', 'Smart Location',\n",
        "    'Country', 'Zipcode', 'City', 'Country Code', 'Experiences Offered','Name', 'Summary', 'Space', 'Description',\n",
        "    'Neighborhood Overview', 'Notes', 'Transit', 'Access', 'Interaction', 'House Rules','Host Location', 'Host About'\n",
        "]\n",
        "\n",
        "df.drop(drop_columns, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyL-EpujEaHD"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Borramos columnas con muchos NA's\n",
        "\n",
        "na_columns = [\n",
        "    'Host Acceptance Rate', 'Square Feet', 'Has Availability', 'License', 'Jurisdiction Names'\n",
        "]\n",
        "\n",
        "df.drop(na_columns, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#Al correlacionarse tanto las variables de availability y reviews, dejamos solo la de availability 365\n",
        "#hacemos una media con todas las columnas de Review y las guardamos en la columna 'Average Review'.\n",
        "\n",
        "reviews = df.loc[: , \"Review Scores Rating\":\"Review Scores Value\"]\n",
        "df['Average Review'] = reviews.mean(axis=1)\n",
        "\n",
        "df.drop(['Availability 30', 'Availability 60', 'Availability 90', 'Review Scores Rating',\n",
        "         'Review Scores Accuracy', 'Review Scores Cleanliness', 'Review Scores Checkin',\n",
        "       'Review Scores Communication', 'Review Scores Location', 'Review Scores Value',\n",
        "        'Accommodates'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#Solo nos quedamos con los precios inferiores a 200 para evitar sobreajustes en el modelo\n",
        "df = df[df['Price'] < 200]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAFRHNMgEmeT"
      },
      "source": [
        "**GENERACIÓN DE CARACTERÍSTICAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl5gdM7rEjV9"
      },
      "outputs": [],
      "source": [
        "\n",
        "#creamos un subconjunto visto que las columnas de barrios, la primera son más específicos y la segundo menos y la última menos.\n",
        "#Rellenamos los valores con NA de la columna 'Neighbourhood Group Cleansed' con los de la columna 'Neighbourhood Cleansed'\n",
        "#que no tiene NA's, y nos creamos una sola columna ( \"Final Neighbourhood\") en representación de las 3·\n",
        "\n",
        "df[\"Final Neighbourhood\"] = df[\"Neighbourhood Group Cleansed\"].fillna(df[\"Neighbourhood Cleansed\"])\n",
        "df.drop([\"Neighbourhood\", \"Neighbourhood Group Cleansed\", \"Neighbourhood Cleansed\"], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Rellenamos con cadenas vacías los NA de las tres columnas('Features','Amenities', 'Host Verifications' ), para codificar correctamente las categóricas.\n",
        "# Contamos el numero de elementos de cada columna, y lo usamos como caraterística sustituyendo\n",
        "# los elementos por su longitud. Vemos que hay buena relación entre el numero de elementos y el precio.\n",
        "\n",
        "\n",
        "df['Features'].fillna(\"\", inplace=True)\n",
        "df['Amenities'].fillna(\"\", inplace=True)\n",
        "df['Host Verifications'].fillna(\"\", inplace=True)\n",
        "\n",
        "df['Features'] = df['Features'].apply(lambda x: len(str(x).split(',')))\n",
        "df['Amenities'] = df['Amenities'].apply(lambda x: len(str(x).split(',')))\n",
        "df['Host Verifications'] = df['Host Verifications'].apply(lambda x: len(str(x).split(',')))\n",
        "\n",
        "# Antiguedad del dueño\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "df.dropna(subset=['Host Since'], inplace=True) # se ha visto antes que solo hay tres valores missing, los borramos.\n",
        "\n",
        "# En vez de la fecha nos quedamos con la antigueda que lleva el dueño en la plataforma.\n",
        "\n",
        "\n",
        "#Convertimos a un formato horario manejable\n",
        "df['Host Since'] = df['Host Since'].apply(lambda x: datetime.strptime(str(x),'%Y-%m-%d'))\n",
        "\n",
        "#Restamos la fecha actual menos la del dataframe y nos quedamos con los años.\n",
        "df['Years Being Host'] = df['Host Since'].apply(lambda x: 2023 - x.year)\n",
        "\n",
        "#Borramos esta columna que ya no nos sirve\n",
        "df.drop(['Host Since'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydGi0z7IE-9A"
      },
      "source": [
        "**CATEGORIZACIÓN DE VARIABLES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAjgbztvE1Ef",
        "outputId": "41f93392-5d20-4de7-c97a-f77072366e67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Price                  False\n",
              "Host Response Time     False\n",
              "Host Response Rate     False\n",
              "Host Verifications     False\n",
              "Latitude               False\n",
              "Longitude              False\n",
              "Property Type          False\n",
              "Room Type              False\n",
              "Bathrooms              False\n",
              "Bedrooms               False\n",
              "Beds                   False\n",
              "Bed Type               False\n",
              "Amenities              False\n",
              "Security Deposit       False\n",
              "Cleaning Fee           False\n",
              "Guests Included        False\n",
              "Extra People           False\n",
              "Minimum Nights         False\n",
              "Maximum Nights         False\n",
              "Availability 365       False\n",
              "Number of Reviews      False\n",
              "Cancellation Policy    False\n",
              "Features               False\n",
              "Average Review         False\n",
              "Final Neighbourhood    False\n",
              "Years Being Host       False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "#Nos quedamos con aquellos elementos distintos de 0.\n",
        "\n",
        "df = df[df['Bathrooms'] != 0]\n",
        "df = df[df['Price'] != 0]\n",
        "df[\"Host Response Time\"].fillna(df[\"Host Response Time\"].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "# Codificamos las categóricas que nos quedan creando un labelEncoder para cada una, y sustituimos los valores.\n",
        "\n",
        "\n",
        "Host_Response_Time_le = LabelEncoder()\n",
        "Property_Type_le = LabelEncoder()\n",
        "Room_Type_le = LabelEncoder()\n",
        "Bed_Type_le = LabelEncoder()\n",
        "Cancellation_Policy_le = LabelEncoder()\n",
        "Final_Neighbourhood_le = LabelEncoder()\n",
        "\n",
        "\n",
        "df['Host Response Time'] = Host_Response_Time_le.fit_transform(df['Host Response Time'] )\n",
        "df['Property Type'] = Property_Type_le.fit_transform(df['Property Type'] )\n",
        "df['Room Type'] = Room_Type_le.fit_transform(df['Room Type'])\n",
        "df['Bed Type'] = Bed_Type_le.fit_transform(df['Bed Type'])\n",
        "df['Cancellation Policy'] = Cancellation_Policy_le.fit_transform(df['Cancellation Policy'] )\n",
        "df['Final Neighbourhood'] = Final_Neighbourhood_le.fit_transform(df['Final Neighbourhood'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Esto solo sirve para mover price a la primera posición\n",
        "cols = df.columns.tolist()\n",
        "cols.insert(0, cols.pop(cols.index('Price')))\n",
        "df = df[cols]\n",
        "\n",
        "#Sustituimos los Nas que queden por la media.\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch0e_hgOJ0jg",
        "outputId": "6f3b4825-2f0f-4404-d187-72970ac08a61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13332, 26)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Onhk5KRCvJ"
      },
      "outputs": [],
      "source": [
        "#Filtro una copia del dataframe original por los entradas del dataframe limpio para añadir las URLs de las imágenes a cada entrada la suya.\n",
        "\n",
        "df_filtered = df_img.loc[df_img.index.isin(df.index)]\n",
        "df_final = pd.concat([df, df_filtered['Thumbnail Url']], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CJ92cKy3Wb5O",
        "outputId": "e77ec1cb-3037-49ba-efd7-64fd5848785f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8625381d-ebd4-4e60-ae83-f0ad1185f69e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <td>36.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Host Response Time</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Host Response Rate</th>\n",
              "      <td>100.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Host Verifications</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latitude</th>\n",
              "      <td>40.410106</td>\n",
              "      <td>40.416969</td>\n",
              "      <td>40.409705</td>\n",
              "      <td>40.423193</td>\n",
              "      <td>40.416514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Longitude</th>\n",
              "      <td>-3.714754</td>\n",
              "      <td>-3.709439</td>\n",
              "      <td>-3.713561</td>\n",
              "      <td>-3.711249</td>\n",
              "      <td>-3.717843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Property Type</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Room Type</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bathrooms</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bedrooms</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beds</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bed Type</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amenities</th>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Security Deposit</th>\n",
              "      <td>179.02537</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cleaning Fee</th>\n",
              "      <td>28.134873</td>\n",
              "      <td>30.0</td>\n",
              "      <td>28.134873</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Guests Included</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra People</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minimum Nights</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maximum Nights</th>\n",
              "      <td>1125</td>\n",
              "      <td>1125</td>\n",
              "      <td>1125</td>\n",
              "      <td>1900</td>\n",
              "      <td>1125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Availability 365</th>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "      <td>158</td>\n",
              "      <td>248</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of Reviews</th>\n",
              "      <td>80</td>\n",
              "      <td>90</td>\n",
              "      <td>20</td>\n",
              "      <td>55</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cancellation Policy</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Features</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average Review</th>\n",
              "      <td>22.571429</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.857143</td>\n",
              "      <td>22.714286</td>\n",
              "      <td>22.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Final Neighbourhood</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Years Being Host</th>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thumbnail Url</th>\n",
              "      <td>https://a0.muscache.com/im/pictures/40713802/3...</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/44239584/c...</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/84378550/f...</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/be441d1f-4...</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/c232f016-f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8625381d-ebd4-4e60-ae83-f0ad1185f69e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8625381d-ebd4-4e60-ae83-f0ad1185f69e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8625381d-ebd4-4e60-ae83-f0ad1185f69e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                     0  \\\n",
              "Price                                                             36.0   \n",
              "Host Response Time                                                   1   \n",
              "Host Response Rate                                               100.0   \n",
              "Host Verifications                                                   4   \n",
              "Latitude                                                     40.410106   \n",
              "Longitude                                                    -3.714754   \n",
              "Property Type                                                        0   \n",
              "Room Type                                                            1   \n",
              "Bathrooms                                                          1.0   \n",
              "Bedrooms                                                           1.0   \n",
              "Beds                                                               1.0   \n",
              "Bed Type                                                             4   \n",
              "Amenities                                                           13   \n",
              "Security Deposit                                             179.02537   \n",
              "Cleaning Fee                                                 28.134873   \n",
              "Guests Included                                                      1   \n",
              "Extra People                                                         0   \n",
              "Minimum Nights                                                       2   \n",
              "Maximum Nights                                                    1125   \n",
              "Availability 365                                                     1   \n",
              "Number of Reviews                                                   80   \n",
              "Cancellation Policy                                                  0   \n",
              "Features                                                             4   \n",
              "Average Review                                               22.571429   \n",
              "Final Neighbourhood                                                 14   \n",
              "Years Being Host                                                     9   \n",
              "Thumbnail Url        https://a0.muscache.com/im/pictures/40713802/3...   \n",
              "\n",
              "                                                                     1  \\\n",
              "Price                                                             85.0   \n",
              "Host Response Time                                                   1   \n",
              "Host Response Rate                                                94.0   \n",
              "Host Verifications                                                   6   \n",
              "Latitude                                                     40.416969   \n",
              "Longitude                                                    -3.709439   \n",
              "Property Type                                                        0   \n",
              "Room Type                                                            0   \n",
              "Bathrooms                                                          1.0   \n",
              "Bedrooms                                                           1.0   \n",
              "Beds                                                               1.0   \n",
              "Bed Type                                                             4   \n",
              "Amenities                                                           16   \n",
              "Security Deposit                                                 100.0   \n",
              "Cleaning Fee                                                      30.0   \n",
              "Guests Included                                                      1   \n",
              "Extra People                                                         0   \n",
              "Minimum Nights                                                       3   \n",
              "Maximum Nights                                                    1125   \n",
              "Availability 365                                                   320   \n",
              "Number of Reviews                                                   90   \n",
              "Cancellation Policy                                                  2   \n",
              "Features                                                             5   \n",
              "Average Review                                                    22.0   \n",
              "Final Neighbourhood                                                 14   \n",
              "Years Being Host                                                    12   \n",
              "Thumbnail Url        https://a0.muscache.com/im/pictures/44239584/c...   \n",
              "\n",
              "                                                                     2  \\\n",
              "Price                                                             20.0   \n",
              "Host Response Time                                                   1   \n",
              "Host Response Rate                                                80.0   \n",
              "Host Verifications                                                   4   \n",
              "Latitude                                                     40.409705   \n",
              "Longitude                                                    -3.713561   \n",
              "Property Type                                                        0   \n",
              "Room Type                                                            1   \n",
              "Bathrooms                                                          1.0   \n",
              "Bedrooms                                                           1.0   \n",
              "Beds                                                               1.0   \n",
              "Bed Type                                                             4   \n",
              "Amenities                                                            6   \n",
              "Security Deposit                                                 100.0   \n",
              "Cleaning Fee                                                 28.134873   \n",
              "Guests Included                                                      1   \n",
              "Extra People                                                        10   \n",
              "Minimum Nights                                                       3   \n",
              "Maximum Nights                                                    1125   \n",
              "Availability 365                                                   158   \n",
              "Number of Reviews                                                   20   \n",
              "Cancellation Policy                                                  0   \n",
              "Features                                                             4   \n",
              "Average Review                                               20.857143   \n",
              "Final Neighbourhood                                                 14   \n",
              "Years Being Host                                                    10   \n",
              "Thumbnail Url        https://a0.muscache.com/im/pictures/84378550/f...   \n",
              "\n",
              "                                                                     3  \\\n",
              "Price                                                            112.0   \n",
              "Host Response Time                                                   3   \n",
              "Host Response Rate                                               100.0   \n",
              "Host Verifications                                                   6   \n",
              "Latitude                                                     40.423193   \n",
              "Longitude                                                    -3.711249   \n",
              "Property Type                                                        0   \n",
              "Room Type                                                            0   \n",
              "Bathrooms                                                          1.0   \n",
              "Bedrooms                                                           1.0   \n",
              "Beds                                                               2.0   \n",
              "Bed Type                                                             4   \n",
              "Amenities                                                           23   \n",
              "Security Deposit                                                 250.0   \n",
              "Cleaning Fee                                                      15.0   \n",
              "Guests Included                                                      2   \n",
              "Extra People                                                         5   \n",
              "Minimum Nights                                                       3   \n",
              "Maximum Nights                                                    1900   \n",
              "Availability 365                                                   248   \n",
              "Number of Reviews                                                   55   \n",
              "Cancellation Policy                                                  2   \n",
              "Features                                                             5   \n",
              "Average Review                                               22.714286   \n",
              "Final Neighbourhood                                                 14   \n",
              "Years Being Host                                                    11   \n",
              "Thumbnail Url        https://a0.muscache.com/im/pictures/be441d1f-4...   \n",
              "\n",
              "                                                                     4  \n",
              "Price                                                            190.0  \n",
              "Host Response Time                                                   2  \n",
              "Host Response Rate                                               100.0  \n",
              "Host Verifications                                                   4  \n",
              "Latitude                                                     40.416514  \n",
              "Longitude                                                    -3.717843  \n",
              "Property Type                                                        0  \n",
              "Room Type                                                            0  \n",
              "Bathrooms                                                          3.0  \n",
              "Bedrooms                                                           3.0  \n",
              "Beds                                                               4.0  \n",
              "Bed Type                                                             4  \n",
              "Amenities                                                           19  \n",
              "Security Deposit                                                 200.0  \n",
              "Cleaning Fee                                                      20.0  \n",
              "Guests Included                                                      6  \n",
              "Extra People                                                        40  \n",
              "Minimum Nights                                                       3  \n",
              "Maximum Nights                                                    1125  \n",
              "Availability 365                                                   296  \n",
              "Number of Reviews                                                   46  \n",
              "Cancellation Policy                                                  1  \n",
              "Features                                                             5  \n",
              "Average Review                                               22.142857  \n",
              "Final Neighbourhood                                                 14  \n",
              "Years Being Host                                                    10  \n",
              "Thumbnail Url        https://a0.muscache.com/im/pictures/c232f016-f...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiYpyHivgcur"
      },
      "outputs": [],
      "source": [
        "\n",
        "import imageio as io\n",
        "import numpy as np\n",
        "import cv2\n",
        "n_images = 1500\n",
        "images = np.zeros((n_images, 224, 224, 3), dtype=np.uint8)\n",
        "urls = df_final['Thumbnail Url']\n",
        "\n",
        "i_aux = 0\n",
        "good_urls = []\n",
        "images_train = []\n",
        "for i_img, url in enumerate(urls):\n",
        "    if len(good_urls) >= n_images:\n",
        "        # ya tenemos n_images imágenes\n",
        "        break\n",
        "    try:\n",
        "        img = io.imread(url)\n",
        "        images_aux = cv2.resize(img, (224, 224))\n",
        "        if images_aux.shape == (224, 224, 3):\n",
        "            images[i_aux] = images_aux\n",
        "            good_urls.append(i_img)\n",
        "            i_aux += 1\n",
        "            print(f'Imagen {i_img} descargada')\n",
        "            print(len(good_urls))\n",
        "        else:\n",
        "          pass\n",
        "    except IOError as err:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTjklg7eLdOX",
        "outputId": "e7dbb4ba-a612-4196-b1fc-25d2f2979153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# Visualizamos las imágenes cargadas\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEipdb88Lg_g"
      },
      "outputs": [],
      "source": [
        "# Mantenemos los datos numéricos solo para aquellos pisos que tienen imágenes\n",
        "# y las hemos obtenido\n",
        "final_data = df_final.iloc[good_urls, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NyPSLMjLjC_",
        "outputId": "3217ba87-7495-4a96-8e0f-56af8f874d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1500, 27)\n"
          ]
        }
      ],
      "source": [
        "print(final_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNhV1sC5d5EP",
        "outputId": "d0284663-dbff-4f01-f320-30bb9f262dbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Price', 'Host Response Time', 'Host Response Rate',\n",
              "       'Host Verifications', 'Latitude', 'Longitude', 'Property Type',\n",
              "       'Room Type', 'Bathrooms', 'Bedrooms', 'Beds', 'Bed Type', 'Amenities',\n",
              "       'Security Deposit', 'Cleaning Fee', 'Guests Included', 'Extra People',\n",
              "       'Minimum Nights', 'Maximum Nights', 'Availability 365',\n",
              "       'Number of Reviews', 'Cancellation Policy', 'Features',\n",
              "       'Average Review', 'Final Neighbourhood', 'Years Being Host',\n",
              "       'Thumbnail Url'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU71yeZLLmmh"
      },
      "outputs": [],
      "source": [
        "# guardamos las imágenes\n",
        "np.save('images_copia2.npy', images)\n",
        "np.save('final_data_copia2.npy', final_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_S8KmXvLyRI",
        "outputId": "ae3260ca-7af8-438f-8117-b533c253db72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " #montamos GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taYibubgL5tc"
      },
      "outputs": [],
      "source": [
        "# almacenamos las imagenes en nuestro drive\n",
        "!cp images_copia2.npy /content/drive/My\\ Drive/images_copia2.npy\n",
        "!cp final_data_copia2.npy /content/drive/My\\ Drive/final_data_copia2.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2J_ex0MGlK"
      },
      "source": [
        "**COMENZAMOS CON LA CARGA DE DATOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J6LDrACHMGe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "images = np.load('/content/drive/My Drive/images_copia2.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv9mFS3a0zf5"
      },
      "outputs": [],
      "source": [
        "#Creamos una semilla para que los pesos se inicializen igual\n",
        "np.random.seed(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfK5WMNVHgv8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = np.load('/content/drive/My Drive/final_data_copia2.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHjlyIcedlGk"
      },
      "outputs": [],
      "source": [
        "#Convierto en dataframe el numpy array que me carga del drive\n",
        "\n",
        "data = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csAD0mbedzDf"
      },
      "outputs": [],
      "source": [
        "#Les añado el nombre a las columnas que se quedaban numeradas.\n",
        "\n",
        "data.columns = ['Price', 'Host Response Time', 'Host Response Rate',\n",
        "       'Host Verifications', 'Latitude', 'Longitude', 'Property Type',\n",
        "       'Room Type', 'Bathrooms', 'Bedrooms', 'Beds', 'Bed Type', 'Amenities',\n",
        "       'Security Deposit', 'Cleaning Fee', 'Guests Included', 'Extra People',\n",
        "       'Minimum Nights', 'Maximum Nights', 'Availability 365',\n",
        "       'Number of Reviews', 'Cancellation Policy', 'Features',\n",
        "       'Average Review', 'Final Neighbourhood', 'Years Being Host',\n",
        "       'Thumbnail Url']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP68DLnYqU3w"
      },
      "outputs": [],
      "source": [
        "#Creo una copia para sacar luego los valores de y_train de Price\n",
        "\n",
        "final_data = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Qc2TZhvVaUIW",
        "outputId": "0bb48098-d3ac-4da5-d4e2-0064da57b8d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0c42e914-ae58-4db7-bf8e-699b8d747f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Host Response Time</th>\n",
              "      <th>Host Response Rate</th>\n",
              "      <th>Host Verifications</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Property Type</th>\n",
              "      <th>Room Type</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>...</th>\n",
              "      <th>Minimum Nights</th>\n",
              "      <th>Maximum Nights</th>\n",
              "      <th>Availability 365</th>\n",
              "      <th>Number of Reviews</th>\n",
              "      <th>Cancellation Policy</th>\n",
              "      <th>Features</th>\n",
              "      <th>Average Review</th>\n",
              "      <th>Final Neighbourhood</th>\n",
              "      <th>Years Being Host</th>\n",
              "      <th>Thumbnail Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36.0</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.410106</td>\n",
              "      <td>-3.714754</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1125</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>22.571429</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/40713802/3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.0</td>\n",
              "      <td>1</td>\n",
              "      <td>94.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40.416969</td>\n",
              "      <td>-3.709439</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1125</td>\n",
              "      <td>320</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/44239584/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.409705</td>\n",
              "      <td>-3.713561</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1125</td>\n",
              "      <td>158</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>20.857143</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/84378550/f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112.0</td>\n",
              "      <td>3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6</td>\n",
              "      <td>40.423193</td>\n",
              "      <td>-3.711249</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1900</td>\n",
              "      <td>248</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>22.714286</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/be441d1f-4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>190.0</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.416514</td>\n",
              "      <td>-3.717843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1125</td>\n",
              "      <td>296</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>22.142857</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/c232f016-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>22.0</td>\n",
              "      <td>3</td>\n",
              "      <td>94.933197</td>\n",
              "      <td>3</td>\n",
              "      <td>40.425122</td>\n",
              "      <td>-3.671283</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1125</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/b9ae9002-6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>80.0</td>\n",
              "      <td>3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7</td>\n",
              "      <td>40.424136</td>\n",
              "      <td>-3.677756</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1125</td>\n",
              "      <td>58</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>22.0</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/106152818/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>125.0</td>\n",
              "      <td>1</td>\n",
              "      <td>83.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.425892</td>\n",
              "      <td>-3.679415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>364</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>21.243647</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/4fb56b8a-2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>82.0</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5</td>\n",
              "      <td>40.424069</td>\n",
              "      <td>-3.669475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1125</td>\n",
              "      <td>32</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>22.714286</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/022ad19c-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>75.0</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3</td>\n",
              "      <td>40.424285</td>\n",
              "      <td>-3.665397</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1125</td>\n",
              "      <td>329</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>20.571429</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>https://a0.muscache.com/im/pictures/33310153/4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c42e914-ae58-4db7-bf8e-699b8d747f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c42e914-ae58-4db7-bf8e-699b8d747f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c42e914-ae58-4db7-bf8e-699b8d747f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Price Host Response Time Host Response Rate Host Verifications  \\\n",
              "0      36.0                  1              100.0                  4   \n",
              "1      85.0                  1               94.0                  6   \n",
              "2      20.0                  1               80.0                  4   \n",
              "3     112.0                  3              100.0                  6   \n",
              "4     190.0                  2              100.0                  4   \n",
              "...     ...                ...                ...                ...   \n",
              "1495   22.0                  3          94.933197                  3   \n",
              "1496   80.0                  3              100.0                  7   \n",
              "1497  125.0                  1               83.0                  4   \n",
              "1498   82.0                  2              100.0                  5   \n",
              "1499   75.0                  2              100.0                  3   \n",
              "\n",
              "       Latitude Longitude Property Type Room Type Bathrooms Bedrooms  ...  \\\n",
              "0     40.410106 -3.714754             0         1       1.0      1.0  ...   \n",
              "1     40.416969 -3.709439             0         0       1.0      1.0  ...   \n",
              "2     40.409705 -3.713561             0         1       1.0      1.0  ...   \n",
              "3     40.423193 -3.711249             0         0       1.0      1.0  ...   \n",
              "4     40.416514 -3.717843             0         0       3.0      3.0  ...   \n",
              "...         ...       ...           ...       ...       ...      ...  ...   \n",
              "1495  40.425122 -3.671283             0         1       1.0      1.0  ...   \n",
              "1496  40.424136 -3.677756             0         0       1.0      2.0  ...   \n",
              "1497  40.425892 -3.679415             0         1       1.5      1.0  ...   \n",
              "1498  40.424069 -3.669475             0         0       2.0      2.0  ...   \n",
              "1499  40.424285 -3.665397             0         0       2.0      1.0  ...   \n",
              "\n",
              "     Minimum Nights Maximum Nights Availability 365 Number of Reviews  \\\n",
              "0                 2           1125                1                80   \n",
              "1                 3           1125              320                90   \n",
              "2                 3           1125              158                20   \n",
              "3                 3           1900              248                55   \n",
              "4                 3           1125              296                46   \n",
              "...             ...            ...              ...               ...   \n",
              "1495              1           1125                0                 8   \n",
              "1496              2           1125               58                64   \n",
              "1497              2             10              364                 0   \n",
              "1498              3           1125               32                19   \n",
              "1499              3           1125              329                48   \n",
              "\n",
              "     Cancellation Policy Features Average Review Final Neighbourhood  \\\n",
              "0                      0        4      22.571429                  14   \n",
              "1                      2        5           22.0                  14   \n",
              "2                      0        4      20.857143                  14   \n",
              "3                      2        5      22.714286                  14   \n",
              "4                      1        5      22.142857                  14   \n",
              "...                  ...      ...            ...                 ...   \n",
              "1495                   0        3           20.0                  45   \n",
              "1496                   1        5           22.0                  45   \n",
              "1497                   0        3      21.243647                  45   \n",
              "1498                   0        5      22.714286                  45   \n",
              "1499                   1        3      20.571429                  45   \n",
              "\n",
              "     Years Being Host                                      Thumbnail Url  \n",
              "0                   9  https://a0.muscache.com/im/pictures/40713802/3...  \n",
              "1                  12  https://a0.muscache.com/im/pictures/44239584/c...  \n",
              "2                  10  https://a0.muscache.com/im/pictures/84378550/f...  \n",
              "3                  11  https://a0.muscache.com/im/pictures/be441d1f-4...  \n",
              "4                  10  https://a0.muscache.com/im/pictures/c232f016-f...  \n",
              "...               ...                                                ...  \n",
              "1495                8  https://a0.muscache.com/im/pictures/b9ae9002-6...  \n",
              "1496                9  https://a0.muscache.com/im/pictures/106152818/...  \n",
              "1497                8  https://a0.muscache.com/im/pictures/4fb56b8a-2...  \n",
              "1498                8  https://a0.muscache.com/im/pictures/022ad19c-0...  \n",
              "1499                9  https://a0.muscache.com/im/pictures/33310153/4...  \n",
              "\n",
              "[1500 rows x 27 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMg3ujukdRGZ"
      },
      "outputs": [],
      "source": [
        "#Borro las urls que ya no nos aportan más al modelo y Price, que cargaremos después de la copia \"final_data\".\n",
        "\n",
        "data.drop(['Thumbnail Url', 'Price'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrRflZIdchqM"
      },
      "outputs": [],
      "source": [
        "# Normalizamos datos y etiquetas (en esta ocasión las etiquetas son los precios\n",
        "# y vamos a normalizarlos también entre 0 y 1)\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Normalizamos los datos\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
        "data_norm = min_max_scaler.fit_transform(data)\n",
        "\n",
        "\n",
        "y_reg = final_data['Price']\n",
        "\n",
        "y_reg_norm = y_reg /y_reg.max()\n",
        "\n",
        "\n",
        "# Split de los datos de train y validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_norm, y_reg_norm.values, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4mG4rJKvBU5",
        "outputId": "5ce954ba-ee46-4af6-e422-dd9e517f805e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], Name: Price, dtype: object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Comprobamos que no haya normalizado ningún valor a 0 para evitar que intente dividir algún valor entre cero y nos de algún error.\n",
        "y_reg_norm[y_reg_norm == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEKkLlc4iCeN",
        "outputId": "d61af3a0-e3a5-4094-b33f-684a7ab75bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del dataset de training: (960, 25)\n",
            "Dimensiones del dataset de df_validation: (240, 25)\n",
            "Dimensiones del dataset de test: (300, 25)\n"
          ]
        }
      ],
      "source": [
        "#Observo las dimensiones y las comparo luego con las de imágeness.\n",
        "\n",
        "print(f'Dimensiones del dataset de training: {X_train.shape}')\n",
        "print(f'Dimensiones del dataset de df_validation: {X_validation.shape}')\n",
        "print(f'Dimensiones del dataset de test: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYY_xskHrey-"
      },
      "outputs": [],
      "source": [
        "#Lo convertimos en formato necesario para que no nos de problemas tensor flow\n",
        "\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "\n",
        "X_validation = np.asarray(X_validation).astype(np.float32)\n",
        "y_validation = np.asarray(y_validation).astype(np.float32)\n",
        "\n",
        "X_test = np.asarray(X_test).astype(np.float32)\n",
        "y_test =  np.asarray(y_test).astype(np.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL7MiKGXlNws"
      },
      "source": [
        "**AHORA COMENZAMOS CON NUESTRA ARQUITECTURA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osCGkNmNUYIy"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "import hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyovpZ6IdC98"
      },
      "source": [
        "**USAMOS HYPEROPT PARA ENCONTRAR LOS MEJORES PARÁMETROS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f5W1orqUUot",
        "outputId": "f3db4a77-ae40-40a4-d373-b87e00e16fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0216\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0245\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0116\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0166\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0232\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0221\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0111\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0261\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0252\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0238\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0234 - val_loss: 0.0110\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0339\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0242\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0232\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0110\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0279\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0231\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0229\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0234 - val_loss: 0.0110\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0184\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0213\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0230\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0109\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0217\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0228\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0213\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0214 - val_loss: 0.0109\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0211\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0241\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0225\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0108\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0145\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0211\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0208\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0104\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0236\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0227\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0225\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0102\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0328\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0217\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0230\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0104\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0262\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0223\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0208\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0103\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0176\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0212\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0217\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0102\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0252\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0213\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0205\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0101\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0274\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0213\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0215\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0102\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0141\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0201\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0200\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0101\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0125\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0207\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0215\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0101\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0253\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0209\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0212\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0100\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0221\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0211\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0203\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0099\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0218\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0206\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0201\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0100\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0181\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0180\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0188\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0099\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0229\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0206\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0100\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0270\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0181\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0174\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0099\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0227\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0201\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0193\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0099\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0285\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0199\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0098\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0147\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0172\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0186\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0099\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0226\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0165\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0179\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0098\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0158\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0186\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0192\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0099\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0295\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0181\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0098\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0164\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0208\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0188\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0098\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0309\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0168\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0185\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0098\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0138\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0175\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0188\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0098\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0222\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0182\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0098\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0145\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0197\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0098\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0275\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0180\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0176\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0089\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0189\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0176\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0348\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0177\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0096\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0253\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0195\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0182\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0097\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0129\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0191\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0098\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0249\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0188\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0177\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0099\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0149\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0176\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0176\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0098\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0161\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0170\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0176\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0239\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0183\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0098\n",
            "\n",
            "Epoch 74/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0273\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0183\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0099\n",
            "\n",
            "Epoch 75/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0248\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0184\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0098\n",
            "\n",
            "Epoch 76/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0178\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0180\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0180\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0098\n",
            "\n",
            "Epoch 77/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0323\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0195\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0177\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0099\n",
            "\n",
            "Epoch 78/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0233\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0179\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0170\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0099\n",
            "\n",
            "Epoch 79/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0137\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0154\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0166\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0097\n",
            "\n",
            "Epoch 80/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0247\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0175\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0098\n",
            "\n",
            "Epoch 81/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0136\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0183\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0168\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0097\n",
            "\n",
            "Epoch 82/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0117\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0193\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0181\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0098\n",
            "\n",
            "Epoch 83/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0157\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0170\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0097\n",
            "\n",
            "Epoch 84/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0119\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0167\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0162\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0097\n",
            "\n",
            "Epoch 85/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0271\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0189\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0184\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0098\n",
            "\n",
            "Epoch 86/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0201\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0168\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0164\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0098\n",
            "\n",
            "Epoch 87/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0097\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0185\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0168\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0098\n",
            "\n",
            "Epoch 88/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0315\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0174\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0097\n",
            "\n",
            "Epoch 89/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0110\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0160\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0175\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0097\n",
            "\n",
            "Epoch 90/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0320\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0160\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0097\n",
            "\n",
            "Epoch 91/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0199\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0173\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0097\n",
            "\n",
            "Epoch 92/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0139\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0150\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0096\n",
            "\n",
            "Epoch 93/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0078\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0140\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0159\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0097\n",
            "\n",
            "Epoch 94/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0094\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0154\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0157\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0096\n",
            "\n",
            "Epoch 95/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0101\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0178\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0097\n",
            "\n",
            "Epoch 96/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0100\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0196\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0097\n",
            "\n",
            "Epoch 97/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0137\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0167\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0171 - val_loss: 0.0097\n",
            "\n",
            "Epoch 98/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0142\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0165\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0162\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0097\n",
            "\n",
            "Epoch 99/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0117\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0149\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0165\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0098\n",
            "\n",
            "Epoch 100/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0170\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0167\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0174\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0101\n",
            "\n",
            "Epoch 1/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 16s - loss: 0.1625\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.1534 \n",
            "15/15 [==============================] - 1s 20ms/step - loss: 0.1553 - val_loss: 0.0624\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1510\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1561\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1545 - val_loss: 0.0510\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1477\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.1486\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1489 - val_loss: 0.0441\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1496\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1512\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1487 - val_loss: 0.0399\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1508\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1467\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1488 - val_loss: 0.0373\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1534\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1534\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1534 - val_loss: 0.0355\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1242\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1428\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1428 - val_loss: 0.0342\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1362\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1360\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1360 - val_loss: 0.0327\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1559\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1409\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1383 - val_loss: 0.0315\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1147\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1351\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1351 - val_loss: 0.0305\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1485\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1377\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1377 - val_loss: 0.0295\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1443\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1267\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1267 - val_loss: 0.0285\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1157\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1308\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1308 - val_loss: 0.0277\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1315\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1312\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1312 - val_loss: 0.0272\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1269\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1335\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1335 - val_loss: 0.0265\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1632\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1393\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1393 - val_loss: 0.0259\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1346\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1276\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1276 - val_loss: 0.0253\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1301\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1324\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1324 - val_loss: 0.0249\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1123\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1264\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1255 - val_loss: 0.0246\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1329\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1338\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1330 - val_loss: 0.0243\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1310\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1259\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1259 - val_loss: 0.0238\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1075\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1240\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1240 - val_loss: 0.0235\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1026\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1201\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1201 - val_loss: 0.0232\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1034\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1238\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1255 - val_loss: 0.0229\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0900\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1127\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1163 - val_loss: 0.0224\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1124\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1179\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1195 - val_loss: 0.0220\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1190\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1121\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1130 - val_loss: 0.0217\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1270\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1219\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1225 - val_loss: 0.0215\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1409\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1191\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1190 - val_loss: 0.0212\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1226\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1157\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1157 - val_loss: 0.0209\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0956\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1043\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1048 - val_loss: 0.0207\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1118\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1115\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1130 - val_loss: 0.0204\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1045\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1093\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1093 - val_loss: 0.0202\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1272\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.1078\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1086 - val_loss: 0.0201\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1398\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1031\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1031 - val_loss: 0.0201\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1056\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1005\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0999 - val_loss: 0.0200\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0890\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1047\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.1057 - val_loss: 0.0200\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1145\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1057\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1046 - val_loss: 0.0200\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1122\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1051\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1051 - val_loss: 0.0198\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1222\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1057\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1058 - val_loss: 0.0197\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1010\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1079\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1087 - val_loss: 0.0198\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1135\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0965\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.0197\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1007\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0999\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1001 - val_loss: 0.0197\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1012\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1023\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0196\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1229\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0984\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.0196\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0971\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0973\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0974 - val_loss: 0.0196\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1196\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1050\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1050 - val_loss: 0.0195\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1011\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0921\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0921 - val_loss: 0.0192\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1001\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0930\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0929 - val_loss: 0.0192\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0855\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0916\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0905 - val_loss: 0.0190\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0887\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0940\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0964 - val_loss: 0.0190\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0893\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0957\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0940 - val_loss: 0.0191\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0977\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0943\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0933 - val_loss: 0.0191\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0894\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0898\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0887 - val_loss: 0.0192\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1098\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0832\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0832 - val_loss: 0.0193\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1090\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0923\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0926 - val_loss: 0.0194\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0741\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0797\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.0195\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1092\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0942\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0928 - val_loss: 0.0195\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0780\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0873\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0903 - val_loss: 0.0197\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0808\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0840\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0828 - val_loss: 0.0196\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1117\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0923\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0921 - val_loss: 0.0194\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0948\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0899\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0870 - val_loss: 0.0194\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0832\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0856\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0193\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1040\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0857\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0851 - val_loss: 0.0191\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0614\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0845\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0852 - val_loss: 0.0191\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1068\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0845\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.0193\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1039\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0849\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0855 - val_loss: 0.0193\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0630\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0847\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0860 - val_loss: 0.0195\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0643\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0918\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0915 - val_loss: 0.0195\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0774\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0833\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0818 - val_loss: 0.0194\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1037\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0810\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0816 - val_loss: 0.0196\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0547\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0797\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0802 - val_loss: 0.0197\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0782\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0762\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0768 - val_loss: 0.0196\n",
            "\n",
            "Epoch 74/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1014\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0833\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0836 - val_loss: 0.0196\n",
            "\n",
            "Epoch 75/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0838\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0774\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.0196\n",
            "\n",
            "Epoch 76/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0989\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0772\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0753 - val_loss: 0.0195\n",
            "\n",
            "Epoch 77/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0750\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0711\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0707 - val_loss: 0.0195\n",
            "\n",
            "Epoch 78/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1021\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0846\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0843 - val_loss: 0.0196\n",
            "\n",
            "Epoch 79/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0825\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0831\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0833 - val_loss: 0.0197\n",
            "\n",
            "Epoch 80/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0842\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0683\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0702 - val_loss: 0.0197\n",
            "\n",
            "Epoch 81/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1012\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0705\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0698 - val_loss: 0.0197\n",
            "\n",
            "Epoch 82/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0683\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0769\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0755 - val_loss: 0.0199\n",
            "\n",
            "Epoch 83/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0754\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0752\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0200\n",
            "\n",
            "Epoch 84/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0616\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0720\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0742 - val_loss: 0.0198\n",
            "\n",
            "Epoch 85/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0726\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0716\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0721 - val_loss: 0.0203\n",
            "\n",
            "Epoch 86/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0830\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0701\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0699 - val_loss: 0.0202\n",
            "\n",
            "Epoch 87/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0848\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0708\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0708 - val_loss: 0.0204\n",
            "\n",
            "Epoch 88/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0821\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0722\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0717 - val_loss: 0.0204\n",
            "\n",
            "Epoch 89/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0604\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0676\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0675 - val_loss: 0.0205\n",
            "\n",
            "Epoch 90/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0604\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0592\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0204\n",
            "\n",
            "Epoch 91/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0571\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0722\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0734 - val_loss: 0.0200\n",
            "\n",
            "Epoch 92/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0382\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0666\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0659 - val_loss: 0.0200\n",
            "\n",
            "Epoch 93/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0824\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0700\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0701 - val_loss: 0.0199\n",
            "\n",
            "Epoch 94/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0755\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0702\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0695 - val_loss: 0.0199\n",
            "\n",
            "Epoch 95/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0494\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0664\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0661 - val_loss: 0.0199\n",
            "\n",
            "Epoch 96/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0714\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0654\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0653 - val_loss: 0.0199\n",
            "\n",
            "Epoch 97/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0689\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0713\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0693 - val_loss: 0.0198\n",
            "\n",
            "Epoch 98/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0602\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0640\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0661 - val_loss: 0.0197\n",
            "\n",
            "Epoch 99/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0549\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0661\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0655 - val_loss: 0.0196\n",
            "\n",
            "Epoch 100/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0612\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0694\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0663 - val_loss: 0.0195\n",
            "\n",
            "Epoch 1/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 35s - loss: 0.1718\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.1368 \n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1290\n",
            "30/30 [==============================] - 2s 11ms/step - loss: 0.1262 - val_loss: 0.0502\n",
            "\n",
            "Epoch 2/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0928\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1041\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0976\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0975 - val_loss: 0.0318\n",
            "\n",
            "Epoch 3/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1104\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0895\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0832\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0810 - val_loss: 0.0241\n",
            "\n",
            "Epoch 4/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1013\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0848\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0767\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0223\n",
            "\n",
            "Epoch 5/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0663\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0610\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0615\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0614 - val_loss: 0.0225\n",
            "\n",
            "Epoch 6/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0441\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0582\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0580\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.0227\n",
            "\n",
            "Epoch 7/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0540\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0478\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0482\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0468 - val_loss: 0.0237\n",
            "\n",
            "Epoch 8/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0429\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0442\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0415\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0234\n",
            "\n",
            "Epoch 9/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0307\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0399\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0406\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0412 - val_loss: 0.0215\n",
            "\n",
            "Epoch 10/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0461\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0422\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0413\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0408 - val_loss: 0.0189\n",
            "\n",
            "Epoch 11/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0336\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0353\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0351\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0374 - val_loss: 0.0160\n",
            "\n",
            "Epoch 12/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0640\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0327\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0340\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.0145\n",
            "\n",
            "Epoch 13/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0164\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0362\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0329\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0141\n",
            "\n",
            "Epoch 14/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0174\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0298\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0308\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0306 - val_loss: 0.0137\n",
            "\n",
            "Epoch 15/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0306\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0302\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0311\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0310 - val_loss: 0.0128\n",
            "\n",
            "Epoch 16/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0177\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0273\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0289\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.0121\n",
            "\n",
            "Epoch 17/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0384\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0296\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0278\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0279 - val_loss: 0.0115\n",
            "\n",
            "Epoch 18/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0147\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0228\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0247\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0259 - val_loss: 0.0113\n",
            "\n",
            "Epoch 19/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0297\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0284\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0278\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0113\n",
            "\n",
            "Epoch 20/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0372\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0264\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0250\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0115\n",
            "\n",
            "Epoch 21/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0093\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0242\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0249\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0114\n",
            "\n",
            "Epoch 22/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0235\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0243\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0263\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0252 - val_loss: 0.0109\n",
            "\n",
            "Epoch 23/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0331\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0248\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0234\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0108\n",
            "\n",
            "Epoch 24/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0125\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0240\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0229\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0107\n",
            "\n",
            "Epoch 25/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0214\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0220\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0213\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0107\n",
            "\n",
            "Epoch 26/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0170\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0220\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0214\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0107\n",
            "\n",
            "Epoch 27/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0321\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0219\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0196\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0109\n",
            "\n",
            "Epoch 28/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0121\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0216\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0215\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0109\n",
            "\n",
            "Epoch 29/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0196\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0198\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0208\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0106\n",
            "\n",
            "Epoch 30/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0161\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0193\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0199\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0105\n",
            "\n",
            "Epoch 31/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0238\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0211\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0189\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0107\n",
            "\n",
            "Epoch 32/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0262\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0190\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0195\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0106\n",
            "\n",
            "Epoch 33/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0197\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0192\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0186\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0104\n",
            "\n",
            "Epoch 34/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0265\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0188\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0184\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0102\n",
            "\n",
            "Epoch 35/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0140\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0194\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0201\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0102\n",
            "\n",
            "Epoch 36/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0294\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0212\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0181\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0102\n",
            "\n",
            "Epoch 37/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0206\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0182\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0184\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0101\n",
            "\n",
            "Epoch 38/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0171\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0192\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0192\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0104\n",
            "\n",
            "Epoch 39/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0140\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0177\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0105\n",
            "\n",
            "Epoch 40/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0189\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0172\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0172\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0106\n",
            "\n",
            "Epoch 41/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0097\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0158\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0107\n",
            "\n",
            "Epoch 42/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0157\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0188\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0103\n",
            "\n",
            "Epoch 43/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0205\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0199\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0106\n",
            "\n",
            "Epoch 44/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0139\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0159\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0190\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0103\n",
            "\n",
            "Epoch 45/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0061\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0164\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0162\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0103\n",
            "\n",
            "Epoch 46/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0120\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0175\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0172\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0104\n",
            "\n",
            "Epoch 47/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0183\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0168\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0162\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0104\n",
            "\n",
            "Epoch 48/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0176\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0168\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0104\n",
            "\n",
            "Epoch 49/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0159\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0148\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0157\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0109\n",
            "\n",
            "Epoch 50/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0148\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0155\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0158\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0110\n",
            "\n",
            "Epoch 51/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0130\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0170\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0170\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0111\n",
            "\n",
            "Epoch 52/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0435\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0170\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0172\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0105\n",
            "\n",
            "Epoch 53/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0125\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0170\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0161\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0105\n",
            "\n",
            "Epoch 54/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0117\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0161\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0104\n",
            "\n",
            "Epoch 55/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0081\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0167\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0159\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0106\n",
            "\n",
            "Epoch 56/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0100\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0134\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0146\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0106\n",
            "\n",
            "Epoch 57/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0079\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0138\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0134\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0105\n",
            "\n",
            "Epoch 58/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0322\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0142\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0153\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0104\n",
            "\n",
            "Epoch 59/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0153\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0156\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0154\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0103\n",
            "\n",
            "Epoch 60/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0195\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0156\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0105\n",
            "\n",
            "Epoch 61/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0117\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0147\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0142\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0105\n",
            "\n",
            "Epoch 62/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0172\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0128\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0144\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0107\n",
            "\n",
            "Epoch 63/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0261\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0168\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0163\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0105\n",
            "\n",
            "Epoch 64/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0115\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0139\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0152\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0106\n",
            "\n",
            "Epoch 65/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0091\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0113\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0130\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0107\n",
            "\n",
            "Epoch 66/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0131\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0170\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0161\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0109\n",
            "\n",
            "Epoch 67/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0376\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0165\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0166\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0105\n",
            "\n",
            "Epoch 68/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0106\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0129\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0141\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0103\n",
            "\n",
            "Epoch 69/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0112\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0119\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0129\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0105\n",
            "\n",
            "Epoch 70/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0096\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0132\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0142\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0107\n",
            "\n",
            "Epoch 71/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0127\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0142\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0145\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0105\n",
            "\n",
            "Epoch 72/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0195\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0159\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0153\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0108\n",
            "\n",
            "Epoch 73/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0163\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0151\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0145\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0104\n",
            "\n",
            "Epoch 74/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0063\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0115\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0129\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
            "\n",
            "Epoch 75/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0157\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0146\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0141\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
            "\n",
            "Epoch 76/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0133\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0140\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0146\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0101\n",
            "\n",
            "Epoch 77/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0144\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0155\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0148\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0103\n",
            "\n",
            "Epoch 78/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0114\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0137\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0151\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0108\n",
            "\n",
            "Epoch 79/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0147\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0128\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0135\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0107\n",
            "\n",
            "Epoch 80/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0115\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0150\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0139\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0103\n",
            "\n",
            "Epoch 81/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0198\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0139\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0141\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
            "\n",
            "Epoch 82/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0202\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0152\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0143\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0106\n",
            "\n",
            "Epoch 83/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0159\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0164\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0146\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0107\n",
            "\n",
            "Epoch 84/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0069\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0135\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0133\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0105\n",
            "\n",
            "Epoch 85/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0126\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0138\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0105\n",
            "\n",
            "Epoch 86/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0206\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0133\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0133\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
            "\n",
            "Epoch 87/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0104\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0148\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0139\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
            "\n",
            "Epoch 88/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0158\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0149\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0146\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0104\n",
            "\n",
            "Epoch 89/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0102\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0145\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0132\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0103\n",
            "\n",
            "Epoch 90/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0110\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0135\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0141\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
            "\n",
            "Epoch 91/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0070\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0129\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0128\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0104\n",
            "\n",
            "Epoch 92/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0085\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0130\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0133\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0106\n",
            "\n",
            "Epoch 93/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0200\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0143\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0131\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0108\n",
            "\n",
            "Epoch 94/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0138\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0149\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0153\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0108\n",
            "\n",
            "Epoch 95/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0082\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0129\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0129\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0113\n",
            "\n",
            "Epoch 96/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0116\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0127\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0108\n",
            "\n",
            "Epoch 97/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0196\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0127\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0139\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0105\n",
            "\n",
            "Epoch 98/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0127\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0144\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0107\n",
            "\n",
            "Epoch 99/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0146\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0146\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0134\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
            "\n",
            "Epoch 100/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0106\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0122\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0134\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0102\n",
            "\n",
            "Epoch 101/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0182\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0134\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0140\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
            "\n",
            "Epoch 102/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0120\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0118\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0120\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0105\n",
            "\n",
            "Epoch 103/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0081\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0135\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0129\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0105\n",
            "\n",
            "Epoch 104/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0118\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0134\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0131\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0109\n",
            "\n",
            "Epoch 105/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0076\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0123\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0128\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0107\n",
            "\n",
            "Epoch 106/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0093\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0132\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0121\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0106\n",
            "\n",
            "Epoch 107/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0100\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0104\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0133\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0107\n",
            "\n",
            "Epoch 108/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0122\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0110\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0114\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0103\n",
            "\n",
            "Epoch 109/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0099\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0140\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0136\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0109\n",
            "\n",
            "Epoch 110/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0098\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0120\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0130\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0111\n",
            "\n",
            "Epoch 111/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0122\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0120\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0115\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0112\n",
            "\n",
            "Epoch 112/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0160\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0119\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0122\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0116\n",
            "\n",
            "Epoch 113/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0098\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0119\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0109\n",
            "\n",
            "Epoch 114/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0083\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0155\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0143\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0108\n",
            "\n",
            "Epoch 115/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0171\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0156\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0140\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0108\n",
            "\n",
            "Epoch 116/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0103\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0113\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0121\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0108\n",
            "\n",
            "Epoch 117/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0225\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0144\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0132\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0105\n",
            "\n",
            "Epoch 118/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0112\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0122\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0115\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0106\n",
            "\n",
            "Epoch 119/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0076\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0144\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0139\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0130\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0116\n",
            "\n",
            "Epoch 120/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0173\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0129\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0133\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0106\n",
            "\n",
            "Epoch 121/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0121\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0122\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0110\n",
            "\n",
            "Epoch 122/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0161\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0125\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0116\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0111\n",
            "\n",
            "Epoch 123/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0116\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0128\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0146\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
            "\n",
            "Epoch 124/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0037\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0091\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0099\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0106\n",
            "\n",
            "Epoch 125/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0131\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0139\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0126\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0113\n",
            "\n",
            "Epoch 126/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0062\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0121\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0117\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0108\n",
            "\n",
            "Epoch 127/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0260\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0163\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0141\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0136\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0114\n",
            "\n",
            "Epoch 128/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0090\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0123\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0109\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0108\n",
            "\n",
            "Epoch 129/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0117\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0121\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0122\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0108\n",
            "\n",
            "Epoch 130/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0331\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0139\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0122\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0111\n",
            "\n",
            "Epoch 131/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0107\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0117\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0117\n",
            "\n",
            "Epoch 132/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0084\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0124\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0113\n",
            "\n",
            "Epoch 133/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0115\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0122\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0119\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0114\n",
            "\n",
            "Epoch 134/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0088\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0117\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0118\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0112\n",
            "\n",
            "Epoch 135/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0173\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0119\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0115\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0117\n",
            "\n",
            "Epoch 136/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0063\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0103\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0122\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0112\n",
            "\n",
            "Epoch 137/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0146\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0139\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0137\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0113\n",
            "\n",
            "Epoch 138/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0080\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0108\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0132\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0112\n",
            "\n",
            "Epoch 139/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0078\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0104\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0122\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0112\n",
            "\n",
            "Epoch 140/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0098\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0116\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0119\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0106\n",
            "\n",
            "Epoch 141/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0243\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0126\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0111\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0110\n",
            "\n",
            "Epoch 142/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0073\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0130\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0114\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0116\n",
            "\n",
            "Epoch 143/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0114\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0116\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0114\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0112\n",
            "\n",
            "Epoch 144/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0064\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0124\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0109\n",
            "\n",
            "Epoch 145/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0143\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0132\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0115\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0109\n",
            "\n",
            "Epoch 146/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0147\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0109\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0113\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0122\n",
            "\n",
            "Epoch 147/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0160\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0149\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0128\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0107\n",
            "\n",
            "Epoch 148/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0103\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0102\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0124\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0109\n",
            "\n",
            "Epoch 149/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0054\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0126\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0117\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0118\n",
            "\n",
            "Epoch 150/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0116\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0111\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0127\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0109\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 7s - loss: 0.1323\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 0.1438 - val_loss: 0.0804\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1382\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1336 - val_loss: 0.0606\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1378\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1394 - val_loss: 0.0474\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1268\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1379 - val_loss: 0.0386\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1139\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1364 - val_loss: 0.0326\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1462\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1427 - val_loss: 0.0283\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1325\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1325 - val_loss: 0.0251\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1461\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1325 - val_loss: 0.0231\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1241\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1275 - val_loss: 0.0219\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1371\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1308 - val_loss: 0.0212\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1196\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1249 - val_loss: 0.0208\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1375\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1243 - val_loss: 0.0207\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1080\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1301 - val_loss: 0.0208\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1370\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1284 - val_loss: 0.0210\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1229\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1220 - val_loss: 0.0213\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1262\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1197 - val_loss: 0.0217\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1108\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1250 - val_loss: 0.0220\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1241\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1172 - val_loss: 0.0224\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1415\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1213 - val_loss: 0.0228\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1118\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1151 - val_loss: 0.0231\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1101\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1174 - val_loss: 0.0237\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1324\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1172 - val_loss: 0.0242\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1167\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1170 - val_loss: 0.0245\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1297\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1162 - val_loss: 0.0247\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1270\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1132 - val_loss: 0.0249\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1120\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1062 - val_loss: 0.0249\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0984\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1061 - val_loss: 0.0248\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1185\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1036 - val_loss: 0.0249\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1226\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1106 - val_loss: 0.0249\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1171\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1154 - val_loss: 0.0249\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0979\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1028 - val_loss: 0.0245\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1066\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1106 - val_loss: 0.0243\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1029\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1008 - val_loss: 0.0241\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0856\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0994 - val_loss: 0.0240\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1034\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1063 - val_loss: 0.0236\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0932\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1013 - val_loss: 0.0235\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1012\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1082 - val_loss: 0.0233\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0772\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1020 - val_loss: 0.0229\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0923\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0936 - val_loss: 0.0223\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0967\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0997 - val_loss: 0.0221\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0848\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0960 - val_loss: 0.0217\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0884\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0908 - val_loss: 0.0215\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0936\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0998 - val_loss: 0.0211\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1092\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0924 - val_loss: 0.0208\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0943\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0950 - val_loss: 0.0203\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0864\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0915 - val_loss: 0.0202\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0694\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0867 - val_loss: 0.0198\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0955\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0946 - val_loss: 0.0195\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0949\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0919 - val_loss: 0.0193\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0920\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0982 - val_loss: 0.0190\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 1:00 - loss: 0.1801\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.1277  \n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.1197\n",
            "33/60 [===============>..............] - ETA: 0s - loss: 0.1008\n",
            "42/60 [====================>.........] - ETA: 0s - loss: 0.0916\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0829\n",
            "60/60 [==============================] - 2s 9ms/step - loss: 0.0759 - val_loss: 0.0208\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0271\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0355\n",
            "20/60 [=========>....................] - ETA: 0s - loss: 0.0351\n",
            "32/60 [===============>..............] - ETA: 0s - loss: 0.0364\n",
            "43/60 [====================>.........] - ETA: 0s - loss: 0.0346\n",
            "55/60 [==========================>...] - ETA: 0s - loss: 0.0329\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0328 - val_loss: 0.0192\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0281\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0313\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0275\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0273\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0265\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.0258\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0210\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0232\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0223\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0228\n",
            "45/60 [=====================>........] - ETA: 0s - loss: 0.0212\n",
            "55/60 [==========================>...] - ETA: 0s - loss: 0.0215\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0133\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0493\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0288\n",
            "27/60 [============>.................] - ETA: 0s - loss: 0.0246\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0225\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0228\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0219\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0117\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0267\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0206\n",
            "27/60 [============>.................] - ETA: 0s - loss: 0.0194\n",
            "40/60 [===================>..........] - ETA: 0s - loss: 0.0213\n",
            "53/60 [=========================>....] - ETA: 0s - loss: 0.0204\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0105\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0276\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0224\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0224\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0228\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0215\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0104\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0237\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0176\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0188\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0210\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0209\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0112\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0100\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0218\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0203\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0206\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0205\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0121\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0075\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0248\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0204\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0202\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0200\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0107\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0192\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0177\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0164\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0174\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0172\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0115\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0140\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0192\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0187\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0175\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0191\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0142\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0128\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0244\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0222\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0189\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0196\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0096\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0145\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0159\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0160\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0180\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0187\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0098\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0301\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0185\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0179\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0177\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0141\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0146\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0200\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0205\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0208\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0191\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0188\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0117\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0147\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0208\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0175\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0171\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0179\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0099\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0170\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0158\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0167\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0175\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0173\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0100\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0202\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0180\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0164\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0173\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0184\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0116\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0101\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0182\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0179\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0171\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0160\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0114\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0081\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0183\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0199\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0187\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0177\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0104\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0127\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0119\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0151\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0176\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0108\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0197\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0157\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0161\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0166\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0175\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0115\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0154\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0156\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0159\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0171\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0174\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0122\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0089\n",
            " 9/60 [===>..........................] - ETA: 0s - loss: 0.0232\n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.0190\n",
            "34/60 [================>.............] - ETA: 0s - loss: 0.0195\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0183\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0108\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0118\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0157\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0159\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0164\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0106\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0304\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0122\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0136\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0172\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0115\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0049\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0138\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0174\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0189\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0171 - val_loss: 0.0102\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0064\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0181\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0181\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0178\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0177\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0118\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0142\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0136\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0147\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0167\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0161\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0104\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0158\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0185\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0181\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0184\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0178\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0112\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0328\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0194\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0176\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0182\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0184\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0109\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0266\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0158\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0191\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0191\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0106\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0125\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0195\n",
            "27/60 [============>.................] - ETA: 0s - loss: 0.0192\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0181\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0182\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0116\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0119\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0165\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0166\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0163\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0178\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0110\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0062\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0135\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0157\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0148\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0159\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0111\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0084\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0185\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0173\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0175\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0177\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0120\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0078\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0152\n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.0168\n",
            "34/60 [================>.............] - ETA: 0s - loss: 0.0169\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0165\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.0168\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0103\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0584\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0178\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0159\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0162\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0171\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0170\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0118\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0104\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0147\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0200\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0204\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0204\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0198\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0101\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0203\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0148\n",
            "21/60 [=========>....................] - ETA: 0s - loss: 0.0187\n",
            "31/60 [==============>...............] - ETA: 0s - loss: 0.0172\n",
            "40/60 [===================>..........] - ETA: 0s - loss: 0.0167\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0168\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0184\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0117\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0164\n",
            "10/60 [====>.........................] - ETA: 0s - loss: 0.0184\n",
            "19/60 [========>.....................] - ETA: 0s - loss: 0.0183\n",
            "30/60 [==============>...............] - ETA: 0s - loss: 0.0187\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0188\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0179\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0170\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0103\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0148\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0148\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0166\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0182\n",
            "45/60 [=====================>........] - ETA: 0s - loss: 0.0191\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0123\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0115\n",
            "10/60 [====>.........................] - ETA: 0s - loss: 0.0195\n",
            "21/60 [=========>....................] - ETA: 0s - loss: 0.0161\n",
            "33/60 [===============>..............] - ETA: 0s - loss: 0.0183\n",
            "45/60 [=====================>........] - ETA: 0s - loss: 0.0180\n",
            "55/60 [==========================>...] - ETA: 0s - loss: 0.0182\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0110\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0157\n",
            "10/60 [====>.........................] - ETA: 0s - loss: 0.0191\n",
            "20/60 [=========>....................] - ETA: 0s - loss: 0.0176\n",
            "32/60 [===============>..............] - ETA: 0s - loss: 0.0180\n",
            "44/60 [=====================>........] - ETA: 0s - loss: 0.0176\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.0170\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0104\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0085\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0149\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0144\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0160\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0165\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0135\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0368\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0249\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0189\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0183\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0182\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0159\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0158\n",
            "15/60 [======>.......................] - ETA: 0s - loss: 0.0207\n",
            "28/60 [=============>................] - ETA: 0s - loss: 0.0196\n",
            "40/60 [===================>..........] - ETA: 0s - loss: 0.0186\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0184\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0100\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0110\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0183\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0196\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0184\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0171\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0110\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0291\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0158\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0159\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0166\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0105\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 13s - loss: 0.1916\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.1397 \n",
            "15/15 [==============================] - 1s 19ms/step - loss: 0.1401 - val_loss: 0.0707\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1264\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1355\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1360 - val_loss: 0.0790\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1202\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1325\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1329 - val_loss: 0.0853\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1442\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1314\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1322 - val_loss: 0.0934\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1243\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.1229\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1217 - val_loss: 0.1007\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1148\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1204\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1201 - val_loss: 0.1084\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1266\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1213\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1201 - val_loss: 0.1148\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1338\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1152\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1137 - val_loss: 0.1206\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0765\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1094\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1114 - val_loss: 0.1260\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0966\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1105\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1117 - val_loss: 0.1294\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1383\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1164\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1168 - val_loss: 0.1318\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0855\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1053\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1051 - val_loss: 0.1325\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1013\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1046\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1034 - val_loss: 0.1333\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1085\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1096\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1085 - val_loss: 0.1333\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1221\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1019\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1024 - val_loss: 0.1322\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1186\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0986\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0983 - val_loss: 0.1295\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0727\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0961\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0963 - val_loss: 0.1269\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1088\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.1021\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1017 - val_loss: 0.1249\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0995\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0991\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0990 - val_loss: 0.1221\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0747\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0883\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0892 - val_loss: 0.1187\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0863\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0918\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0918 - val_loss: 0.1143\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1087\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0924\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0929 - val_loss: 0.1097\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0829\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0897\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0896 - val_loss: 0.1064\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0920\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0869\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0874 - val_loss: 0.1029\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0935\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0919\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0943 - val_loss: 0.0997\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0911\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0851\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0873 - val_loss: 0.0961\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.1041\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0824\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0822 - val_loss: 0.0914\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0765\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0887\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0869 - val_loss: 0.0876\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0785\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0850\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0849 - val_loss: 0.0841\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0884\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0836\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0807\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0991\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0857\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0853 - val_loss: 0.0770\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0620\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0827\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0816 - val_loss: 0.0739\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0625\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0739\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0739 - val_loss: 0.0707\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0653\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0743\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0673\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0871\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0809\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0793 - val_loss: 0.0646\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0703\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0831\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0837 - val_loss: 0.0616\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0888\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0716\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0724 - val_loss: 0.0590\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0603\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0809\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0564\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0835\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0751\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0760 - val_loss: 0.0552\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0777\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0748\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0737 - val_loss: 0.0543\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0822\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0728\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0725 - val_loss: 0.0524\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0793\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0715\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0715 - val_loss: 0.0506\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0577\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0688\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0685 - val_loss: 0.0488\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0745\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0706\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0697 - val_loss: 0.0473\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0731\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0710\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0712 - val_loss: 0.0463\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0634\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0687\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0710 - val_loss: 0.0450\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0506\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0649\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0660 - val_loss: 0.0435\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0662\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0660\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.0427\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0488\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0664\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0668 - val_loss: 0.0422\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0584\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0686\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0664 - val_loss: 0.0414\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 37s - loss: 0.1630\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.1325 \n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1057\n",
            "30/30 [==============================] - 2s 13ms/step - loss: 0.0908 - val_loss: 0.0231\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0447\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0468\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0428\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0415 - val_loss: 0.0232\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0531\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0313\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0334\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.0223\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0136\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0239\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0226\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0164\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0214\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0239\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0239\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.0200\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0162\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0207\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0214\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0180\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0264\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0228\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0205\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0206 - val_loss: 0.0135\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0197\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0238\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0204\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0192\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0124\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0152\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0199\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0192\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0126\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0326\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0184\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0187\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0125\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0279\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0239\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0187\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0119\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0223\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0195\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0189\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0146\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0180\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0206\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0197\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0128\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0248\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0160\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0185\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0134\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0181\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0194\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0187\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0103\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0069\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0158\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0175\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0107\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0091\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0163\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0111\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0101\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0168\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0180\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0125\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0176\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0169\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0112\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0253\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0180\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0121\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0157\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0158\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0163\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0125\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0137\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0184\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0101\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0143\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0151\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0156\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0108\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0260\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0179\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0169\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0124\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0108\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0174\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0177\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0120\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0177\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0168\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0128\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0146\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0168\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0179\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0106\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0162\n",
            "12/30 [===========>..................] - ETA: 0s - loss: 0.0164\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0104\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0106\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0155\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0169\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0115\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0218\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0181\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0113\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0131\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0172\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0177\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0111\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0263\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0193\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0108\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0133\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0162\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0178\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0123\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0069\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0163\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0171\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0128\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0186\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0106\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0223\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0194\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0179\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0125\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0395\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0188\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0179\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0118\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0186\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0164\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0157\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0101\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0094\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0198\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0168\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0118\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0152\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0151\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0151\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0106\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0177\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0160\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0120\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0080\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0166\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0174\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0103\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0167\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0175\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0164\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0104\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0143\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0163\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0156\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0108\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0151\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0165\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0116\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0103\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0167\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0173\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0119\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0053\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.0152\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0167\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0131\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0200\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0165\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0152\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0101\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0113\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0164\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0180\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0106\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0218\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.0181\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0165\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0103\n",
            "\n",
            "Epoch 1/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 8s - loss: 0.1320\n",
            "8/8 [==============================] - 2s 35ms/step - loss: 0.1305 - val_loss: 0.0708\n",
            "\n",
            "Epoch 2/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1438\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1171 - val_loss: 0.0481\n",
            "\n",
            "Epoch 3/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1128\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1179 - val_loss: 0.0366\n",
            "\n",
            "Epoch 4/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0931\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1111 - val_loss: 0.0300\n",
            "\n",
            "Epoch 5/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0891\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0922 - val_loss: 0.0266\n",
            "\n",
            "Epoch 6/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0999\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0893 - val_loss: 0.0246\n",
            "\n",
            "Epoch 7/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0989\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0902 - val_loss: 0.0234\n",
            "\n",
            "Epoch 8/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0700\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0787 - val_loss: 0.0228\n",
            "\n",
            "Epoch 9/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0734\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0801\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0801 - val_loss: 0.0225\n",
            "\n",
            "Epoch 10/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0931\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0785 - val_loss: 0.0224\n",
            "\n",
            "Epoch 11/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0888\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0730 - val_loss: 0.0226\n",
            "\n",
            "Epoch 12/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0598\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0622\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0622 - val_loss: 0.0228\n",
            "\n",
            "Epoch 13/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0608\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0615 - val_loss: 0.0230\n",
            "\n",
            "Epoch 14/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0612\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0643 - val_loss: 0.0231\n",
            "\n",
            "Epoch 15/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0684\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.0231\n",
            "\n",
            "Epoch 16/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0677\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0574\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0574 - val_loss: 0.0231\n",
            "\n",
            "Epoch 17/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0344\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.0230\n",
            "\n",
            "Epoch 18/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0553\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0536 - val_loss: 0.0228\n",
            "\n",
            "Epoch 19/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0511\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0483\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0483 - val_loss: 0.0229\n",
            "\n",
            "Epoch 20/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0560\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0491\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0491 - val_loss: 0.0232\n",
            "\n",
            "Epoch 21/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0553\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0458 - val_loss: 0.0232\n",
            "\n",
            "Epoch 22/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0418\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0464 - val_loss: 0.0230\n",
            "\n",
            "Epoch 23/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0592\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0524 - val_loss: 0.0227\n",
            "\n",
            "Epoch 24/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0441\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0460 - val_loss: 0.0221\n",
            "\n",
            "Epoch 25/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0478\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0441 - val_loss: 0.0215\n",
            "\n",
            "Epoch 26/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0365\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0416 - val_loss: 0.0212\n",
            "\n",
            "Epoch 27/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0510\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0208\n",
            "\n",
            "Epoch 28/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0482\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0443 - val_loss: 0.0204\n",
            "\n",
            "Epoch 29/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0484\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.0200\n",
            "\n",
            "Epoch 30/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0310\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.0198\n",
            "\n",
            "Epoch 31/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0330\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0362 - val_loss: 0.0194\n",
            "\n",
            "Epoch 32/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0333\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0350 - val_loss: 0.0191\n",
            "\n",
            "Epoch 33/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0370\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0378 - val_loss: 0.0186\n",
            "\n",
            "Epoch 34/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0387\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0410 - val_loss: 0.0182\n",
            "\n",
            "Epoch 35/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0331\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.0179\n",
            "\n",
            "Epoch 36/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0345\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0309 - val_loss: 0.0178\n",
            "\n",
            "Epoch 37/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0359\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0176\n",
            "\n",
            "Epoch 38/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0386\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0373\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0373 - val_loss: 0.0175\n",
            "\n",
            "Epoch 39/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0290\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0316\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0316 - val_loss: 0.0173\n",
            "\n",
            "Epoch 40/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0319\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0326\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0170\n",
            "\n",
            "Epoch 41/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0371\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0167\n",
            "\n",
            "Epoch 42/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0329\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0347 - val_loss: 0.0164\n",
            "\n",
            "Epoch 43/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0238\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0316 - val_loss: 0.0161\n",
            "\n",
            "Epoch 44/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0313\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0306 - val_loss: 0.0157\n",
            "\n",
            "Epoch 45/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0365\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0331 - val_loss: 0.0154\n",
            "\n",
            "Epoch 46/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0306\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.0151\n",
            "\n",
            "Epoch 47/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0321\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0317 - val_loss: 0.0149\n",
            "\n",
            "Epoch 48/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0296\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0148\n",
            "\n",
            "Epoch 49/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0288\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0146\n",
            "\n",
            "Epoch 50/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0297\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - val_loss: 0.0143\n",
            "\n",
            "Epoch 51/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0263\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.0140\n",
            "\n",
            "Epoch 52/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0187\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0290 - val_loss: 0.0139\n",
            "\n",
            "Epoch 53/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0273\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0274 - val_loss: 0.0139\n",
            "\n",
            "Epoch 54/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0223\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0260 - val_loss: 0.0138\n",
            "\n",
            "Epoch 55/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0382\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0296 - val_loss: 0.0137\n",
            "\n",
            "Epoch 56/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0250\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0137\n",
            "\n",
            "Epoch 57/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0315\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - val_loss: 0.0135\n",
            "\n",
            "Epoch 58/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0196\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.0134\n",
            "\n",
            "Epoch 59/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0163\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.0132\n",
            "\n",
            "Epoch 60/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0294\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0289 - val_loss: 0.0130\n",
            "\n",
            "Epoch 61/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0361\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0262 - val_loss: 0.0128\n",
            "\n",
            "Epoch 62/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0249\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0306 - val_loss: 0.0128\n",
            "\n",
            "Epoch 63/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0278\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0248 - val_loss: 0.0127\n",
            "\n",
            "Epoch 64/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0295\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0125\n",
            "\n",
            "Epoch 65/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0302\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0267 - val_loss: 0.0123\n",
            "\n",
            "Epoch 66/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0274\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0258 - val_loss: 0.0121\n",
            "\n",
            "Epoch 67/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0208\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - val_loss: 0.0118\n",
            "\n",
            "Epoch 68/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0333\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0116\n",
            "\n",
            "Epoch 69/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0297\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0115\n",
            "\n",
            "Epoch 70/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0213\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0113\n",
            "\n",
            "Epoch 71/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0279\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - val_loss: 0.0111\n",
            "\n",
            "Epoch 72/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0274\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0252 - val_loss: 0.0110\n",
            "\n",
            "Epoch 73/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0317\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - val_loss: 0.0109\n",
            "\n",
            "Epoch 74/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0231\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - val_loss: 0.0108\n",
            "\n",
            "Epoch 75/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0245\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0107\n",
            "\n",
            "Epoch 76/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0254\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0106\n",
            "\n",
            "Epoch 77/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0294\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0234 - val_loss: 0.0106\n",
            "\n",
            "Epoch 78/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0209\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0228 - val_loss: 0.0105\n",
            "\n",
            "Epoch 79/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0260\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0104\n",
            "\n",
            "Epoch 80/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0259\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0232 - val_loss: 0.0103\n",
            "\n",
            "Epoch 81/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0221\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0220 - val_loss: 0.0103\n",
            "\n",
            "Epoch 82/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0234\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0102\n",
            "\n",
            "Epoch 83/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0179\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - val_loss: 0.0102\n",
            "\n",
            "Epoch 84/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0202\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0102\n",
            "\n",
            "Epoch 85/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0223\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0101\n",
            "\n",
            "Epoch 86/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0207\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.0101\n",
            "\n",
            "Epoch 87/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0211\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 0.0101\n",
            "\n",
            "Epoch 88/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0223\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0100\n",
            "\n",
            "Epoch 89/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0238\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0100\n",
            "\n",
            "Epoch 90/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0204\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0100\n",
            "\n",
            "Epoch 91/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0178\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0100\n",
            "\n",
            "Epoch 92/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0204\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0100\n",
            "\n",
            "Epoch 93/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0295\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0100\n",
            "\n",
            "Epoch 94/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0188\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0099\n",
            "\n",
            "Epoch 95/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0211\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0099\n",
            "\n",
            "Epoch 96/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0196\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.0099\n",
            "\n",
            "Epoch 97/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0225\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - val_loss: 0.0099\n",
            "\n",
            "Epoch 98/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0141\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.0098\n",
            "\n",
            "Epoch 99/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0160\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0098\n",
            "\n",
            "Epoch 100/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0196\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - val_loss: 0.0098\n",
            "\n",
            "Epoch 101/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0206\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0098\n",
            "\n",
            "Epoch 102/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0143\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0098\n",
            "\n",
            "Epoch 103/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0254\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0098\n",
            "\n",
            "Epoch 104/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0185\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0098\n",
            "\n",
            "Epoch 105/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0206\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0187 - val_loss: 0.0098\n",
            "\n",
            "Epoch 106/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0188\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.0098\n",
            "\n",
            "Epoch 107/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0169\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0098\n",
            "\n",
            "Epoch 108/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0234\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 0.0098\n",
            "\n",
            "Epoch 109/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0211\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - val_loss: 0.0098\n",
            "\n",
            "Epoch 110/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0207\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0098\n",
            "\n",
            "Epoch 111/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0242\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - val_loss: 0.0098\n",
            "\n",
            "Epoch 112/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0186\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0098\n",
            "\n",
            "Epoch 113/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0130\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0098\n",
            "\n",
            "Epoch 114/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0230\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0098\n",
            "\n",
            "Epoch 115/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0155\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0098\n",
            "\n",
            "Epoch 116/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0156\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0098\n",
            "\n",
            "Epoch 117/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0146\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.0098\n",
            "\n",
            "Epoch 118/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0206\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0098\n",
            "\n",
            "Epoch 119/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0159\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0098\n",
            "\n",
            "Epoch 120/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0175\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0098\n",
            "\n",
            "Epoch 121/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0215\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.0098\n",
            "\n",
            "Epoch 122/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0259\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 0.0097\n",
            "\n",
            "Epoch 123/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0207\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0189\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 0.0098\n",
            "\n",
            "Epoch 124/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0143\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.0097\n",
            "\n",
            "Epoch 125/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0135\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0097\n",
            "\n",
            "Epoch 126/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0173\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0097\n",
            "\n",
            "Epoch 127/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0164\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0190 - val_loss: 0.0096\n",
            "\n",
            "Epoch 128/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0133\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0097\n",
            "\n",
            "Epoch 129/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0213\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.0098\n",
            "\n",
            "Epoch 130/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0099\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0182 - val_loss: 0.0098\n",
            "\n",
            "Epoch 131/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0179\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "\n",
            "Epoch 132/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0235\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0098\n",
            "\n",
            "Epoch 133/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0171\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.0098\n",
            "\n",
            "Epoch 134/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0173\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0098\n",
            "\n",
            "Epoch 135/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0206\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.0097\n",
            "\n",
            "Epoch 136/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0160\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - val_loss: 0.0097\n",
            "\n",
            "Epoch 137/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0192\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 0.0097\n",
            "\n",
            "Epoch 138/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0184\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0097\n",
            "\n",
            "Epoch 139/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0208\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "\n",
            "Epoch 140/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0163\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0165\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0165 - val_loss: 0.0097\n",
            "\n",
            "Epoch 141/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0251\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0176\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 0.0097\n",
            "\n",
            "Epoch 142/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0158\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.0097\n",
            "\n",
            "Epoch 143/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0160\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0175\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "\n",
            "Epoch 144/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0212\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0097\n",
            "\n",
            "Epoch 145/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0236\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0097\n",
            "\n",
            "Epoch 146/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0173\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "\n",
            "Epoch 147/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0186\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.0168\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - val_loss: 0.0097\n",
            "\n",
            "Epoch 148/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0225\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0097\n",
            "\n",
            "Epoch 149/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0131\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - val_loss: 0.0097\n",
            "\n",
            "Epoch 150/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0117\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0097\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 11s - loss: 0.1659\n",
            "8/8 [==============================] - 2s 36ms/step - loss: 0.1777 - val_loss: 0.0477\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1761\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1660 - val_loss: 0.0702\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1641\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1711 - val_loss: 0.0908\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1734\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1748 - val_loss: 0.1064\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1670\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1671 - val_loss: 0.1180\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1708\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1662 - val_loss: 0.1265\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1734\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - val_loss: 0.1317\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1257\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1561 - val_loss: 0.1351\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1619\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1690 - val_loss: 0.1374\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1582\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1674 - val_loss: 0.1398\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1913\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1592 - val_loss: 0.1423\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1526\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1544 - val_loss: 0.1442\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1489\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1553 - val_loss: 0.1445\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1812\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1572 - val_loss: 0.1436\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1225\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1655 - val_loss: 0.1441\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1716\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1618 - val_loss: 0.1439\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1632\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1572 - val_loss: 0.1433\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1515\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1617 - val_loss: 0.1420\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1775\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1516 - val_loss: 0.1407\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1399\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1501 - val_loss: 0.1396\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1493\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1524 - val_loss: 0.1393\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1535\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1497 - val_loss: 0.1383\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1359\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1431 - val_loss: 0.1371\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1402\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1456 - val_loss: 0.1361\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1324\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1416 - val_loss: 0.1354\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1308\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1369 - val_loss: 0.1347\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1473\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1494 - val_loss: 0.1339\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1090\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1355 - val_loss: 0.1323\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1584\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1430 - val_loss: 0.1313\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1559\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1433 - val_loss: 0.1303\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1278\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1388 - val_loss: 0.1283\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1356\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1432 - val_loss: 0.1276\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1502\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1397 - val_loss: 0.1269\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1548\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1388 - val_loss: 0.1256\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1392\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1368 - val_loss: 0.1243\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1155\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1261 - val_loss: 0.1234\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1591\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1399 - val_loss: 0.1228\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1385\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1420 - val_loss: 0.1226\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1311\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1383 - val_loss: 0.1225\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1267\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1290 - val_loss: 0.1216\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1398\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1349 - val_loss: 0.1212\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1263\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1254 - val_loss: 0.1207\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1079\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1337 - val_loss: 0.1207\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1551\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1290 - val_loss: 0.1200\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1288\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1333 - val_loss: 0.1191\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1193\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1270 - val_loss: 0.1181\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1413\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1279 - val_loss: 0.1172\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1244\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1237 - val_loss: 0.1170\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1246\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1190 - val_loss: 0.1162\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1195\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1294 - val_loss: 0.1157\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 1:01 - loss: 0.2404\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.1472  \n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.1223\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.1040\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0934\n",
            "60/60 [==============================] - 2s 8ms/step - loss: 0.0833 - val_loss: 0.0208\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0344\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0303\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0363\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0348\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0328\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0205\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0219\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0264\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0278\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0269\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0274\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0258\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0200\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0187\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0257\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0239\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0236\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0231\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0155\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0307\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0286\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0239\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0235\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0219\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0125\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0196\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0202\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0186\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0200\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0202\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0208 - val_loss: 0.0105\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0043\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0206\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0212\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0219\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0209\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0108\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 1s - loss: 0.0147\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0205\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0212\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0195\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0202\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0107\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0302\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0187\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0194\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0188\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0189\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0191\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0101\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0132\n",
            "10/60 [====>.........................] - ETA: 0s - loss: 0.0164\n",
            "21/60 [=========>....................] - ETA: 0s - loss: 0.0180\n",
            "31/60 [==============>...............] - ETA: 0s - loss: 0.0197\n",
            "41/60 [===================>..........] - ETA: 0s - loss: 0.0194\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0203\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0125\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0198\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0141\n",
            "21/60 [=========>....................] - ETA: 0s - loss: 0.0191\n",
            "32/60 [===============>..............] - ETA: 0s - loss: 0.0180\n",
            "42/60 [====================>.........] - ETA: 0s - loss: 0.0183\n",
            "52/60 [=========================>....] - ETA: 0s - loss: 0.0182\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0105\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0129\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0164\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0169\n",
            "33/60 [===============>..............] - ETA: 0s - loss: 0.0168\n",
            "42/60 [====================>.........] - ETA: 0s - loss: 0.0176\n",
            "53/60 [=========================>....] - ETA: 0s - loss: 0.0191\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0099\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0256\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0152\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0188\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0177\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0192\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0107\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0170\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0163\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0145\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0159\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0164\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0103\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0133\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0202\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0170\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0182\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0186\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.0194\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0101\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0324\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0175\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0199\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0179\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0172\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0171\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0109\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0324\n",
            "10/60 [====>.........................] - ETA: 0s - loss: 0.0186\n",
            "20/60 [=========>....................] - ETA: 0s - loss: 0.0179\n",
            "33/60 [===============>..............] - ETA: 0s - loss: 0.0164\n",
            "45/60 [=====================>........] - ETA: 0s - loss: 0.0174\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.0185\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0131\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0145\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0187\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0190\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0186\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0191\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0106\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0215\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0215\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0183\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0188\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0106\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0101\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0175\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0212\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0196\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0195\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0187\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0225\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0207\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0196\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0208\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0189\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0104\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0145\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0170\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0185\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0178\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0183\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0117\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0094\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0160\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0150\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0177\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0181\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0108\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0342\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0160\n",
            "27/60 [============>.................] - ETA: 0s - loss: 0.0156\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0162\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0170\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0121\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0571\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0197\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0198\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0189\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0177\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0128\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0134\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0181\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0162\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0192\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0181\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0110\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0145\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0194\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0181\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0193\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0188\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0186\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0112\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0183\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0165\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0181\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0168\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0166\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0105\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0182\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0146\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0170\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0169\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0176\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.0174\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0110\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0177\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0169\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0183\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0180\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0178\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0109\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0416\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0174\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0189\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0185\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0105\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0399\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0229\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0208\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0198\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0191\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0103\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0236\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0167\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0197\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0191\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0189\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0105\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0309\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0192\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0193\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0182\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0172\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.0182\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0105\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0171\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0173\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0156\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0161\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0169\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0130\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0198\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0156\n",
            "23/60 [==========>...................] - ETA: 0s - loss: 0.0185\n",
            "34/60 [================>.............] - ETA: 0s - loss: 0.0181\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0181\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0122\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0133\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0181\n",
            "26/60 [============>.................] - ETA: 0s - loss: 0.0175\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0170\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0161\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0113\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0171\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0212\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0193\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0179\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0111\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0062\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0189\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0195\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0182\n",
            "50/60 [========================>.....] - ETA: 0s - loss: 0.0177\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0180\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0102\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0140\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0182\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0185\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0196\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0182\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0104\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0055\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0158\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0158\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0179\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0114\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0096\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0163\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0182\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0176\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0169\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0102\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0183\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0173\n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.0165\n",
            "34/60 [================>.............] - ETA: 0s - loss: 0.0166\n",
            "47/60 [======================>.......] - ETA: 0s - loss: 0.0179\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0179\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0119\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0134\n",
            "13/60 [=====>........................] - ETA: 0s - loss: 0.0191\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0170\n",
            "35/60 [================>.............] - ETA: 0s - loss: 0.0174\n",
            "46/60 [======================>.......] - ETA: 0s - loss: 0.0160\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.0162\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0102\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0085\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0152\n",
            "27/60 [============>.................] - ETA: 0s - loss: 0.0150\n",
            "38/60 [==================>...........] - ETA: 0s - loss: 0.0173\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0170\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0129\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0349\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0199\n",
            "24/60 [===========>..................] - ETA: 0s - loss: 0.0178\n",
            "36/60 [=================>............] - ETA: 0s - loss: 0.0185\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0185\n",
            "60/60 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0126\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 1s - loss: 0.0043\n",
            "14/60 [======>.......................] - ETA: 0s - loss: 0.0162\n",
            "25/60 [===========>..................] - ETA: 0s - loss: 0.0169\n",
            "37/60 [=================>............] - ETA: 0s - loss: 0.0181\n",
            "49/60 [=======================>......] - ETA: 0s - loss: 0.0178\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.0176\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0104\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0149\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0153\n",
            "21/60 [=========>....................] - ETA: 0s - loss: 0.0139\n",
            "30/60 [==============>...............] - ETA: 0s - loss: 0.0163\n",
            "39/60 [==================>...........] - ETA: 0s - loss: 0.0177\n",
            "48/60 [=======================>......] - ETA: 0s - loss: 0.0178\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.0171\n",
            "60/60 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0103\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0139\n",
            "11/60 [====>.........................] - ETA: 0s - loss: 0.0177\n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.0172\n",
            "32/60 [===============>..............] - ETA: 0s - loss: 0.0165\n",
            "43/60 [====================>.........] - ETA: 0s - loss: 0.0188\n",
            "55/60 [==========================>...] - ETA: 0s - loss: 0.0186\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0106\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.0084\n",
            "12/60 [=====>........................] - ETA: 0s - loss: 0.0199\n",
            "22/60 [==========>...................] - ETA: 0s - loss: 0.0176\n",
            "32/60 [===============>..............] - ETA: 0s - loss: 0.0171\n",
            "41/60 [===================>..........] - ETA: 0s - loss: 0.0172\n",
            "51/60 [========================>.....] - ETA: 0s - loss: 0.0172\n",
            "60/60 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0113\n",
            "\n",
            "100%|██████████| 10/10 [02:34<00:00, 15.49s/it, best loss: 0.015570192597806454]\n",
            "Mejores hiperparámetros: {'Dropout': 0.3, 'batch_size': 32, 'epochs': 150, 'learning_rate': 0.001}\n",
            "Pérdida mínima: 0.015570192597806454\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "\n",
        "#Contruimos nuestro modelo que es nuesta función objetivo:\n",
        "\n",
        "def objetive(params):\n",
        "# Construir el modelo para datos numéricos densamente conectado\n",
        "  input_1 = Input(shape=(25,))\n",
        "\n",
        "\n",
        "  #Capa de entrada de datos con su batch normalization y dropout para evitar el sobreajuste\n",
        "  num_model = Dense(128, activation='relu')(input_1)\n",
        "  num_model = BatchNormalization()(num_model)\n",
        "  num_model = Dropout(params['Dropout'])(num_model)\n",
        "\n",
        "  num_model = Dense(64, activation='relu')(num_model)\n",
        "  num_model = BatchNormalization()(num_model)\n",
        "  num_model = Dropout(params['Dropout'])(num_model)\n",
        "\n",
        "  num_model = Dense(32, activation='relu')(num_model)\n",
        "  num_model = BatchNormalization()(num_model)\n",
        "  num_model = Dropout(params['Dropout'])(num_model)\n",
        "\n",
        "  num_model = Dense(16, activation='relu')(num_model)\n",
        "  num_model = BatchNormalization()(num_model)\n",
        "  num_model = Dropout(params['Dropout'])(num_model)\n",
        "\n",
        "  num_model = Dense(1, activation='sigmoid')(num_model)\n",
        "  num_model_final = Model(input_1, num_model)\n",
        "\n",
        "  num_model_final.compile(optimizer= Adam(learning_rate=params['learning_rate']), loss = 'mean_squared_error')\n",
        "  num_model_final.fit(X_train, y_train, validation_data = (X_validation, y_validation), shuffle = True, epochs = params['epochs'], batch_size = params['batch_size'])\n",
        "\n",
        "  loss = num_model_final.evaluate(X_test, y_test, verbose=0)\n",
        "  return {'loss': loss, 'status': STATUS_OK}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Definir el espacio de búsqueda de hiperparámetros\n",
        "space = {\n",
        "    'epochs': hp.choice('epochs', [50, 100, 150]),\n",
        "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
        "    'learning_rate': hp.choice('lr', [0.01, 0.001, 0.0001]),\n",
        "    'Dropout': hp.choice('Dropout',[ 0.3, 0.5])\n",
        "}\n",
        "\n",
        "# Configurar el algoritmo de optimización\n",
        "trials = Trials()\n",
        "best = fmin(fn=objetive,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10,\n",
        "            trials=trials)\n",
        "\n",
        "# Obtener los mejores hiperparámetros y la pérdida mínima\n",
        "best_params = hyperopt.space_eval(space, best)\n",
        "min_loss = trials.best_trial['result']['loss']\n",
        "\n",
        "\n",
        "# Imprimir los resultados\n",
        "print('Mejores hiperparámetros:', best_params)\n",
        "print('Pérdida mínima:', min_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC0f8KQDVWXm"
      },
      "source": [
        "**PROBAMOS NUESTRO MODELO CON LOS HIPERPARÁMETROS ÓPTIMOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFL2s1QhVVmH"
      },
      "outputs": [],
      "source": [
        "# Construir el modelo para datos numéricos densamente conectado\n",
        "input_1 = Input(shape=(25,))\n",
        "n_epochs = 150\n",
        "\n",
        "#Capa de entrada de datos con su batch normalization y dropout para evitar el sobreajuste\n",
        "num_model = Dense(128, activation='relu')(input_1)\n",
        "num_model = BatchNormalization()(num_model)\n",
        "num_model = Dropout(0.3)(num_model)\n",
        "\n",
        "num_model = Dense(64, activation='relu')(num_model)\n",
        "num_model = BatchNormalization()(num_model)\n",
        "num_model = Dropout(0.3)(num_model)\n",
        "\n",
        "num_model = Dense(32, activation='relu')(num_model)\n",
        "num_model = BatchNormalization()(num_model)\n",
        "num_model = Dropout(0.3)(num_model)\n",
        "\n",
        "num_model = Dense(16, activation='relu')(num_model)\n",
        "num_model = BatchNormalization()(num_model)\n",
        "num_model = Dropout(0.3)(num_model)\n",
        "\n",
        "num_model = Dense(1, activation='sigmoid')(num_model)\n",
        "num_model_final = Model(input_1, num_model)\n",
        "\n",
        "#Usaremos esta salida para el modelo híbrido\n",
        "\n",
        "num_model_1 = Model(input_1, num_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI5YOTIyXPVn",
        "outputId": "d30a1212-cbbb-4734-d977-3a60ee73615a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 1s 12ms/step - loss: 0.1320 - val_loss: 0.0763\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.1031 - val_loss: 0.0598\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0428\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.0298\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0624 - val_loss: 0.0199\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0500 - val_loss: 0.0159\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0480 - val_loss: 0.0143\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.0139\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0137\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.0134\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0132\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0128\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0322 - val_loss: 0.0126\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.0129\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.0127\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0121\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0121\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0122\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0120\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0115\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0120\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0125\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0121\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0113\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0115\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0116\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0116\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0114\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0111\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0110\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0111\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0105\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0103\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0101\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0101\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0106\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0102\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0105\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0109\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0104\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0104\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0103\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0107\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0103\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0103\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0106\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0103\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0103\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0099\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0100\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0100\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0099\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0101\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0100\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0104\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0104\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0105\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0105\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0103\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0103\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0100\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0102\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0104\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0101\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0099\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0100\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0100\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0102\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0101\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0105\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0101\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0102\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0103\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0104\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0102\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0101\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0101\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0103\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0108\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0106\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0106\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0104\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0104\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0105\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0105\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0106\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0107\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0109\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0109\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0111\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0107\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0108\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0102\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0104\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0102\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0104\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0100\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0105\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0102\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0100\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0109\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0105\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0100\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0104\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0103\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0100\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0107\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0105\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0098\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0101\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0102\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0102\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0103\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0102\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0102\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0105\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0112\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0102\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0112\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0108\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0102\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0100\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0104\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0106\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0105\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0105\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0105\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0108\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0103\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0101\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0102\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0101\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0104\n",
            "Epoch 134/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0108\n",
            "Epoch 135/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0101\n",
            "Epoch 136/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0115\n",
            "Epoch 137/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0111\n",
            "Epoch 138/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0103\n",
            "Epoch 139/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0108\n",
            "Epoch 140/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0102\n",
            "Epoch 141/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0108\n",
            "Epoch 142/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0109\n",
            "Epoch 143/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0107\n",
            "Epoch 144/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0100\n",
            "Epoch 145/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0100\n",
            "Epoch 146/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0107\n",
            "Epoch 147/150\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0106\n",
            "Epoch 148/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0107\n",
            "Epoch 149/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0105\n",
            "Epoch 150/150\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0113\n"
          ]
        }
      ],
      "source": [
        "num_model_final.compile(optimizer= Adam(lr=0.001), loss = 'mean_squared_error')\n",
        "Numeric_Model = num_model_final.fit(X_train, y_train, validation_data = (X_validation, y_validation), shuffle = True, epochs = n_epochs, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnFSEXdAuC_z",
        "outputId": "7076d0b4-9d0d-4cc7-bcdf-c8b40a877a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pérdida en el conjunto de prueba con los mejores hiperparámetros: 0.016830766573548317\n"
          ]
        }
      ],
      "source": [
        "#evaluar el modelo con los mejores hiperparámetros\n",
        "test_loss = num_model_final.evaluate(X_test, y_test, verbose=0)\n",
        "print('Pérdida en el conjunto de prueba con los mejores hiperparámetros:', test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "cGkYLeXcZ1wr",
        "outputId": "cb3003d7-1939-4765-d697-b4304e007004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4e90302040>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs), Numeric_Model.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs), Numeric_Model.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jU8GjKppRuk"
      },
      "source": [
        "**COMPROBAMOS LOS RESULTADOS DEL MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9VAtBoKa8_l",
        "outputId": "993b8027-dfac-47ff-d354-360c70425620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "Porcentaje medio de diferencia del GT: 25.32 % - Desviación típica: 25.32\n",
            "Error medio: 17.89€\n"
          ]
        }
      ],
      "source": [
        "# Métricas Modelo numérica 1D\n",
        "y_test_denorm = y_test * (y_reg.max() - y_reg.min()) + y_reg.min()\n",
        "y_pred_numeric = num_model_final.predict(X_test)\n",
        "y_pred_numeric_denorm = y_pred_numeric[:, 0] *  y_reg.max()\n",
        "diferencia_numeric = y_pred_numeric_denorm.flatten()- y_test_denorm\n",
        "porcentaje_diferencia_numeric = (diferencia_numeric / y_test_denorm) * 100\n",
        "abs_porcentaje_diferencia_numeric = np.abs(porcentaje_diferencia_numeric)\n",
        "\n",
        "error_denorm_numeric = np.abs(y_pred_numeric_denorm - y_test_denorm)\n",
        "mean_numeric = np.mean(abs_porcentaje_diferencia_numeric)\n",
        "\n",
        "\n",
        "print('Porcentaje medio de diferencia del GT: {0:.2f} % - Desviación típica: {0:.2f}'.format(mean_numeric ))\n",
        "print('Error medio: {0:.2f}€'.format(error_denorm_numeric.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da2vMy-dHUfu"
      },
      "source": [
        "**RESUMEN**\n",
        "\n",
        "Vemos que usando los hiperparámetros dados por el optimizador obtenemos muy buenos resultados con un error de medio 17,89€ y una diferencia del 25% del GT. Para solo 1500 entradas pienso que el resultado es más que decente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz3MqeiULi6L"
      },
      "source": [
        "**CREAMOS EL MODELO PARA LAS IMÁGENES 1D**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxjy3XYnz-a-",
        "outputId": "170ba65a-6c62-44a2-d21e-67f0c306debd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del dataset de training: (960, 224, 224, 3)\n",
            "Dimensiones del dataset de df_validation: (240, 224, 224, 3)\n",
            "Dimensiones del dataset de test: (300, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "df_img, test_img = train_test_split(images, test_size=0.2,  random_state=42)\n",
        "train_img, validation_img = train_test_split(df_img, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(f'Dimensiones del dataset de training: {train_img.shape}')\n",
        "print(f'Dimensiones del dataset de df_validation: {validation_img.shape}')\n",
        "print(f'Dimensiones del dataset de test: {test_img.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--JrqANEwMp_",
        "outputId": "a4454a05-b856-4bde-96d1-38b007545bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(960, 48, 48, 3)\n",
            "(240, 48, 48, 3)\n",
            "(300, 48, 48, 3)\n"
          ]
        }
      ],
      "source": [
        "#Redimensiono las imagenes para poder usar la red preentrenada y normalizamos\n",
        "\n",
        "input_shape = (48, 48, 3)\n",
        "\n",
        "\n",
        "# resize train set\n",
        "X_train_resized = []\n",
        "for img in train_img:\n",
        "  X_train_resized.append(np.resize(img, input_shape) / 255)\n",
        "\n",
        "X_train_resized = np.array(X_train_resized)\n",
        "print(X_train_resized.shape)\n",
        "\n",
        "# resize validation set\n",
        "X_validation_resized = []\n",
        "for img in validation_img:\n",
        "  X_validation_resized.append(np.resize(img, input_shape) / 255)\n",
        "\n",
        "X_validation_resized = np.array(X_validation_resized)\n",
        "print(X_validation_resized.shape)\n",
        "\n",
        "\n",
        "# resize test set\n",
        "X_test_resized = []\n",
        "for img in test_img:\n",
        "  X_test_resized.append(np.resize(img, input_shape) / 255)\n",
        "\n",
        "X_test_resized = np.array(X_test_resized)\n",
        "print(X_test_resized.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckv6-DYq9p95"
      },
      "source": [
        "**Buscamos los mejores parámetros para las imagenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njVGIvSJlimJ",
        "outputId": "0acf6856-344f-4b63-dc16-6d9b8eb17917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2938\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 17/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1544 - mean_absolute_error: 0.3058\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.3006\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2910\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1137 - mean_absolute_error: 0.2876\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 18/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.2595\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1095 - mean_absolute_error: 0.2881\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.2927\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.2926\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 19/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1055 - mean_absolute_error: 0.2788\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2989\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1166 - mean_absolute_error: 0.2937\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2944\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 20/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1343 - mean_absolute_error: 0.3152\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2916\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1263 - mean_absolute_error: 0.3005\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2931\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 21/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1019 - mean_absolute_error: 0.2651\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2985\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2971\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2950\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2942\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 22/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1064 - mean_absolute_error: 0.2792\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1254 - mean_absolute_error: 0.2971\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2970\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2965\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 23/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1048 - mean_absolute_error: 0.2827\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1062 - mean_absolute_error: 0.2817\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1113 - mean_absolute_error: 0.2860\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1150 - mean_absolute_error: 0.2888\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2944\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 24/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0983 - mean_absolute_error: 0.2548\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2868\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2912\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2958\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2942\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 25/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1099 - mean_absolute_error: 0.2958\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2862\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2931\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2961\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 26/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1350 - mean_absolute_error: 0.3019\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1271 - mean_absolute_error: 0.3022\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2966\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1246 - mean_absolute_error: 0.3003\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 27/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1366 - mean_absolute_error: 0.3188\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1119 - mean_absolute_error: 0.2816\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.2894\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2922\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 28/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2873\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1153 - mean_absolute_error: 0.2879\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2915\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2898\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2922\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 29/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.2715\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1146 - mean_absolute_error: 0.2901\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2948\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1234 - mean_absolute_error: 0.3003\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2967\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 30/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1077 - mean_absolute_error: 0.2875\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1242 - mean_absolute_error: 0.3038\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2967\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2963\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 31/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1513 - mean_absolute_error: 0.3417\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1113 - mean_absolute_error: 0.2849\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1172 - mean_absolute_error: 0.2901\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2942\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 32/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1060 - mean_absolute_error: 0.2824\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2943\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2948\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2951\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2955\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 33/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1027 - mean_absolute_error: 0.2689\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.2997\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.1282 - mean_absolute_error: 0.3023\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2969\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2957\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 34/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.2367\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2915\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1175 - mean_absolute_error: 0.2930\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1190 - mean_absolute_error: 0.2962\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 35/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1399 - mean_absolute_error: 0.3152\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2950\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2941\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2910\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 36/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0817 - mean_absolute_error: 0.2458\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1234 - mean_absolute_error: 0.2925\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2904\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2975\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2962\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 37/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1001 - mean_absolute_error: 0.2691\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.3035\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2869\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1116 - mean_absolute_error: 0.2873\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2904\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 38/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1427 - mean_absolute_error: 0.3372\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.3048\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.3003\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2973\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 39/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2880\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1098 - mean_absolute_error: 0.2786\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2946\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2937\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 40/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.3091\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2952\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2918\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2940\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 41/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0766 - mean_absolute_error: 0.2179\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.2915\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1226 - mean_absolute_error: 0.2989\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2948\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 42/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1149 - mean_absolute_error: 0.2776\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1080 - mean_absolute_error: 0.2822\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.2862\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2913\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 43/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2909\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1363 - mean_absolute_error: 0.3097\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1327 - mean_absolute_error: 0.3069\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2974\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2954\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 44/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0947 - mean_absolute_error: 0.2766\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1249 - mean_absolute_error: 0.2981\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1263 - mean_absolute_error: 0.3017\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.2977\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 45/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0808 - mean_absolute_error: 0.2505\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1282 - mean_absolute_error: 0.3029\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2956\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2966\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2957\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 46/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0946 - mean_absolute_error: 0.2644\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1247 - mean_absolute_error: 0.2921\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2867\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2963\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2959\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 47/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1693 - mean_absolute_error: 0.3325\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1275 - mean_absolute_error: 0.3001\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2925\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2932\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 48/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1287 - mean_absolute_error: 0.3051\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.3004\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2971\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2961\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 49/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1299 - mean_absolute_error: 0.3048\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1097 - mean_absolute_error: 0.2782\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1111 - mean_absolute_error: 0.2864\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.2881\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1179 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 50/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1319 - mean_absolute_error: 0.3194\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2960\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1253 - mean_absolute_error: 0.3004\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2945\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2937\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 51/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1013 - mean_absolute_error: 0.2838\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1336 - mean_absolute_error: 0.3153\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.3006\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2922\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 52/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2816\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2908\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1141 - mean_absolute_error: 0.2875\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2899\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2939\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 53/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1234 - mean_absolute_error: 0.2963\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1229 - mean_absolute_error: 0.2980\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2938\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.2882\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 54/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.3072\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1329 - mean_absolute_error: 0.3056\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2973\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2946\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 55/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2753\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1135 - mean_absolute_error: 0.2894\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2928\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2954\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 56/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0991 - mean_absolute_error: 0.2739\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1097 - mean_absolute_error: 0.2879\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2989\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1160 - mean_absolute_error: 0.2906\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 57/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1304 - mean_absolute_error: 0.3027\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2913\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2958\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2958\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 58/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0943 - mean_absolute_error: 0.2644\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2933\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2932\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1172 - mean_absolute_error: 0.2913\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 59/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2902\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1308 - mean_absolute_error: 0.3065\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1253 - mean_absolute_error: 0.3037\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2929\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 60/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1368 - mean_absolute_error: 0.3192\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3020\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1166 - mean_absolute_error: 0.2910\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.2906\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 61/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1841 - mean_absolute_error: 0.3615\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1334 - mean_absolute_error: 0.3095\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.3044\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1271 - mean_absolute_error: 0.3021\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 62/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1327 - mean_absolute_error: 0.3008\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1399 - mean_absolute_error: 0.3160\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2983\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2967\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 63/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2944\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2913\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.2829\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1146 - mean_absolute_error: 0.2871\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 64/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1219 - mean_absolute_error: 0.3002\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1084 - mean_absolute_error: 0.2837\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2926\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2943\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 65/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.2917\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.2892\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1106 - mean_absolute_error: 0.2859\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1153 - mean_absolute_error: 0.2885\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 66/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1444 - mean_absolute_error: 0.3037\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1276 - mean_absolute_error: 0.3024\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2990\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2943\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 67/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2824\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2944\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.3009\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2991\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 68/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1055 - mean_absolute_error: 0.2845\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2902\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.2850\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2955\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 69/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0903 - mean_absolute_error: 0.2699\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2966\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2955\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2972\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 70/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1099 - mean_absolute_error: 0.2776\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2896\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2940\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2925\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 71/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.3021\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1262 - mean_absolute_error: 0.3019\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2965\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 72/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0766 - mean_absolute_error: 0.2478\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1362 - mean_absolute_error: 0.3112\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1297 - mean_absolute_error: 0.3053\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2959\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1190 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 73/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0715 - mean_absolute_error: 0.2324\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2868\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2941\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2955\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2953\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 74/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1331 - mean_absolute_error: 0.3212\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1118 - mean_absolute_error: 0.2881\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1162 - mean_absolute_error: 0.2928\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.2927\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 75/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1392 - mean_absolute_error: 0.3205\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2931\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.2866\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2902\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2951\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 76/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1002 - mean_absolute_error: 0.2824\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1090 - mean_absolute_error: 0.2786\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2890\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2904\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 77/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1153 - mean_absolute_error: 0.2851\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1075 - mean_absolute_error: 0.2804\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1092 - mean_absolute_error: 0.2826\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2924\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 78/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1020 - mean_absolute_error: 0.2758\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1262 - mean_absolute_error: 0.3002\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2909\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1169 - mean_absolute_error: 0.2895\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 79/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2965\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1230 - mean_absolute_error: 0.2998\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2913\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2908\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 80/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3087\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1285 - mean_absolute_error: 0.3056\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.1229 - mean_absolute_error: 0.2981\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2965\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2963\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 81/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1517 - mean_absolute_error: 0.3192\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1119 - mean_absolute_error: 0.2815\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.2965\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2955\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2946\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 82/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1371 - mean_absolute_error: 0.3197\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.3007\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2963\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1166 - mean_absolute_error: 0.2898\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1190 - mean_absolute_error: 0.2930\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 83/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0844 - mean_absolute_error: 0.2466\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1120 - mean_absolute_error: 0.2853\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2916\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2933\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 84/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0913 - mean_absolute_error: 0.2521\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1157 - mean_absolute_error: 0.2893\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2953\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2968\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2950\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 85/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1580 - mean_absolute_error: 0.3332\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1281 - mean_absolute_error: 0.3016\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2961\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2915\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 86/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1626 - mean_absolute_error: 0.3369\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.2885\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2957\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.2988\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2967\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 87/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1408 - mean_absolute_error: 0.3109\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2887\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2912\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2949\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 88/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1375 - mean_absolute_error: 0.3194\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.3041\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2932\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2912\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2943\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 89/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0970 - mean_absolute_error: 0.2777\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1083 - mean_absolute_error: 0.2801\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1160 - mean_absolute_error: 0.2879\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2935\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2943\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 90/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1769 - mean_absolute_error: 0.3534\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2921\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2892\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2907\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 91/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0840 - mean_absolute_error: 0.2559\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2912\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2952\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2939\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 92/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2989\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1099 - mean_absolute_error: 0.2855\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1151 - mean_absolute_error: 0.2909\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1146 - mean_absolute_error: 0.2894\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 93/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0902 - mean_absolute_error: 0.2700\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2947\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2949\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1229 - mean_absolute_error: 0.2971\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 94/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1286 - mean_absolute_error: 0.3091\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2948\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2979\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2945\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 95/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1656 - mean_absolute_error: 0.3569\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2966\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2924\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2927\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 96/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2954\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2887\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2983\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2984\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2952\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 97/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1653 - mean_absolute_error: 0.3401\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2925\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.3024\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2972\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2964\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 98/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1605 - mean_absolute_error: 0.3407\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.3009\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1314 - mean_absolute_error: 0.3061\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1262 - mean_absolute_error: 0.3012\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 99/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1385 - mean_absolute_error: 0.3189\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2993\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2958\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2953\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 100/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0750 - mean_absolute_error: 0.2369\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1355 - mean_absolute_error: 0.3175\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1283 - mean_absolute_error: 0.3027\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1254 - mean_absolute_error: 0.3016\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2938\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 101/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3085\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1272 - mean_absolute_error: 0.3069\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.3040\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 102/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1095 - mean_absolute_error: 0.2744\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2953\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1253 - mean_absolute_error: 0.3045\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.3005\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 103/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1393 - mean_absolute_error: 0.3397\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2949\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1282 - mean_absolute_error: 0.3011\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2962\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2933\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 104/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0961 - mean_absolute_error: 0.2723\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2912\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1255 - mean_absolute_error: 0.3011\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2954\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2948\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 105/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0855 - mean_absolute_error: 0.2447\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2971\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3012\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2958\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 106/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1090 - mean_absolute_error: 0.2643\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1048 - mean_absolute_error: 0.2726\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2897\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2947\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2952\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 107/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1042 - mean_absolute_error: 0.2851\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1241 - mean_absolute_error: 0.3004\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2946\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2961\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 108/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1000 - mean_absolute_error: 0.2673\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2894\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2897\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2957\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 109/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1671 - mean_absolute_error: 0.3550\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1380 - mean_absolute_error: 0.3198\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2972\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2939\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2957\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 110/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2973\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1062 - mean_absolute_error: 0.2785\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1172 - mean_absolute_error: 0.2924\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2917\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 111/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1601 - mean_absolute_error: 0.3444\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1434 - mean_absolute_error: 0.3225\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1283 - mean_absolute_error: 0.3054\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2951\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 112/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1933 - mean_absolute_error: 0.3522\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1306 - mean_absolute_error: 0.3050\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2905\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2932\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 113/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0908 - mean_absolute_error: 0.2627\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1142 - mean_absolute_error: 0.2864\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1113 - mean_absolute_error: 0.2862\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.2891\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2952\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 114/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0779 - mean_absolute_error: 0.2550\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1086 - mean_absolute_error: 0.2816\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2952\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1228 - mean_absolute_error: 0.2975\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2950\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 115/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0851 - mean_absolute_error: 0.2420\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1095 - mean_absolute_error: 0.2834\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.2887\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2965\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2941\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 116/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1318 - mean_absolute_error: 0.3088\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1071 - mean_absolute_error: 0.2757\n",
            "13/30 [============>.................] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.2959\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1240 - mean_absolute_error: 0.2990\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2960\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 117/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0831 - mean_absolute_error: 0.2587\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2866\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2924\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1151 - mean_absolute_error: 0.2899\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 118/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1179 - mean_absolute_error: 0.2915\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2906\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2948\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2985\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2938\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 119/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1024 - mean_absolute_error: 0.2739\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2920\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2898\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2949\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 120/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.2785\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.1347 - mean_absolute_error: 0.3092\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1145 - mean_absolute_error: 0.2890\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2947\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2968\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 121/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0754 - mean_absolute_error: 0.2439\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1275 - mean_absolute_error: 0.3048\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1244 - mean_absolute_error: 0.3007\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.1228 - mean_absolute_error: 0.2980\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2988\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 122/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1117 - mean_absolute_error: 0.2957\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2898\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.2829\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2912\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2954\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 123/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1084 - mean_absolute_error: 0.2867\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1268 - mean_absolute_error: 0.3108\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1265 - mean_absolute_error: 0.3036\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1273 - mean_absolute_error: 0.3038\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2940\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 124/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1312 - mean_absolute_error: 0.3135\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1321 - mean_absolute_error: 0.3083\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2983\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2963\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 125/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1014 - mean_absolute_error: 0.2684\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3017\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.2975\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3007\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2957\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 126/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1040 - mean_absolute_error: 0.2707\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.2857\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2935\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2905\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 127/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1373 - mean_absolute_error: 0.3139\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1344 - mean_absolute_error: 0.3083\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1244 - mean_absolute_error: 0.2991\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2937\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 128/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.2973\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1274 - mean_absolute_error: 0.3056\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1170 - mean_absolute_error: 0.2922\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2920\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 129/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1105 - mean_absolute_error: 0.2756\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2973\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1266 - mean_absolute_error: 0.3042\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1228 - mean_absolute_error: 0.2991\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 130/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.3215\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.3037\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2983\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2979\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 131/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0983 - mean_absolute_error: 0.2796\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1298 - mean_absolute_error: 0.3052\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3006\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1234 - mean_absolute_error: 0.2989\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 132/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0787 - mean_absolute_error: 0.2397\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1268 - mean_absolute_error: 0.3038\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1251 - mean_absolute_error: 0.2999\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2945\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2935\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 133/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1028 - mean_absolute_error: 0.2798\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1320 - mean_absolute_error: 0.3088\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2954\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2971\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2951\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 134/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1526 - mean_absolute_error: 0.3268\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1369 - mean_absolute_error: 0.3093\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1239 - mean_absolute_error: 0.2966\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2924\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 135/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1025 - mean_absolute_error: 0.2728\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.2984\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2980\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2980\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 136/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1175 - mean_absolute_error: 0.3141\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1228 - mean_absolute_error: 0.2968\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2899\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2973\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2967\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 137/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1468 - mean_absolute_error: 0.3128\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.2959\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2939\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.1190 - mean_absolute_error: 0.2944\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 138/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1754 - mean_absolute_error: 0.3439\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1291 - mean_absolute_error: 0.3092\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2954\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1169 - mean_absolute_error: 0.2913\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 139/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1005 - mean_absolute_error: 0.2503\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.3011\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1275 - mean_absolute_error: 0.3009\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2971\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2948\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 140/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1789 - mean_absolute_error: 0.3495\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1261 - mean_absolute_error: 0.2989\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1276 - mean_absolute_error: 0.3013\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1254 - mean_absolute_error: 0.2999\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1223 - mean_absolute_error: 0.2975\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 141/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2952\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2921\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2911\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2948\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 142/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1675 - mean_absolute_error: 0.3365\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2954\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2952\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2909\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 143/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1228 - mean_absolute_error: 0.3045\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2980\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2936\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2926\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 144/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.2689\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1261 - mean_absolute_error: 0.3018\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2947\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1223 - mean_absolute_error: 0.2973\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2951\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 145/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1635 - mean_absolute_error: 0.3245\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2996\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1293 - mean_absolute_error: 0.3054\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2995\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 146/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1048 - mean_absolute_error: 0.2744\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.1293 - mean_absolute_error: 0.3055\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2937\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2945\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 147/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.2543\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1242 - mean_absolute_error: 0.2985\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2931\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2984\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 148/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0932 - mean_absolute_error: 0.2575\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1114 - mean_absolute_error: 0.2845\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2934\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2905\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2934\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 149/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1324 - mean_absolute_error: 0.3163\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.3055\n",
            "14/30 [=============>................] - ETA: 0s - loss: 0.1242 - mean_absolute_error: 0.3029\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.1230 - mean_absolute_error: 0.2991\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2940\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 150/150\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.2955\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2812\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2958\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.1251 - mean_absolute_error: 0.3006\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 1/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 9s - loss: 0.0678 - mean_absolute_error: 0.2274\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0565 - mean_absolute_error: 0.2098\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0539 - mean_absolute_error: 0.2016\n",
            "15/15 [==============================] - 1s 25ms/step - loss: 0.0539 - mean_absolute_error: 0.2016 - val_loss: 0.0567 - val_mean_absolute_error: 0.2133\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1776\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1559\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1523\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0375 - mean_absolute_error: 0.1516 - val_loss: 0.0475 - val_mean_absolute_error: 0.1931\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0436 - mean_absolute_error: 0.1566\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1409\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1505\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0379 - mean_absolute_error: 0.1521 - val_loss: 0.0526 - val_mean_absolute_error: 0.2045\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0434 - mean_absolute_error: 0.1702\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1635\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1550\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0372 - mean_absolute_error: 0.1534 - val_loss: 0.0521 - val_mean_absolute_error: 0.2033\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1413\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1505\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1517\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0370 - mean_absolute_error: 0.1512 - val_loss: 0.0504 - val_mean_absolute_error: 0.1995\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1570\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1556\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1520\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0370 - mean_absolute_error: 0.1516 - val_loss: 0.0505 - val_mean_absolute_error: 0.1997\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1515\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1559\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1537\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0369 - mean_absolute_error: 0.1517 - val_loss: 0.0509 - val_mean_absolute_error: 0.2007\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.1514\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1456\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1496\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0366 - mean_absolute_error: 0.1499 - val_loss: 0.0495 - val_mean_absolute_error: 0.1974\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0267 - mean_absolute_error: 0.1356\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1449\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1502\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0364 - mean_absolute_error: 0.1507 - val_loss: 0.0494 - val_mean_absolute_error: 0.1972\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1390\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0369 - mean_absolute_error: 0.1487\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1487\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0351 - mean_absolute_error: 0.1471 - val_loss: 0.0489 - val_mean_absolute_error: 0.1961\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0469 - mean_absolute_error: 0.1689\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0370 - mean_absolute_error: 0.1488\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1478\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0351 - mean_absolute_error: 0.1467 - val_loss: 0.0481 - val_mean_absolute_error: 0.1943\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1345\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1477\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1455\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.0347 - mean_absolute_error: 0.1451 - val_loss: 0.0473 - val_mean_absolute_error: 0.1923\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1427\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0377 - mean_absolute_error: 0.1522\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1477\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1466\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0346 - mean_absolute_error: 0.1466 - val_loss: 0.0482 - val_mean_absolute_error: 0.1944\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1528\n",
            " 4/15 [=======>......................] - ETA: 0s - loss: 0.0399 - mean_absolute_error: 0.1548\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1502\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1432\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1450\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0348 - mean_absolute_error: 0.1450 - val_loss: 0.0456 - val_mean_absolute_error: 0.1884\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1399\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1430\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1459\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0351 - mean_absolute_error: 0.1466 - val_loss: 0.0474 - val_mean_absolute_error: 0.1926\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1406\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1528\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1453\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0345 - mean_absolute_error: 0.1464 - val_loss: 0.0459 - val_mean_absolute_error: 0.1890\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1462\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1517\n",
            " 9/15 [=================>............] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1482\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1458\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.0346 - mean_absolute_error: 0.1457 - val_loss: 0.0460 - val_mean_absolute_error: 0.1893\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0510 - mean_absolute_error: 0.1705\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1415\n",
            "10/15 [===================>..........] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1406\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1422\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.0341 - mean_absolute_error: 0.1436 - val_loss: 0.0443 - val_mean_absolute_error: 0.1850\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1270\n",
            " 4/15 [=======>......................] - ETA: 0s - loss: 0.0391 - mean_absolute_error: 0.1473\n",
            "10/15 [===================>..........] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1430\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0337 - mean_absolute_error: 0.1427 - val_loss: 0.0451 - val_mean_absolute_error: 0.1870\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1534\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1436\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1421\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0341 - mean_absolute_error: 0.1437 - val_loss: 0.0438 - val_mean_absolute_error: 0.1837\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1422\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1344\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1441\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0337 - mean_absolute_error: 0.1421 - val_loss: 0.0446 - val_mean_absolute_error: 0.1858\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1499\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1448\n",
            " 9/15 [=================>............] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1433\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1439\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0340 - mean_absolute_error: 0.1435 - val_loss: 0.0441 - val_mean_absolute_error: 0.1845\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0433 - mean_absolute_error: 0.1548\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1420\n",
            " 9/15 [=================>............] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1449\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1434\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.0335 - mean_absolute_error: 0.1416 - val_loss: 0.0421 - val_mean_absolute_error: 0.1794\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0520 - mean_absolute_error: 0.1697\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1459\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1429\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0335 - mean_absolute_error: 0.1427 - val_loss: 0.0432 - val_mean_absolute_error: 0.1822\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0263 - mean_absolute_error: 0.1323\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1447\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1432\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0337 - mean_absolute_error: 0.1428 - val_loss: 0.0421 - val_mean_absolute_error: 0.1793\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1624\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1403\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1433\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0331 - mean_absolute_error: 0.1424 - val_loss: 0.0425 - val_mean_absolute_error: 0.1805\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0185 - mean_absolute_error: 0.1140\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1332\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1379\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0334 - mean_absolute_error: 0.1402 - val_loss: 0.0414 - val_mean_absolute_error: 0.1775\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0218 - mean_absolute_error: 0.1238\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1412\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1421\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.0331 - mean_absolute_error: 0.1415 - val_loss: 0.0420 - val_mean_absolute_error: 0.1791\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1281\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1414\n",
            "10/15 [===================>..........] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1419\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1423\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0332 - mean_absolute_error: 0.1423 - val_loss: 0.0409 - val_mean_absolute_error: 0.1765\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1372\n",
            " 4/15 [=======>......................] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1410\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1410\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1422\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.0335 - mean_absolute_error: 0.1431 - val_loss: 0.0404 - val_mean_absolute_error: 0.1752\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0383 - mean_absolute_error: 0.1538\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1453\n",
            "10/15 [===================>..........] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1438\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0336 - mean_absolute_error: 0.1422 - val_loss: 0.0405 - val_mean_absolute_error: 0.1755\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1500\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1418\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1409\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0327 - mean_absolute_error: 0.1407 - val_loss: 0.0396 - val_mean_absolute_error: 0.1733\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1427\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1347\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1378\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0333 - mean_absolute_error: 0.1417 - val_loss: 0.0392 - val_mean_absolute_error: 0.1722\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0472 - mean_absolute_error: 0.1633\n",
            " 5/15 [=========>....................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1392\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1387\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1428\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1407\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0331 - mean_absolute_error: 0.1407 - val_loss: 0.0388 - val_mean_absolute_error: 0.1712\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1384\n",
            " 4/15 [=======>......................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1438\n",
            " 9/15 [=================>............] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1333\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1413\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.0332 - mean_absolute_error: 0.1420 - val_loss: 0.0389 - val_mean_absolute_error: 0.1715\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0437 - mean_absolute_error: 0.1620\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1470\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1380\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0327 - mean_absolute_error: 0.1398 - val_loss: 0.0381 - val_mean_absolute_error: 0.1692\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.1143\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1364\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1376\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0329 - mean_absolute_error: 0.1398 - val_loss: 0.0381 - val_mean_absolute_error: 0.1693\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0493 - mean_absolute_error: 0.1719\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1392\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1412\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0327 - mean_absolute_error: 0.1410 - val_loss: 0.0378 - val_mean_absolute_error: 0.1687\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.1227\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1394\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1410\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0331 - mean_absolute_error: 0.1401 - val_loss: 0.0369 - val_mean_absolute_error: 0.1661\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0466 - mean_absolute_error: 0.1574\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1474\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1418\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0330 - mean_absolute_error: 0.1408 - val_loss: 0.0366 - val_mean_absolute_error: 0.1656\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1404\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1375\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1415\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0330 - mean_absolute_error: 0.1411 - val_loss: 0.0363 - val_mean_absolute_error: 0.1647\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0401 - mean_absolute_error: 0.1542\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1395\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1408\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0327 - mean_absolute_error: 0.1394 - val_loss: 0.0359 - val_mean_absolute_error: 0.1637\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1486\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1401\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1402\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0327 - mean_absolute_error: 0.1399 - val_loss: 0.0369 - val_mean_absolute_error: 0.1663\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1502\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1368\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1425\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0323 - mean_absolute_error: 0.1397 - val_loss: 0.0346 - val_mean_absolute_error: 0.1602\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1143\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1346\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1401\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0330 - mean_absolute_error: 0.1393 - val_loss: 0.0364 - val_mean_absolute_error: 0.1652\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1232\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1348\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1408\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0329 - mean_absolute_error: 0.1414 - val_loss: 0.0344 - val_mean_absolute_error: 0.1595\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0252 - mean_absolute_error: 0.1265\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1361\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1414\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0327 - mean_absolute_error: 0.1396 - val_loss: 0.0343 - val_mean_absolute_error: 0.1594\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0219 - mean_absolute_error: 0.1180\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1318\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1356\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0323 - mean_absolute_error: 0.1386 - val_loss: 0.0340 - val_mean_absolute_error: 0.1585\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1271\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1298\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1388\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0321 - mean_absolute_error: 0.1384 - val_loss: 0.0346 - val_mean_absolute_error: 0.1603\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0205 - mean_absolute_error: 0.1166\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1334\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1372\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0326 - mean_absolute_error: 0.1388 - val_loss: 0.0339 - val_mean_absolute_error: 0.1583\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1493\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1440\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1405\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0322 - mean_absolute_error: 0.1402 - val_loss: 0.0341 - val_mean_absolute_error: 0.1589\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1377\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1354\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1348\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0322 - mean_absolute_error: 0.1363 - val_loss: 0.0330 - val_mean_absolute_error: 0.1558\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0408 - mean_absolute_error: 0.1488\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1464\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1403\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0322 - mean_absolute_error: 0.1397 - val_loss: 0.0336 - val_mean_absolute_error: 0.1574\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0184 - mean_absolute_error: 0.1051\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1421\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1379\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0323 - mean_absolute_error: 0.1396 - val_loss: 0.0333 - val_mean_absolute_error: 0.1566\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0416 - mean_absolute_error: 0.1486\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1359\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1349\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0320 - mean_absolute_error: 0.1372 - val_loss: 0.0329 - val_mean_absolute_error: 0.1555\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1383\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.1293\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1394\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0321 - mean_absolute_error: 0.1394 - val_loss: 0.0335 - val_mean_absolute_error: 0.1573\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1395\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1446\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1387\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0320 - mean_absolute_error: 0.1389 - val_loss: 0.0321 - val_mean_absolute_error: 0.1530\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0263 - mean_absolute_error: 0.1282\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1353\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1342\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0317 - mean_absolute_error: 0.1357 - val_loss: 0.0329 - val_mean_absolute_error: 0.1555\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1377\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1429\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1405\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0318 - mean_absolute_error: 0.1383 - val_loss: 0.0320 - val_mean_absolute_error: 0.1529\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0451 - mean_absolute_error: 0.1711\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1392\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1373\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0318 - mean_absolute_error: 0.1380 - val_loss: 0.0325 - val_mean_absolute_error: 0.1544\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0402 - mean_absolute_error: 0.1541\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1409\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1356\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0317 - mean_absolute_error: 0.1371 - val_loss: 0.0315 - val_mean_absolute_error: 0.1511\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1432\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1349\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1365\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0319 - mean_absolute_error: 0.1374 - val_loss: 0.0328 - val_mean_absolute_error: 0.1553\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1581\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1403\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1408\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.0316 - mean_absolute_error: 0.1376 - val_loss: 0.0317 - val_mean_absolute_error: 0.1519\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.1229\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1347\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1345\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0318 - mean_absolute_error: 0.1371 - val_loss: 0.0320 - val_mean_absolute_error: 0.1527\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.1222\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1385\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1370\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0320 - mean_absolute_error: 0.1373 - val_loss: 0.0318 - val_mean_absolute_error: 0.1522\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0514 - mean_absolute_error: 0.1549\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1493\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1400\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0318 - mean_absolute_error: 0.1389 - val_loss: 0.0311 - val_mean_absolute_error: 0.1502\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1352\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1357\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1351\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0317 - mean_absolute_error: 0.1355 - val_loss: 0.0322 - val_mean_absolute_error: 0.1536\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0449 - mean_absolute_error: 0.1699\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1457\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1407\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0317 - mean_absolute_error: 0.1397 - val_loss: 0.0311 - val_mean_absolute_error: 0.1499\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.1096\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1368\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1358\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0314 - mean_absolute_error: 0.1353 - val_loss: 0.0318 - val_mean_absolute_error: 0.1523\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.1399\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1346\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1381\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0316 - mean_absolute_error: 0.1375 - val_loss: 0.0301 - val_mean_absolute_error: 0.1469\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1328\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1318\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1373\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0315 - mean_absolute_error: 0.1368 - val_loss: 0.0314 - val_mean_absolute_error: 0.1512\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.1230\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1385\n",
            "11/15 [=====================>........] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1400\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.0316 - mean_absolute_error: 0.1376 - val_loss: 0.0315 - val_mean_absolute_error: 0.1514\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1400\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1335\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1359\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0315 - mean_absolute_error: 0.1367 - val_loss: 0.0309 - val_mean_absolute_error: 0.1492\n",
            "\n",
            "Epoch 74/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.1257\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1373\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1403\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0316 - mean_absolute_error: 0.1385 - val_loss: 0.0309 - val_mean_absolute_error: 0.1493\n",
            "\n",
            "Epoch 75/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0287 - mean_absolute_error: 0.1319\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1344\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1338\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0311 - mean_absolute_error: 0.1350 - val_loss: 0.0311 - val_mean_absolute_error: 0.1500\n",
            "\n",
            "Epoch 76/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1401\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1376\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1367\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_absolute_error: 0.1362 - val_loss: 0.0317 - val_mean_absolute_error: 0.1521\n",
            "\n",
            "Epoch 77/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0417 - mean_absolute_error: 0.1502\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1435\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1384\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0311 - mean_absolute_error: 0.1373 - val_loss: 0.0297 - val_mean_absolute_error: 0.1453\n",
            "\n",
            "Epoch 78/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.1209\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1310\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1379\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1349 - val_loss: 0.0328 - val_mean_absolute_error: 0.1555\n",
            "\n",
            "Epoch 79/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1409\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1401\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1381\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0317 - mean_absolute_error: 0.1381 - val_loss: 0.0297 - val_mean_absolute_error: 0.1457\n",
            "\n",
            "Epoch 80/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.1143\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1300\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1348\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0310 - mean_absolute_error: 0.1355 - val_loss: 0.0313 - val_mean_absolute_error: 0.1508\n",
            "\n",
            "Epoch 81/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.1179\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1339\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1371\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_absolute_error: 0.1357 - val_loss: 0.0305 - val_mean_absolute_error: 0.1482\n",
            "\n",
            "Epoch 82/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1427\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1379\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1387\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1380 - val_loss: 0.0299 - val_mean_absolute_error: 0.1461\n",
            "\n",
            "Epoch 83/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1658\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1367\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1369\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0312 - mean_absolute_error: 0.1371 - val_loss: 0.0304 - val_mean_absolute_error: 0.1479\n",
            "\n",
            "Epoch 84/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.1270\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1335\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1364\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_absolute_error: 0.1351 - val_loss: 0.0305 - val_mean_absolute_error: 0.1482\n",
            "\n",
            "Epoch 85/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1202\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1343\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1352\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1348 - val_loss: 0.0305 - val_mean_absolute_error: 0.1481\n",
            "\n",
            "Epoch 86/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.1193\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1271\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1351\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1346 - val_loss: 0.0315 - val_mean_absolute_error: 0.1516\n",
            "\n",
            "Epoch 87/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0364 - mean_absolute_error: 0.1433\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1352\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1367\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0312 - mean_absolute_error: 0.1363 - val_loss: 0.0296 - val_mean_absolute_error: 0.1452\n",
            "\n",
            "Epoch 88/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.1108\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1356\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1344\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0310 - mean_absolute_error: 0.1355 - val_loss: 0.0302 - val_mean_absolute_error: 0.1471\n",
            "\n",
            "Epoch 89/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1278\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1340\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1315\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1358 - val_loss: 0.0297 - val_mean_absolute_error: 0.1451\n",
            "\n",
            "Epoch 90/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0386 - mean_absolute_error: 0.1492\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1407\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1348\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0310 - mean_absolute_error: 0.1359 - val_loss: 0.0297 - val_mean_absolute_error: 0.1454\n",
            "\n",
            "Epoch 91/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1424\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1346\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1354\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0308 - mean_absolute_error: 0.1357 - val_loss: 0.0301 - val_mean_absolute_error: 0.1466\n",
            "\n",
            "Epoch 92/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1539\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1337\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1321\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0305 - mean_absolute_error: 0.1348 - val_loss: 0.0297 - val_mean_absolute_error: 0.1454\n",
            "\n",
            "Epoch 93/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0238 - mean_absolute_error: 0.1133\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1321\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1342\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0308 - mean_absolute_error: 0.1344 - val_loss: 0.0299 - val_mean_absolute_error: 0.1462\n",
            "\n",
            "Epoch 94/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1405\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1360\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1373\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0310 - mean_absolute_error: 0.1367 - val_loss: 0.0298 - val_mean_absolute_error: 0.1457\n",
            "\n",
            "Epoch 95/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1357\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1326\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1345\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0305 - mean_absolute_error: 0.1344 - val_loss: 0.0304 - val_mean_absolute_error: 0.1478\n",
            "\n",
            "Epoch 96/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0255 - mean_absolute_error: 0.1234\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1308\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1331\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1349 - val_loss: 0.0308 - val_mean_absolute_error: 0.1490\n",
            "\n",
            "Epoch 97/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1456\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1357\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1332\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0306 - mean_absolute_error: 0.1348 - val_loss: 0.0302 - val_mean_absolute_error: 0.1470\n",
            "\n",
            "Epoch 98/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.1183\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1286\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1342\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0303 - mean_absolute_error: 0.1342 - val_loss: 0.0309 - val_mean_absolute_error: 0.1495\n",
            "\n",
            "Epoch 99/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0216 - mean_absolute_error: 0.1150\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1370\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1335\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0305 - mean_absolute_error: 0.1348 - val_loss: 0.0301 - val_mean_absolute_error: 0.1467\n",
            "\n",
            "Epoch 100/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1214\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1335\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1341\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0306 - mean_absolute_error: 0.1346 - val_loss: 0.0310 - val_mean_absolute_error: 0.1497\n",
            "\n",
            "Epoch 1/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 8s - loss: 0.0783 - mean_absolute_error: 0.2527\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0997 - mean_absolute_error: 0.2725\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1095 - mean_absolute_error: 0.2831\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.2903\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2893\n",
            "8/8 [==============================] - 2s 121ms/step - loss: 0.1148 - mean_absolute_error: 0.2893 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 2/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1284 - mean_absolute_error: 0.3047\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1334 - mean_absolute_error: 0.3106\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1284 - mean_absolute_error: 0.3037\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2949\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 3/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1160 - mean_absolute_error: 0.2951\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2962\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2958\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2931\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 4/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2944\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2968\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2944\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2943\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 5/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1118 - mean_absolute_error: 0.2806\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2966\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2965\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2966\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 6/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1475 - mean_absolute_error: 0.3260\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2975\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2980\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.2982\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 7/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1253 - mean_absolute_error: 0.3029\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2938\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2968\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2956\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 8/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2980\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1098 - mean_absolute_error: 0.2829\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.2918\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2941\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 9/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1449 - mean_absolute_error: 0.3192\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1288 - mean_absolute_error: 0.3056\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1241 - mean_absolute_error: 0.2987\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2949\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 10/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1336 - mean_absolute_error: 0.3014\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1269 - mean_absolute_error: 0.3045\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2988\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2968\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 11/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1277 - mean_absolute_error: 0.3092\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1318 - mean_absolute_error: 0.3092\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1292 - mean_absolute_error: 0.3065\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2961\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 12/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1299 - mean_absolute_error: 0.3103\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2961\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2986\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2926\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 13/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.3057\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1095 - mean_absolute_error: 0.2861\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.2877\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2938\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 14/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2915\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1149 - mean_absolute_error: 0.2880\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2988\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1223 - mean_absolute_error: 0.2977\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 15/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.2904\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2876\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2898\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 16/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2879\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2901\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2941\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2941\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 17/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1320 - mean_absolute_error: 0.3079\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.3008\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2950\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2968\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 18/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2973\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.2897\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.2889\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 19/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1082 - mean_absolute_error: 0.2822\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.2996\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2962\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2946\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 20/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1502 - mean_absolute_error: 0.3220\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1269 - mean_absolute_error: 0.3004\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2963\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1203 - mean_absolute_error: 0.2948\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 21/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1272 - mean_absolute_error: 0.2991\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2970\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2934\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2936\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 22/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1387 - mean_absolute_error: 0.3033\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2931\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2957\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2959\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 23/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1308 - mean_absolute_error: 0.3052\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2887\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2980\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2988\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 24/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0942 - mean_absolute_error: 0.2701\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2924\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2950\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2947\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 25/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1179 - mean_absolute_error: 0.2914\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1260 - mean_absolute_error: 0.3000\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2951\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2937\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 26/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1086 - mean_absolute_error: 0.2853\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2844\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1157 - mean_absolute_error: 0.2898\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2957\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 27/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2987\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2934\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1223 - mean_absolute_error: 0.2969\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2923\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 28/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1080 - mean_absolute_error: 0.2800\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1047 - mean_absolute_error: 0.2768\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.2875\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2946\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 29/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1415 - mean_absolute_error: 0.3143\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3010\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.2993\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2952\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 30/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2974\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2916\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2891\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2919\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 31/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2927\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2911\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2937\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2952\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 32/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1012 - mean_absolute_error: 0.2755\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1076 - mean_absolute_error: 0.2813\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1096 - mean_absolute_error: 0.2817\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2949\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 33/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1299 - mean_absolute_error: 0.3034\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1266 - mean_absolute_error: 0.3015\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2973\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2956\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 34/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1391 - mean_absolute_error: 0.3200\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2981\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2937\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2940\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 35/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1259 - mean_absolute_error: 0.3004\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2896\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2944\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2940\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 36/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.2816\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1134 - mean_absolute_error: 0.2875\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.2877\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2955\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 37/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1483 - mean_absolute_error: 0.3242\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1239 - mean_absolute_error: 0.2984\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2948\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2929\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 38/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1102 - mean_absolute_error: 0.2792\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1266 - mean_absolute_error: 0.3009\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2935\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2950\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 39/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1356 - mean_absolute_error: 0.3250\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1239 - mean_absolute_error: 0.3019\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1169 - mean_absolute_error: 0.2923\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2934\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 40/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1391 - mean_absolute_error: 0.3148\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2977\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2920\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2943\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 41/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1014 - mean_absolute_error: 0.2741\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1105 - mean_absolute_error: 0.2879\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2902\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 42/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.2907\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2927\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2924\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2944\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 43/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2857\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2923\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2941\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2938\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 44/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1122 - mean_absolute_error: 0.2783\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2851\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1175 - mean_absolute_error: 0.2900\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1166 - mean_absolute_error: 0.2910\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 45/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1003 - mean_absolute_error: 0.2699\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1050 - mean_absolute_error: 0.2777\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2948\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 46/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1231 - mean_absolute_error: 0.2992\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.2933\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1211 - mean_absolute_error: 0.2975\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2990\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 47/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1052 - mean_absolute_error: 0.2860\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1157 - mean_absolute_error: 0.2952\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2948\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2952\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 48/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1022 - mean_absolute_error: 0.2726\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1263 - mean_absolute_error: 0.2980\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1270 - mean_absolute_error: 0.3018\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 49/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1252 - mean_absolute_error: 0.3074\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.3004\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1237 - mean_absolute_error: 0.3009\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2939\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 50/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1328 - mean_absolute_error: 0.3112\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2968\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1149 - mean_absolute_error: 0.2894\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2911\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 51/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3002\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2971\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2928\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2948\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 52/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2994\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1133 - mean_absolute_error: 0.2846\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2942\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 53/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0915 - mean_absolute_error: 0.2612\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2922\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1170 - mean_absolute_error: 0.2929\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2927\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 54/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1126 - mean_absolute_error: 0.2958\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1120 - mean_absolute_error: 0.2875\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2969\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2929\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 55/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.3004\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2892\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1151 - mean_absolute_error: 0.2885\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.2915\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 56/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1265 - mean_absolute_error: 0.2996\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2907\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2978\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2937\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 57/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2915\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1153 - mean_absolute_error: 0.2867\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.2901\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2963\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 58/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.2961\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3022\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2963\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2945\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 59/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1319 - mean_absolute_error: 0.3052\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2944\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2988\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2931\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 60/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1066 - mean_absolute_error: 0.2786\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1170 - mean_absolute_error: 0.2905\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2994\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 61/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1142 - mean_absolute_error: 0.2838\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2907\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2965\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2904\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 62/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1571 - mean_absolute_error: 0.3323\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.2968\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.2986\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2915\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 63/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1337 - mean_absolute_error: 0.3022\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1269 - mean_absolute_error: 0.3042\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2990\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2960\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 64/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1103 - mean_absolute_error: 0.2816\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1113 - mean_absolute_error: 0.2858\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.2878\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2928\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 65/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.2935\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1142 - mean_absolute_error: 0.2900\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2974\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2943\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 66/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1280 - mean_absolute_error: 0.3017\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1111 - mean_absolute_error: 0.2833\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2920\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2963\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 67/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2970\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1241 - mean_absolute_error: 0.3024\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2944\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2944\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 68/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1060 - mean_absolute_error: 0.2784\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2864\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2918\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2969\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 69/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.3218\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2920\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1244 - mean_absolute_error: 0.2989\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2957\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 70/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1343 - mean_absolute_error: 0.2982\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2972\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2991\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2936\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 71/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2919\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2938\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2985\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2956\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 72/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1258 - mean_absolute_error: 0.2989\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1273 - mean_absolute_error: 0.3019\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2962\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 73/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1337 - mean_absolute_error: 0.3067\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2903\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1151 - mean_absolute_error: 0.2876\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.2910\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 74/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1320 - mean_absolute_error: 0.3161\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2931\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.2892\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2948\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 75/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1251 - mean_absolute_error: 0.3037\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1305 - mean_absolute_error: 0.3073\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1263 - mean_absolute_error: 0.3026\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2958\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 76/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1088 - mean_absolute_error: 0.2774\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2995\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2932\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2926\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 77/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0982 - mean_absolute_error: 0.2698\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2929\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2914\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 78/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2881\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2905\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2919\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2962\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 79/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1342 - mean_absolute_error: 0.3120\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2970\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1132 - mean_absolute_error: 0.2880\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2932\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 80/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1307 - mean_absolute_error: 0.3056\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2966\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3020\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2983\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 81/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1154 - mean_absolute_error: 0.2924\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2839\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1150 - mean_absolute_error: 0.2907\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2929\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 82/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2840\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1146 - mean_absolute_error: 0.2917\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2972\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2978\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 83/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1219 - mean_absolute_error: 0.2899\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1217 - mean_absolute_error: 0.2932\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2902\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2957\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 84/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1037 - mean_absolute_error: 0.2758\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1080 - mean_absolute_error: 0.2811\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.2920\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1180 - mean_absolute_error: 0.2933\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 85/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1127 - mean_absolute_error: 0.2912\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2941\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2915\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 86/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.3040\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2955\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2964\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2938\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 87/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0939 - mean_absolute_error: 0.2654\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.2889\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1168 - mean_absolute_error: 0.2898\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2935\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 88/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1108 - mean_absolute_error: 0.2860\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1157 - mean_absolute_error: 0.2926\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2908\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 89/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1117 - mean_absolute_error: 0.2903\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.2898\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2980\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2927\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 90/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1315 - mean_absolute_error: 0.3155\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1283 - mean_absolute_error: 0.3092\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3010\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2928\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 91/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1086 - mean_absolute_error: 0.2780\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1098 - mean_absolute_error: 0.2835\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2890\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.2918\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 92/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1076 - mean_absolute_error: 0.2742\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2850\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1155 - mean_absolute_error: 0.2892\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2944\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 93/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1265 - mean_absolute_error: 0.2972\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1109 - mean_absolute_error: 0.2809\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1219 - mean_absolute_error: 0.2940\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2954\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 94/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1003 - mean_absolute_error: 0.2768\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1093 - mean_absolute_error: 0.2826\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1162 - mean_absolute_error: 0.2883\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2940\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 95/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1161 - mean_absolute_error: 0.2951\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1212 - mean_absolute_error: 0.2973\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2957\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 96/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2916\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2944\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.2985\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2941\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 97/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1394 - mean_absolute_error: 0.3207\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1317 - mean_absolute_error: 0.3088\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1244 - mean_absolute_error: 0.3000\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2968\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 98/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1285 - mean_absolute_error: 0.3113\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2925\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1181 - mean_absolute_error: 0.2925\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2959\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 99/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1414 - mean_absolute_error: 0.3111\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2973\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2930\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2932\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 100/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0991 - mean_absolute_error: 0.2576\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1053 - mean_absolute_error: 0.2737\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.2873\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2933\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 101/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1134 - mean_absolute_error: 0.2974\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1242 - mean_absolute_error: 0.3050\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1179 - mean_absolute_error: 0.2953\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 102/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2919\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1296 - mean_absolute_error: 0.3037\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1251 - mean_absolute_error: 0.2999\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2950\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 103/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2930\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2962\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2902\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2933\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 104/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1047 - mean_absolute_error: 0.2746\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1147 - mean_absolute_error: 0.2906\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2990\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 105/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2885\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1264 - mean_absolute_error: 0.3018\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1226 - mean_absolute_error: 0.2970\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2970\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 106/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1232 - mean_absolute_error: 0.2988\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1237 - mean_absolute_error: 0.2965\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1202 - mean_absolute_error: 0.2933\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2941\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 107/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1152 - mean_absolute_error: 0.2830\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1124 - mean_absolute_error: 0.2847\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1144 - mean_absolute_error: 0.2875\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2931\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 108/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1313 - mean_absolute_error: 0.3060\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2955\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2952\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 109/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1279 - mean_absolute_error: 0.3061\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1182 - mean_absolute_error: 0.2952\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2947\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2950\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 110/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1288 - mean_absolute_error: 0.3042\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.3004\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.3024\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 111/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.3119\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1243 - mean_absolute_error: 0.3026\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1247 - mean_absolute_error: 0.3007\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2964\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 112/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1247 - mean_absolute_error: 0.2974\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1298 - mean_absolute_error: 0.3042\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1245 - mean_absolute_error: 0.2997\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2950\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 113/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1269 - mean_absolute_error: 0.2978\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1285 - mean_absolute_error: 0.3063\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1237 - mean_absolute_error: 0.3005\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1223 - mean_absolute_error: 0.2974\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 114/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1288 - mean_absolute_error: 0.3010\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1261 - mean_absolute_error: 0.2996\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2935\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2934\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 115/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1328 - mean_absolute_error: 0.3000\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1175 - mean_absolute_error: 0.2925\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1233 - mean_absolute_error: 0.2977\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 116/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2890\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1160 - mean_absolute_error: 0.2896\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1171 - mean_absolute_error: 0.2913\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2930\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 117/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2858\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2931\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2928\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 118/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1005 - mean_absolute_error: 0.2757\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2954\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2958\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2944\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 119/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1276 - mean_absolute_error: 0.2995\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2951\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2935\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.2948\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 120/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1069 - mean_absolute_error: 0.2855\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1165 - mean_absolute_error: 0.2891\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1196 - mean_absolute_error: 0.2943\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1178 - mean_absolute_error: 0.2927\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 121/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.2959\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2920\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1256 - mean_absolute_error: 0.3019\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 122/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1375 - mean_absolute_error: 0.3149\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1252 - mean_absolute_error: 0.2999\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1267 - mean_absolute_error: 0.3020\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2955\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 123/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1328 - mean_absolute_error: 0.3061\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1162 - mean_absolute_error: 0.2913\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2966\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2959\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 124/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1187 - mean_absolute_error: 0.2945\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1134 - mean_absolute_error: 0.2861\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1118 - mean_absolute_error: 0.2853\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1179 - mean_absolute_error: 0.2926\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 125/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1297 - mean_absolute_error: 0.3018\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1214 - mean_absolute_error: 0.2961\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1174 - mean_absolute_error: 0.2908\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2939\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 126/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.2933\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1237 - mean_absolute_error: 0.2990\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.2871\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1184 - mean_absolute_error: 0.2932\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 127/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1274 - mean_absolute_error: 0.3097\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1143 - mean_absolute_error: 0.2913\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2892\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2948\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 128/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2877\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1247 - mean_absolute_error: 0.2966\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2947\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1201 - mean_absolute_error: 0.2947\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 129/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1374 - mean_absolute_error: 0.3086\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1104 - mean_absolute_error: 0.2808\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1213 - mean_absolute_error: 0.2943\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1175 - mean_absolute_error: 0.2917\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 130/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1322 - mean_absolute_error: 0.3075\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2946\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2910\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1193 - mean_absolute_error: 0.2942\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 131/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1259 - mean_absolute_error: 0.3047\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1246 - mean_absolute_error: 0.3005\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1216 - mean_absolute_error: 0.2961\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2926\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 132/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2924\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.2993\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1259 - mean_absolute_error: 0.3010\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2968\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 133/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1209 - mean_absolute_error: 0.2987\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1138 - mean_absolute_error: 0.2913\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2949\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1198 - mean_absolute_error: 0.2946\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 134/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1482 - mean_absolute_error: 0.3153\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1310 - mean_absolute_error: 0.3048\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2954\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 135/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1159 - mean_absolute_error: 0.2897\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1125 - mean_absolute_error: 0.2873\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2910\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1186 - mean_absolute_error: 0.2938\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 136/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1200 - mean_absolute_error: 0.2942\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1139 - mean_absolute_error: 0.2849\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.2901\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2937\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 137/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1222 - mean_absolute_error: 0.3042\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1221 - mean_absolute_error: 0.2985\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1206 - mean_absolute_error: 0.2960\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1190 - mean_absolute_error: 0.2937\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 138/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1173 - mean_absolute_error: 0.2933\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1164 - mean_absolute_error: 0.2914\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1225 - mean_absolute_error: 0.2972\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2953\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 139/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1061 - mean_absolute_error: 0.2774\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1234 - mean_absolute_error: 0.2945\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2959\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.2981\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 140/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1215 - mean_absolute_error: 0.2937\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.2951\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1207 - mean_absolute_error: 0.2962\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1219 - mean_absolute_error: 0.2966\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 141/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1241 - mean_absolute_error: 0.3006\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1116 - mean_absolute_error: 0.2864\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2938\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1192 - mean_absolute_error: 0.2944\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 142/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1259 - mean_absolute_error: 0.3055\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1218 - mean_absolute_error: 0.2993\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2965\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1194 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 143/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1104 - mean_absolute_error: 0.2826\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1149 - mean_absolute_error: 0.2902\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1191 - mean_absolute_error: 0.2939\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1210 - mean_absolute_error: 0.2961\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 144/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1235 - mean_absolute_error: 0.3015\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1128 - mean_absolute_error: 0.2894\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1170 - mean_absolute_error: 0.2945\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1185 - mean_absolute_error: 0.2925\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 145/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1278 - mean_absolute_error: 0.3179\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1106 - mean_absolute_error: 0.2870\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1224 - mean_absolute_error: 0.2969\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2949\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 146/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1045 - mean_absolute_error: 0.2743\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1230 - mean_absolute_error: 0.3002\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1227 - mean_absolute_error: 0.3002\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_error: 0.2947\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 147/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1374 - mean_absolute_error: 0.3155\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1208 - mean_absolute_error: 0.2949\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1252 - mean_absolute_error: 0.3008\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_error: 0.2955\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 148/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1183 - mean_absolute_error: 0.2902\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.2891\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1177 - mean_absolute_error: 0.2926\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1197 - mean_absolute_error: 0.2951\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 149/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1114 - mean_absolute_error: 0.2744\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.2960\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.2962\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1195 - mean_absolute_error: 0.2937\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 150/150\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.1367 - mean_absolute_error: 0.3179\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.1250 - mean_absolute_error: 0.3044\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.1275 - mean_absolute_error: 0.3048\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1226 - mean_absolute_error: 0.2984\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1199 - mean_absolute_error: 0.2947 - val_loss: 0.1004 - val_mean_absolute_error: 0.2773\n",
            "\n",
            "Epoch 1/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 12s - loss: 0.0747 - mean_absolute_error: 0.2413\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0682 - mean_absolute_error: 0.2313 \n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0632 - mean_absolute_error: 0.2218\n",
            "15/15 [==============================] - 1s 29ms/step - loss: 0.0596 - mean_absolute_error: 0.2139 - val_loss: 0.0593 - val_mean_absolute_error: 0.2186\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1491\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0408 - mean_absolute_error: 0.1669\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1549\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0383 - mean_absolute_error: 0.1559 - val_loss: 0.0450 - val_mean_absolute_error: 0.1872\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1527\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0364 - mean_absolute_error: 0.1480\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1423\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0379 - mean_absolute_error: 0.1488 - val_loss: 0.0493 - val_mean_absolute_error: 0.1972\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1345\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1470\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1551\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0368 - mean_absolute_error: 0.1532 - val_loss: 0.0517 - val_mean_absolute_error: 0.2025\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1407\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1511\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1483\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0368 - mean_absolute_error: 0.1501 - val_loss: 0.0473 - val_mean_absolute_error: 0.1926\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0425 - mean_absolute_error: 0.1532\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1487\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1493\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0363 - mean_absolute_error: 0.1495 - val_loss: 0.0486 - val_mean_absolute_error: 0.1955\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0462 - mean_absolute_error: 0.1643\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0396 - mean_absolute_error: 0.1575\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1509\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0370 - mean_absolute_error: 0.1526 - val_loss: 0.0475 - val_mean_absolute_error: 0.1930\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0454 - mean_absolute_error: 0.1644\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1506\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1488\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0359 - mean_absolute_error: 0.1478 - val_loss: 0.0469 - val_mean_absolute_error: 0.1916\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1497\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1422\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1490\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0365 - mean_absolute_error: 0.1503 - val_loss: 0.0470 - val_mean_absolute_error: 0.1917\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1837\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0383 - mean_absolute_error: 0.1532\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1524\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0364 - mean_absolute_error: 0.1512 - val_loss: 0.0480 - val_mean_absolute_error: 0.1942\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1597\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1402\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1490\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0364 - mean_absolute_error: 0.1482 - val_loss: 0.0452 - val_mean_absolute_error: 0.1874\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1448\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1451\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1473\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0350 - mean_absolute_error: 0.1465 - val_loss: 0.0461 - val_mean_absolute_error: 0.1896\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1435\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1457\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1467\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0351 - mean_absolute_error: 0.1467 - val_loss: 0.0445 - val_mean_absolute_error: 0.1857\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0416 - mean_absolute_error: 0.1641\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1494\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0354 - mean_absolute_error: 0.1470\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0355 - mean_absolute_error: 0.1472 - val_loss: 0.0446 - val_mean_absolute_error: 0.1860\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1433\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1451\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1456\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0349 - mean_absolute_error: 0.1464 - val_loss: 0.0437 - val_mean_absolute_error: 0.1837\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1545\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1406\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1437\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0345 - mean_absolute_error: 0.1455 - val_loss: 0.0440 - val_mean_absolute_error: 0.1844\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0398 - mean_absolute_error: 0.1656\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1493\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0352 - mean_absolute_error: 0.1474\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0345 - mean_absolute_error: 0.1459 - val_loss: 0.0432 - val_mean_absolute_error: 0.1825\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1345\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1436\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1442\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0345 - mean_absolute_error: 0.1461 - val_loss: 0.0430 - val_mean_absolute_error: 0.1819\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1504\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1440\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1452\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0341 - mean_absolute_error: 0.1452 - val_loss: 0.0419 - val_mean_absolute_error: 0.1790\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0414 - mean_absolute_error: 0.1602\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1514\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1458\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0342 - mean_absolute_error: 0.1448 - val_loss: 0.0417 - val_mean_absolute_error: 0.1787\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1422\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1418\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1442\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0341 - mean_absolute_error: 0.1442 - val_loss: 0.0408 - val_mean_absolute_error: 0.1764\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1459\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1413\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1426\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0341 - mean_absolute_error: 0.1438 - val_loss: 0.0408 - val_mean_absolute_error: 0.1764\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.1348\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1393\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1427\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0339 - mean_absolute_error: 0.1433 - val_loss: 0.0402 - val_mean_absolute_error: 0.1747\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.1375\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1447\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1450\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0340 - mean_absolute_error: 0.1450 - val_loss: 0.0400 - val_mean_absolute_error: 0.1742\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0397 - mean_absolute_error: 0.1587\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1409\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1413\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0332 - mean_absolute_error: 0.1413 - val_loss: 0.0383 - val_mean_absolute_error: 0.1699\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1490\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1456\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1423\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0334 - mean_absolute_error: 0.1427 - val_loss: 0.0384 - val_mean_absolute_error: 0.1701\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1370\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1396\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1425\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0337 - mean_absolute_error: 0.1425 - val_loss: 0.0381 - val_mean_absolute_error: 0.1693\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1455\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1307\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1395\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0330 - mean_absolute_error: 0.1412 - val_loss: 0.0373 - val_mean_absolute_error: 0.1673\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1566\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1367\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1408\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0334 - mean_absolute_error: 0.1413 - val_loss: 0.0374 - val_mean_absolute_error: 0.1674\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1403\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1435\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1435\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0335 - mean_absolute_error: 0.1429 - val_loss: 0.0368 - val_mean_absolute_error: 0.1658\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.1295\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1388\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1416\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0329 - mean_absolute_error: 0.1404 - val_loss: 0.0362 - val_mean_absolute_error: 0.1643\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1460\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1419\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1398\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - mean_absolute_error: 0.1402 - val_loss: 0.0360 - val_mean_absolute_error: 0.1637\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1355\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1316\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1396\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0323 - mean_absolute_error: 0.1397 - val_loss: 0.0360 - val_mean_absolute_error: 0.1637\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0387 - mean_absolute_error: 0.1554\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1418\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1412\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - mean_absolute_error: 0.1411 - val_loss: 0.0352 - val_mean_absolute_error: 0.1617\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0249 - mean_absolute_error: 0.1162\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1391\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1394\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0324 - mean_absolute_error: 0.1394 - val_loss: 0.0347 - val_mean_absolute_error: 0.1603\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1216\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1447\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1392\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0328 - mean_absolute_error: 0.1394 - val_loss: 0.0346 - val_mean_absolute_error: 0.1600\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1334\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1374\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1408\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0328 - mean_absolute_error: 0.1408 - val_loss: 0.0350 - val_mean_absolute_error: 0.1610\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.1354\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1432\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1412\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0332 - mean_absolute_error: 0.1422 - val_loss: 0.0341 - val_mean_absolute_error: 0.1585\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1396\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1378\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1418\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0327 - mean_absolute_error: 0.1389 - val_loss: 0.0339 - val_mean_absolute_error: 0.1582\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0427 - mean_absolute_error: 0.1546\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1414\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1419\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - mean_absolute_error: 0.1419 - val_loss: 0.0338 - val_mean_absolute_error: 0.1578\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0535 - mean_absolute_error: 0.1743\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1405\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1392\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - mean_absolute_error: 0.1392 - val_loss: 0.0326 - val_mean_absolute_error: 0.1542\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1376\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1480\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1403\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0328 - mean_absolute_error: 0.1410 - val_loss: 0.0337 - val_mean_absolute_error: 0.1576\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.1352\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1445\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1385\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0326 - mean_absolute_error: 0.1388 - val_loss: 0.0325 - val_mean_absolute_error: 0.1543\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1443\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1402\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1403\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0325 - mean_absolute_error: 0.1400 - val_loss: 0.0332 - val_mean_absolute_error: 0.1563\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0442 - mean_absolute_error: 0.1526\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1426\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1390\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0323 - mean_absolute_error: 0.1390 - val_loss: 0.0317 - val_mean_absolute_error: 0.1517\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0211 - mean_absolute_error: 0.1283\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1468\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1391\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0322 - mean_absolute_error: 0.1391 - val_loss: 0.0322 - val_mean_absolute_error: 0.1532\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1377\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1451\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1410\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0325 - mean_absolute_error: 0.1395 - val_loss: 0.0321 - val_mean_absolute_error: 0.1530\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1498\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1447\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1390\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0325 - mean_absolute_error: 0.1390 - val_loss: 0.0313 - val_mean_absolute_error: 0.1504\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1411\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1333\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1374\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0322 - mean_absolute_error: 0.1385 - val_loss: 0.0319 - val_mean_absolute_error: 0.1524\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0401 - mean_absolute_error: 0.1511\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1409\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1406\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0319 - mean_absolute_error: 0.1390 - val_loss: 0.0306 - val_mean_absolute_error: 0.1482\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0232 - mean_absolute_error: 0.1231\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1373\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1370\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0320 - mean_absolute_error: 0.1370 - val_loss: 0.0308 - val_mean_absolute_error: 0.1490\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0269 - mean_absolute_error: 0.1324\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1363\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1397\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0324 - mean_absolute_error: 0.1397 - val_loss: 0.0309 - val_mean_absolute_error: 0.1490\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1490\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1424\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1389\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0319 - mean_absolute_error: 0.1382 - val_loss: 0.0302 - val_mean_absolute_error: 0.1469\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0409 - mean_absolute_error: 0.1505\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1416\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1407\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0322 - mean_absolute_error: 0.1391 - val_loss: 0.0310 - val_mean_absolute_error: 0.1494\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0254 - mean_absolute_error: 0.1270\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1340\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1360\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - mean_absolute_error: 0.1372 - val_loss: 0.0299 - val_mean_absolute_error: 0.1458\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.1176\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1341\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1409\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0326 - mean_absolute_error: 0.1410 - val_loss: 0.0311 - val_mean_absolute_error: 0.1499\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.1294\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1387\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1402\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - mean_absolute_error: 0.1377 - val_loss: 0.0296 - val_mean_absolute_error: 0.1452\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0273 - mean_absolute_error: 0.1317\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0283 - mean_absolute_error: 0.1322\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1387\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0320 - mean_absolute_error: 0.1385 - val_loss: 0.0302 - val_mean_absolute_error: 0.1470\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1541\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1397\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1411\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0325 - mean_absolute_error: 0.1393 - val_loss: 0.0302 - val_mean_absolute_error: 0.1471\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0257 - mean_absolute_error: 0.1335\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1379\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1414\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0322 - mean_absolute_error: 0.1389 - val_loss: 0.0293 - val_mean_absolute_error: 0.1440\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1478\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1426\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1385\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0320 - mean_absolute_error: 0.1389 - val_loss: 0.0293 - val_mean_absolute_error: 0.1441\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1346\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1393\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1380\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0321 - mean_absolute_error: 0.1370 - val_loss: 0.0288 - val_mean_absolute_error: 0.1425\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1495\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1404\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1385\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0324 - mean_absolute_error: 0.1384 - val_loss: 0.0294 - val_mean_absolute_error: 0.1443\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0272 - mean_absolute_error: 0.1337\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1350\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1349\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.0313 - mean_absolute_error: 0.1368 - val_loss: 0.0288 - val_mean_absolute_error: 0.1423\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1597\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1474\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1409\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0320 - mean_absolute_error: 0.1382 - val_loss: 0.0290 - val_mean_absolute_error: 0.1430\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0469 - mean_absolute_error: 0.1525\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1408\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1350\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1361 - val_loss: 0.0283 - val_mean_absolute_error: 0.1405\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1410\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1364\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1396\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0323 - mean_absolute_error: 0.1388 - val_loss: 0.0292 - val_mean_absolute_error: 0.1437\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0478 - mean_absolute_error: 0.1728\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1413\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1391\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0316 - mean_absolute_error: 0.1370 - val_loss: 0.0282 - val_mean_absolute_error: 0.1402\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1238\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1370\n",
            "12/15 [=======================>......] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1387\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0317 - mean_absolute_error: 0.1374 - val_loss: 0.0289 - val_mean_absolute_error: 0.1428\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1513\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1375\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1360\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1360 - val_loss: 0.0281 - val_mean_absolute_error: 0.1401\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1347\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1355\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1385\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0319 - mean_absolute_error: 0.1377 - val_loss: 0.0287 - val_mean_absolute_error: 0.1421\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1389\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1418\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1362\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0313 - mean_absolute_error: 0.1362 - val_loss: 0.0280 - val_mean_absolute_error: 0.1394\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0202 - mean_absolute_error: 0.1176\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1371\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1375\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0315 - mean_absolute_error: 0.1366 - val_loss: 0.0283 - val_mean_absolute_error: 0.1403\n",
            "\n",
            "Epoch 74/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0502 - mean_absolute_error: 0.1732\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1418\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1376\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0314 - mean_absolute_error: 0.1368 - val_loss: 0.0283 - val_mean_absolute_error: 0.1405\n",
            "\n",
            "Epoch 75/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1414\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1375\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1373\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1373 - val_loss: 0.0282 - val_mean_absolute_error: 0.1402\n",
            "\n",
            "Epoch 76/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1463\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1381\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1359\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0313 - mean_absolute_error: 0.1359 - val_loss: 0.0278 - val_mean_absolute_error: 0.1386\n",
            "\n",
            "Epoch 77/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0243 - mean_absolute_error: 0.1192\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1339\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1353\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0319 - mean_absolute_error: 0.1358 - val_loss: 0.0285 - val_mean_absolute_error: 0.1412\n",
            "\n",
            "Epoch 78/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0197 - mean_absolute_error: 0.1149\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1355\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1370\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1376 - val_loss: 0.0278 - val_mean_absolute_error: 0.1385\n",
            "\n",
            "Epoch 79/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0483 - mean_absolute_error: 0.1555\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1369\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1360\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0314 - mean_absolute_error: 0.1366 - val_loss: 0.0276 - val_mean_absolute_error: 0.1379\n",
            "\n",
            "Epoch 80/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.1382\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1307\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1318\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0318 - mean_absolute_error: 0.1357 - val_loss: 0.0280 - val_mean_absolute_error: 0.1393\n",
            "\n",
            "Epoch 81/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1229\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1372\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1392\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1392 - val_loss: 0.0276 - val_mean_absolute_error: 0.1379\n",
            "\n",
            "Epoch 82/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1331\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1285\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1341\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0314 - mean_absolute_error: 0.1346 - val_loss: 0.0278 - val_mean_absolute_error: 0.1387\n",
            "\n",
            "Epoch 83/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1266\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1424\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1410\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1388 - val_loss: 0.0276 - val_mean_absolute_error: 0.1378\n",
            "\n",
            "Epoch 84/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.1263\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1327\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1355\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0314 - mean_absolute_error: 0.1355 - val_loss: 0.0277 - val_mean_absolute_error: 0.1382\n",
            "\n",
            "Epoch 85/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1326\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1384\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1366\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0310 - mean_absolute_error: 0.1366 - val_loss: 0.0275 - val_mean_absolute_error: 0.1373\n",
            "\n",
            "Epoch 86/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1329\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1403\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1354\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1367 - val_loss: 0.0277 - val_mean_absolute_error: 0.1381\n",
            "\n",
            "Epoch 87/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1358\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1357\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1348\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0312 - mean_absolute_error: 0.1357 - val_loss: 0.0276 - val_mean_absolute_error: 0.1374\n",
            "\n",
            "Epoch 88/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0364 - mean_absolute_error: 0.1507\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1389\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1360\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1361 - val_loss: 0.0279 - val_mean_absolute_error: 0.1386\n",
            "\n",
            "Epoch 89/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0421 - mean_absolute_error: 0.1480\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1380\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1363\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0313 - mean_absolute_error: 0.1363 - val_loss: 0.0275 - val_mean_absolute_error: 0.1371\n",
            "\n",
            "Epoch 90/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1419\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1397\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1349\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0310 - mean_absolute_error: 0.1363 - val_loss: 0.0271 - val_mean_absolute_error: 0.1354\n",
            "\n",
            "Epoch 91/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1349\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1301\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1347\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_absolute_error: 0.1349 - val_loss: 0.0274 - val_mean_absolute_error: 0.1364\n",
            "\n",
            "Epoch 92/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1317\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1405\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1371\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1368 - val_loss: 0.0265 - val_mean_absolute_error: 0.1329\n",
            "\n",
            "Epoch 93/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.1277\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1302\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1337\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0308 - mean_absolute_error: 0.1341 - val_loss: 0.0280 - val_mean_absolute_error: 0.1391\n",
            "\n",
            "Epoch 94/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0432 - mean_absolute_error: 0.1641\n",
            " 6/15 [===========>..................] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1461\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1391\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_absolute_error: 0.1378 - val_loss: 0.0269 - val_mean_absolute_error: 0.1345\n",
            "\n",
            "Epoch 95/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0237 - mean_absolute_error: 0.1188\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1358\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1345\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1350 - val_loss: 0.0279 - val_mean_absolute_error: 0.1388\n",
            "\n",
            "Epoch 96/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0206 - mean_absolute_error: 0.1247\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1378\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1368\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0310 - mean_absolute_error: 0.1366 - val_loss: 0.0273 - val_mean_absolute_error: 0.1359\n",
            "\n",
            "Epoch 97/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0395 - mean_absolute_error: 0.1518\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1354\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1352\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0307 - mean_absolute_error: 0.1347 - val_loss: 0.0275 - val_mean_absolute_error: 0.1368\n",
            "\n",
            "Epoch 98/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0225 - mean_absolute_error: 0.1200\n",
            " 8/15 [===============>..............] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1332\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1351\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0305 - mean_absolute_error: 0.1351 - val_loss: 0.0272 - val_mean_absolute_error: 0.1356\n",
            "\n",
            "Epoch 99/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0238 - mean_absolute_error: 0.1287\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1306\n",
            "13/15 [=========================>....] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1304\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0307 - mean_absolute_error: 0.1341 - val_loss: 0.0276 - val_mean_absolute_error: 0.1372\n",
            "\n",
            "Epoch 100/100\n",
            "\n",
            " 1/15 [=>............................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1497\n",
            " 7/15 [=============>................] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1422\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1366\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1366 - val_loss: 0.0266 - val_mean_absolute_error: 0.1328\n",
            "\n",
            "Epoch 1/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 5s - loss: 0.0837 - mean_absolute_error: 0.2581\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0736 - mean_absolute_error: 0.2401\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.2268\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0606 - mean_absolute_error: 0.2146\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.0599 - mean_absolute_error: 0.2131 - val_loss: 0.0501 - val_mean_absolute_error: 0.1990\n",
            "\n",
            "Epoch 2/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0434 - mean_absolute_error: 0.1724\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0413 - mean_absolute_error: 0.1588\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0389 - mean_absolute_error: 0.1520\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0394 - mean_absolute_error: 0.1520\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0386 - mean_absolute_error: 0.1499 - val_loss: 0.0409 - val_mean_absolute_error: 0.1769\n",
            "\n",
            "Epoch 3/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1450\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1352\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1449\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1482\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0367 - mean_absolute_error: 0.1479 - val_loss: 0.0512 - val_mean_absolute_error: 0.2012\n",
            "\n",
            "Epoch 4/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0412 - mean_absolute_error: 0.1583\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0376 - mean_absolute_error: 0.1522\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1526\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0376 - mean_absolute_error: 0.1557\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0373 - mean_absolute_error: 0.1554 - val_loss: 0.0501 - val_mean_absolute_error: 0.1988\n",
            "\n",
            "Epoch 5/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0443 - mean_absolute_error: 0.1630\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0401 - mean_absolute_error: 0.1624\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1547\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1503\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0361 - mean_absolute_error: 0.1493 - val_loss: 0.0452 - val_mean_absolute_error: 0.1875\n",
            "\n",
            "Epoch 6/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1369\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1442\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1461\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1477\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0360 - mean_absolute_error: 0.1469 - val_loss: 0.0480 - val_mean_absolute_error: 0.1941\n",
            "\n",
            "Epoch 7/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0411 - mean_absolute_error: 0.1590\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1439\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1474\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1485\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0354 - mean_absolute_error: 0.1489 - val_loss: 0.0478 - val_mean_absolute_error: 0.1936\n",
            "\n",
            "Epoch 8/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1580\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1483\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1480\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1469\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0358 - mean_absolute_error: 0.1482 - val_loss: 0.0467 - val_mean_absolute_error: 0.1909\n",
            "\n",
            "Epoch 9/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0282 - mean_absolute_error: 0.1325\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1368\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1428\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1466\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0358 - mean_absolute_error: 0.1464 - val_loss: 0.0467 - val_mean_absolute_error: 0.1907\n",
            "\n",
            "Epoch 10/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1424\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1527\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1497\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1460\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0346 - mean_absolute_error: 0.1461 - val_loss: 0.0472 - val_mean_absolute_error: 0.1918\n",
            "\n",
            "Epoch 11/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0429 - mean_absolute_error: 0.1633\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1477\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1451\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1436\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0350 - mean_absolute_error: 0.1447 - val_loss: 0.0453 - val_mean_absolute_error: 0.1871\n",
            "\n",
            "Epoch 12/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.1338\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1366\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1394\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1424\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0342 - mean_absolute_error: 0.1429 - val_loss: 0.0473 - val_mean_absolute_error: 0.1920\n",
            "\n",
            "Epoch 13/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1461\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1509\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1483\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1484\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0349 - mean_absolute_error: 0.1481 - val_loss: 0.0466 - val_mean_absolute_error: 0.1902\n",
            "\n",
            "Epoch 14/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0436 - mean_absolute_error: 0.1638\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1450\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1435\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1422\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0345 - mean_absolute_error: 0.1421 - val_loss: 0.0451 - val_mean_absolute_error: 0.1863\n",
            "\n",
            "Epoch 15/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0407 - mean_absolute_error: 0.1581\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1514\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1487\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1462\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0345 - mean_absolute_error: 0.1471 - val_loss: 0.0468 - val_mean_absolute_error: 0.1905\n",
            "\n",
            "Epoch 16/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1350\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1434\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1404\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1430\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0344 - mean_absolute_error: 0.1445 - val_loss: 0.0433 - val_mean_absolute_error: 0.1817\n",
            "\n",
            "Epoch 17/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1431\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1433\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1454\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1440\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0342 - mean_absolute_error: 0.1431 - val_loss: 0.0467 - val_mean_absolute_error: 0.1900\n",
            "\n",
            "Epoch 18/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1528\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1476\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1441\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1435\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0343 - mean_absolute_error: 0.1451 - val_loss: 0.0436 - val_mean_absolute_error: 0.1823\n",
            "\n",
            "Epoch 19/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1407\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1439\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1444\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1434\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0341 - mean_absolute_error: 0.1442 - val_loss: 0.0448 - val_mean_absolute_error: 0.1854\n",
            "\n",
            "Epoch 20/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0387 - mean_absolute_error: 0.1473\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1482\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0357 - mean_absolute_error: 0.1444\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1410\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0334 - mean_absolute_error: 0.1409 - val_loss: 0.0435 - val_mean_absolute_error: 0.1820\n",
            "\n",
            "Epoch 21/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1559\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1435\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1446\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1443\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0332 - mean_absolute_error: 0.1426 - val_loss: 0.0442 - val_mean_absolute_error: 0.1839\n",
            "\n",
            "Epoch 22/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0415 - mean_absolute_error: 0.1536\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0368 - mean_absolute_error: 0.1486\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0364 - mean_absolute_error: 0.1491\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1442\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0340 - mean_absolute_error: 0.1437 - val_loss: 0.0425 - val_mean_absolute_error: 0.1794\n",
            "\n",
            "Epoch 23/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1477\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0367 - mean_absolute_error: 0.1465\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0352 - mean_absolute_error: 0.1427\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1404\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0330 - mean_absolute_error: 0.1393 - val_loss: 0.0434 - val_mean_absolute_error: 0.1818\n",
            "\n",
            "Epoch 24/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0370 - mean_absolute_error: 0.1465\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0345 - mean_absolute_error: 0.1441\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1389\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1434\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0336 - mean_absolute_error: 0.1428 - val_loss: 0.0437 - val_mean_absolute_error: 0.1824\n",
            "\n",
            "Epoch 25/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1494\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1447\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1397\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1408\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0329 - mean_absolute_error: 0.1415 - val_loss: 0.0434 - val_mean_absolute_error: 0.1818\n",
            "\n",
            "Epoch 26/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1463\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1393\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1377\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1396\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0339 - mean_absolute_error: 0.1421 - val_loss: 0.0432 - val_mean_absolute_error: 0.1813\n",
            "\n",
            "Epoch 27/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1316\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1401\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1462\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1465\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0339 - mean_absolute_error: 0.1466 - val_loss: 0.0446 - val_mean_absolute_error: 0.1849\n",
            "\n",
            "Epoch 28/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1415\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1387\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1388\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1405\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0331 - mean_absolute_error: 0.1395 - val_loss: 0.0402 - val_mean_absolute_error: 0.1737\n",
            "\n",
            "Epoch 29/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1319\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1319\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1404\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1407\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0331 - mean_absolute_error: 0.1427 - val_loss: 0.0440 - val_mean_absolute_error: 0.1834\n",
            "\n",
            "Epoch 30/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0380 - mean_absolute_error: 0.1597\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1489\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1400\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1391\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0328 - mean_absolute_error: 0.1397 - val_loss: 0.0403 - val_mean_absolute_error: 0.1741\n",
            "\n",
            "Epoch 31/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0251 - mean_absolute_error: 0.1255\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1372\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1391\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0323 - mean_absolute_error: 0.1406\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0327 - mean_absolute_error: 0.1408 - val_loss: 0.0423 - val_mean_absolute_error: 0.1794\n",
            "\n",
            "Epoch 32/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1391\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1387\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1453\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1417\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0324 - mean_absolute_error: 0.1407 - val_loss: 0.0402 - val_mean_absolute_error: 0.1739\n",
            "\n",
            "Epoch 33/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0365 - mean_absolute_error: 0.1505\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1350\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1413\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1387\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0332 - mean_absolute_error: 0.1398 - val_loss: 0.0421 - val_mean_absolute_error: 0.1788\n",
            "\n",
            "Epoch 34/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1499\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1426\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1394\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1394\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0325 - mean_absolute_error: 0.1409 - val_loss: 0.0398 - val_mean_absolute_error: 0.1728\n",
            "\n",
            "Epoch 35/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0437 - mean_absolute_error: 0.1635\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1522\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1434\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1398\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0328 - mean_absolute_error: 0.1394 - val_loss: 0.0417 - val_mean_absolute_error: 0.1780\n",
            "\n",
            "Epoch 36/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1436\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1443\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1456\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1420\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0326 - mean_absolute_error: 0.1406 - val_loss: 0.0384 - val_mean_absolute_error: 0.1693\n",
            "\n",
            "Epoch 37/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1333\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1280\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1315\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1360\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0324 - mean_absolute_error: 0.1364 - val_loss: 0.0425 - val_mean_absolute_error: 0.1799\n",
            "\n",
            "Epoch 38/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1510\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1480\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1485\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1448\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0327 - mean_absolute_error: 0.1442 - val_loss: 0.0384 - val_mean_absolute_error: 0.1692\n",
            "\n",
            "Epoch 39/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1403\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1408\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1370\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1383\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0328 - mean_absolute_error: 0.1367 - val_loss: 0.0409 - val_mean_absolute_error: 0.1760\n",
            "\n",
            "Epoch 40/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.1300\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.1293\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1393\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1401\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0323 - mean_absolute_error: 0.1408 - val_loss: 0.0401 - val_mean_absolute_error: 0.1739\n",
            "\n",
            "Epoch 41/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1415\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1393\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1345\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1369\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0327 - mean_absolute_error: 0.1370 - val_loss: 0.0393 - val_mean_absolute_error: 0.1718\n",
            "\n",
            "Epoch 42/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1331\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1407\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1416\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1419\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0322 - mean_absolute_error: 0.1426 - val_loss: 0.0385 - val_mean_absolute_error: 0.1698\n",
            "\n",
            "Epoch 43/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1465\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1428\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1361\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1372\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0325 - mean_absolute_error: 0.1375 - val_loss: 0.0393 - val_mean_absolute_error: 0.1719\n",
            "\n",
            "Epoch 44/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1363\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1443\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1424\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1421\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0321 - mean_absolute_error: 0.1414 - val_loss: 0.0381 - val_mean_absolute_error: 0.1686\n",
            "\n",
            "Epoch 45/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1386\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1381\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1345\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1339\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0320 - mean_absolute_error: 0.1344 - val_loss: 0.0393 - val_mean_absolute_error: 0.1718\n",
            "\n",
            "Epoch 46/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1322\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1365\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1405\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1421\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0318 - mean_absolute_error: 0.1409 - val_loss: 0.0372 - val_mean_absolute_error: 0.1665\n",
            "\n",
            "Epoch 47/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0374 - mean_absolute_error: 0.1465\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1349\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1352\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1347\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0319 - mean_absolute_error: 0.1357 - val_loss: 0.0388 - val_mean_absolute_error: 0.1708\n",
            "\n",
            "Epoch 48/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0406 - mean_absolute_error: 0.1503\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1467\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1421\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1401\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.0316 - mean_absolute_error: 0.1401 - val_loss: 0.0370 - val_mean_absolute_error: 0.1660\n",
            "\n",
            "Epoch 49/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0224 - mean_absolute_error: 0.1182\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0241 - mean_absolute_error: 0.1237\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.1266\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1337\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0317 - mean_absolute_error: 0.1351 - val_loss: 0.0411 - val_mean_absolute_error: 0.1769\n",
            "\n",
            "Epoch 50/50\n",
            "\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.0459 - mean_absolute_error: 0.1582\n",
            "3/8 [==========>...................] - ETA: 0s - loss: 0.0355 - mean_absolute_error: 0.1469\n",
            "5/8 [=================>............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1456\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0326 - mean_absolute_error: 0.1440\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0326 - mean_absolute_error: 0.1443 - val_loss: 0.0343 - val_mean_absolute_error: 0.1584\n",
            "\n",
            "Epoch 1/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 25s - loss: 0.0704 - mean_absolute_error: 0.2375\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0696 - mean_absolute_error: 0.2363 \n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0632 - mean_absolute_error: 0.2234\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0548 - mean_absolute_error: 0.2030\n",
            "30/30 [==============================] - 1s 16ms/step - loss: 0.0515 - mean_absolute_error: 0.1943 - val_loss: 0.0468 - val_mean_absolute_error: 0.1913\n",
            "\n",
            "Epoch 2/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0383 - mean_absolute_error: 0.1439\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1451\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1489\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1505\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0375 - mean_absolute_error: 0.1505 - val_loss: 0.0464 - val_mean_absolute_error: 0.1905\n",
            "\n",
            "Epoch 3/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0409 - mean_absolute_error: 0.1459\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1429\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1503\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1509\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0358 - mean_absolute_error: 0.1507 - val_loss: 0.0449 - val_mean_absolute_error: 0.1870\n",
            "\n",
            "Epoch 4/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0595 - mean_absolute_error: 0.1947\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0373 - mean_absolute_error: 0.1479\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1519\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0363 - mean_absolute_error: 0.1498\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0354 - mean_absolute_error: 0.1477 - val_loss: 0.0451 - val_mean_absolute_error: 0.1873\n",
            "\n",
            "Epoch 5/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0531 - mean_absolute_error: 0.1752\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0391 - mean_absolute_error: 0.1543\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1484\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0366 - mean_absolute_error: 0.1501\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0363 - mean_absolute_error: 0.1494 - val_loss: 0.0447 - val_mean_absolute_error: 0.1861\n",
            "\n",
            "Epoch 6/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0513 - mean_absolute_error: 0.1655\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0390 - mean_absolute_error: 0.1550\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0378 - mean_absolute_error: 0.1538\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1502\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0355 - mean_absolute_error: 0.1490 - val_loss: 0.0439 - val_mean_absolute_error: 0.1842\n",
            "\n",
            "Epoch 7/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0226 - mean_absolute_error: 0.1273\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0379 - mean_absolute_error: 0.1529\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1489\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.1476\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0351 - mean_absolute_error: 0.1476 - val_loss: 0.0447 - val_mean_absolute_error: 0.1859\n",
            "\n",
            "Epoch 8/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1565\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0375 - mean_absolute_error: 0.1515\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1474\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1470\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0345 - mean_absolute_error: 0.1460 - val_loss: 0.0429 - val_mean_absolute_error: 0.1815\n",
            "\n",
            "Epoch 9/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1311\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0371 - mean_absolute_error: 0.1485\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1483\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0356 - mean_absolute_error: 0.1467\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0345 - mean_absolute_error: 0.1444 - val_loss: 0.0418 - val_mean_absolute_error: 0.1787\n",
            "\n",
            "Epoch 10/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0473 - mean_absolute_error: 0.1647\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0351 - mean_absolute_error: 0.1452\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1451\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1446\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0343 - mean_absolute_error: 0.1448 - val_loss: 0.0410 - val_mean_absolute_error: 0.1767\n",
            "\n",
            "Epoch 11/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0583 - mean_absolute_error: 0.1763\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1453\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0353 - mean_absolute_error: 0.1472\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1457\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0339 - mean_absolute_error: 0.1444 - val_loss: 0.0416 - val_mean_absolute_error: 0.1781\n",
            "\n",
            "Epoch 12/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0451 - mean_absolute_error: 0.1723\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0384 - mean_absolute_error: 0.1485\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1472\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1438\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0341 - mean_absolute_error: 0.1437 - val_loss: 0.0395 - val_mean_absolute_error: 0.1726\n",
            "\n",
            "Epoch 13/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1347\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1472\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1470\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1440\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0338 - mean_absolute_error: 0.1441 - val_loss: 0.0390 - val_mean_absolute_error: 0.1714\n",
            "\n",
            "Epoch 14/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0456 - mean_absolute_error: 0.1669\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1401\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0340 - mean_absolute_error: 0.1442\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1417\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0335 - mean_absolute_error: 0.1421 - val_loss: 0.0394 - val_mean_absolute_error: 0.1724\n",
            "\n",
            "Epoch 15/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1410\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1369\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1429\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0338 - mean_absolute_error: 0.1427\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0334 - mean_absolute_error: 0.1419 - val_loss: 0.0396 - val_mean_absolute_error: 0.1729\n",
            "\n",
            "Epoch 16/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1574\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1408\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1466\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1427\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0334 - mean_absolute_error: 0.1428 - val_loss: 0.0394 - val_mean_absolute_error: 0.1725\n",
            "\n",
            "Epoch 17/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0372 - mean_absolute_error: 0.1460\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1380\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1413\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1381\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0334 - mean_absolute_error: 0.1406 - val_loss: 0.0376 - val_mean_absolute_error: 0.1679\n",
            "\n",
            "Epoch 18/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1338\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1298\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1399\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1397\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0332 - mean_absolute_error: 0.1411 - val_loss: 0.0377 - val_mean_absolute_error: 0.1684\n",
            "\n",
            "Epoch 19/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0742 - mean_absolute_error: 0.2123\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0407 - mean_absolute_error: 0.1568\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0358 - mean_absolute_error: 0.1472\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1430\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0332 - mean_absolute_error: 0.1425 - val_loss: 0.0354 - val_mean_absolute_error: 0.1622\n",
            "\n",
            "Epoch 20/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0228 - mean_absolute_error: 0.1141\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1354\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1370\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1410\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0334 - mean_absolute_error: 0.1408 - val_loss: 0.0372 - val_mean_absolute_error: 0.1671\n",
            "\n",
            "Epoch 21/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1393\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0350 - mean_absolute_error: 0.1460\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0360 - mean_absolute_error: 0.1461\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1407\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0329 - mean_absolute_error: 0.1406 - val_loss: 0.0360 - val_mean_absolute_error: 0.1638\n",
            "\n",
            "Epoch 22/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.1100\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1450\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1381\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.1413\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0333 - mean_absolute_error: 0.1407 - val_loss: 0.0386 - val_mean_absolute_error: 0.1708\n",
            "\n",
            "Epoch 23/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0206 - mean_absolute_error: 0.1188\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1434\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1417\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1426\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0329 - mean_absolute_error: 0.1414 - val_loss: 0.0326 - val_mean_absolute_error: 0.1543\n",
            "\n",
            "Epoch 24/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1249\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0344 - mean_absolute_error: 0.1394\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1424\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1414\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0329 - mean_absolute_error: 0.1403 - val_loss: 0.0345 - val_mean_absolute_error: 0.1598\n",
            "\n",
            "Epoch 25/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0527 - mean_absolute_error: 0.1920\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1422\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1367\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1389\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0327 - mean_absolute_error: 0.1398 - val_loss: 0.0347 - val_mean_absolute_error: 0.1605\n",
            "\n",
            "Epoch 26/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1609\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1399\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1407\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1404\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0327 - mean_absolute_error: 0.1402 - val_loss: 0.0346 - val_mean_absolute_error: 0.1602\n",
            "\n",
            "Epoch 27/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0264 - mean_absolute_error: 0.1318\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1387\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1386\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1383\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0329 - mean_absolute_error: 0.1394 - val_loss: 0.0345 - val_mean_absolute_error: 0.1599\n",
            "\n",
            "Epoch 28/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1364\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1439\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1441\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1422\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0328 - mean_absolute_error: 0.1409 - val_loss: 0.0328 - val_mean_absolute_error: 0.1552\n",
            "\n",
            "Epoch 29/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1407\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1366\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1410\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1391\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0325 - mean_absolute_error: 0.1395 - val_loss: 0.0311 - val_mean_absolute_error: 0.1499\n",
            "\n",
            "Epoch 30/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0347 - mean_absolute_error: 0.1542\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1348\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1384\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1382\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1383 - val_loss: 0.0312 - val_mean_absolute_error: 0.1500\n",
            "\n",
            "Epoch 31/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0542 - mean_absolute_error: 0.1599\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1298\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1322\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1392\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0326 - mean_absolute_error: 0.1388 - val_loss: 0.0329 - val_mean_absolute_error: 0.1555\n",
            "\n",
            "Epoch 32/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0225 - mean_absolute_error: 0.1282\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1385\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1405\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1393\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0326 - mean_absolute_error: 0.1401 - val_loss: 0.0313 - val_mean_absolute_error: 0.1507\n",
            "\n",
            "Epoch 33/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0378 - mean_absolute_error: 0.1572\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1360\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1332\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1400\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1386 - val_loss: 0.0320 - val_mean_absolute_error: 0.1526\n",
            "\n",
            "Epoch 34/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.1294\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1433\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1390\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1404\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1389 - val_loss: 0.0313 - val_mean_absolute_error: 0.1507\n",
            "\n",
            "Epoch 35/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1386\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1406\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0342 - mean_absolute_error: 0.1435\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1406\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0324 - mean_absolute_error: 0.1401 - val_loss: 0.0298 - val_mean_absolute_error: 0.1459\n",
            "\n",
            "Epoch 36/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0404 - mean_absolute_error: 0.1458\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1289\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1342\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1383\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1379 - val_loss: 0.0312 - val_mean_absolute_error: 0.1503\n",
            "\n",
            "Epoch 37/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1519\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0265 - mean_absolute_error: 0.1281\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1335\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1374\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0323 - mean_absolute_error: 0.1390 - val_loss: 0.0308 - val_mean_absolute_error: 0.1493\n",
            "\n",
            "Epoch 38/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.1233\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0348 - mean_absolute_error: 0.1449\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1420\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1388\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0320 - mean_absolute_error: 0.1386 - val_loss: 0.0300 - val_mean_absolute_error: 0.1466\n",
            "\n",
            "Epoch 39/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0410 - mean_absolute_error: 0.1485\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1368\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1413\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1408\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0322 - mean_absolute_error: 0.1386 - val_loss: 0.0304 - val_mean_absolute_error: 0.1479\n",
            "\n",
            "Epoch 40/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1293\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0341 - mean_absolute_error: 0.1443\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1382\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1375\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.1378 - val_loss: 0.0298 - val_mean_absolute_error: 0.1458\n",
            "\n",
            "Epoch 41/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0200 - mean_absolute_error: 0.1157\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1329\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1303\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1363\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0324 - mean_absolute_error: 0.1385 - val_loss: 0.0301 - val_mean_absolute_error: 0.1470\n",
            "\n",
            "Epoch 42/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1274\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1348\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1385\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1383\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.1390 - val_loss: 0.0281 - val_mean_absolute_error: 0.1402\n",
            "\n",
            "Epoch 43/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0207 - mean_absolute_error: 0.1147\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1359\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1357\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1362\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0317 - mean_absolute_error: 0.1362 - val_loss: 0.0294 - val_mean_absolute_error: 0.1445\n",
            "\n",
            "Epoch 44/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0236 - mean_absolute_error: 0.1212\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1324\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1386\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1367\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1387 - val_loss: 0.0288 - val_mean_absolute_error: 0.1426\n",
            "\n",
            "Epoch 45/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0168 - mean_absolute_error: 0.1093\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1350\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1391\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1377\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0323 - mean_absolute_error: 0.1391 - val_loss: 0.0291 - val_mean_absolute_error: 0.1437\n",
            "\n",
            "Epoch 46/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0392 - mean_absolute_error: 0.1470\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1420\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0320 - mean_absolute_error: 0.1440\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0336 - mean_absolute_error: 0.1438\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1408\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0322 - mean_absolute_error: 0.1408 - val_loss: 0.0279 - val_mean_absolute_error: 0.1394\n",
            "\n",
            "Epoch 47/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.1051\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1345\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1384\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1403\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0316 - mean_absolute_error: 0.1379 - val_loss: 0.0285 - val_mean_absolute_error: 0.1417\n",
            "\n",
            "Epoch 48/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0388 - mean_absolute_error: 0.1482\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1358\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1369\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1379\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0317 - mean_absolute_error: 0.1370 - val_loss: 0.0283 - val_mean_absolute_error: 0.1410\n",
            "\n",
            "Epoch 49/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1382\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0349 - mean_absolute_error: 0.1365\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1369\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1365\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1366\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0315 - mean_absolute_error: 0.1366 - val_loss: 0.0275 - val_mean_absolute_error: 0.1379\n",
            "\n",
            "Epoch 50/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0253 - mean_absolute_error: 0.1289\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0279 - mean_absolute_error: 0.1310\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1323\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1360\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0317 - mean_absolute_error: 0.1372 - val_loss: 0.0285 - val_mean_absolute_error: 0.1413\n",
            "\n",
            "Epoch 51/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0210 - mean_absolute_error: 0.1209\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1418\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1367\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1359\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0314 - mean_absolute_error: 0.1362 - val_loss: 0.0290 - val_mean_absolute_error: 0.1432\n",
            "\n",
            "Epoch 52/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0417 - mean_absolute_error: 0.1520\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1405\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1402\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1372\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1370\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0315 - mean_absolute_error: 0.1367 - val_loss: 0.0284 - val_mean_absolute_error: 0.1408\n",
            "\n",
            "Epoch 53/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0458 - mean_absolute_error: 0.1515\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1410\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1429\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0332 - mean_absolute_error: 0.1400\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1372\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0313 - mean_absolute_error: 0.1368 - val_loss: 0.0282 - val_mean_absolute_error: 0.1401\n",
            "\n",
            "Epoch 54/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0225 - mean_absolute_error: 0.1229\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0270 - mean_absolute_error: 0.1315\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1321\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1373\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1368\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0313 - mean_absolute_error: 0.1368 - val_loss: 0.0270 - val_mean_absolute_error: 0.1355\n",
            "\n",
            "Epoch 55/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.1037\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1389\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1377\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1373\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0314 - mean_absolute_error: 0.1368 - val_loss: 0.0268 - val_mean_absolute_error: 0.1350\n",
            "\n",
            "Epoch 56/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.1134\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.0343 - mean_absolute_error: 0.1374\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1321\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1367\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0313 - mean_absolute_error: 0.1355 - val_loss: 0.0296 - val_mean_absolute_error: 0.1452\n",
            "\n",
            "Epoch 57/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0247 - mean_absolute_error: 0.1336\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1320\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1349\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1365\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0312 - mean_absolute_error: 0.1369 - val_loss: 0.0282 - val_mean_absolute_error: 0.1401\n",
            "\n",
            "Epoch 58/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0334 - mean_absolute_error: 0.1498\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1324\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0324 - mean_absolute_error: 0.1382\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1379\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.1369 - val_loss: 0.0281 - val_mean_absolute_error: 0.1397\n",
            "\n",
            "Epoch 59/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1252\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1307\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1335\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1347\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0315 - mean_absolute_error: 0.1364 - val_loss: 0.0301 - val_mean_absolute_error: 0.1469\n",
            "\n",
            "Epoch 60/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0391 - mean_absolute_error: 0.1570\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1389\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1353\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1357\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0314 - mean_absolute_error: 0.1363 - val_loss: 0.0290 - val_mean_absolute_error: 0.1430\n",
            "\n",
            "Epoch 61/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1336\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.1283\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1319\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1360\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.1367 - val_loss: 0.0293 - val_mean_absolute_error: 0.1440\n",
            "\n",
            "Epoch 62/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0233 - mean_absolute_error: 0.1340\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1299\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0294 - mean_absolute_error: 0.1305\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1357\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.1364 - val_loss: 0.0293 - val_mean_absolute_error: 0.1440\n",
            "\n",
            "Epoch 63/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0196 - mean_absolute_error: 0.1205\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1342\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1334\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1352\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0310 - mean_absolute_error: 0.1350 - val_loss: 0.0296 - val_mean_absolute_error: 0.1449\n",
            "\n",
            "Epoch 64/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1433\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1333\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1353\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1357\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0311 - mean_absolute_error: 0.1364 - val_loss: 0.0269 - val_mean_absolute_error: 0.1344\n",
            "\n",
            "Epoch 65/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0381 - mean_absolute_error: 0.1443\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1335\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1355\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0315 - mean_absolute_error: 0.1379\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0311 - mean_absolute_error: 0.1370 - val_loss: 0.0286 - val_mean_absolute_error: 0.1413\n",
            "\n",
            "Epoch 66/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1262\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0266 - mean_absolute_error: 0.1250\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1327\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1359\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0314 - mean_absolute_error: 0.1367 - val_loss: 0.0301 - val_mean_absolute_error: 0.1469\n",
            "\n",
            "Epoch 67/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1329\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1439\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1363\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1364\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0311 - mean_absolute_error: 0.1361 - val_loss: 0.0284 - val_mean_absolute_error: 0.1406\n",
            "\n",
            "Epoch 68/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1413\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1303\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1357\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1357\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0309 - mean_absolute_error: 0.1354 - val_loss: 0.0283 - val_mean_absolute_error: 0.1400\n",
            "\n",
            "Epoch 69/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1316\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0319 - mean_absolute_error: 0.1411\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1357\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1342\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0309 - mean_absolute_error: 0.1348 - val_loss: 0.0295 - val_mean_absolute_error: 0.1442\n",
            "\n",
            "Epoch 70/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0244 - mean_absolute_error: 0.1244\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0335 - mean_absolute_error: 0.1456\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1405\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1391\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0317 - mean_absolute_error: 0.1388 - val_loss: 0.0273 - val_mean_absolute_error: 0.1360\n",
            "\n",
            "Epoch 71/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0248 - mean_absolute_error: 0.1197\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0337 - mean_absolute_error: 0.1410\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1360\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0300 - mean_absolute_error: 0.1340\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0306 - mean_absolute_error: 0.1345 - val_loss: 0.0279 - val_mean_absolute_error: 0.1383\n",
            "\n",
            "Epoch 72/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0352 - mean_absolute_error: 0.1439\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1385\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0317 - mean_absolute_error: 0.1383\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1356\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0309 - mean_absolute_error: 0.1354 - val_loss: 0.0280 - val_mean_absolute_error: 0.1385\n",
            "\n",
            "Epoch 73/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.1093\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1307\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1329\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1353\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0310 - mean_absolute_error: 0.1360 - val_loss: 0.0285 - val_mean_absolute_error: 0.1405\n",
            "\n",
            "Epoch 74/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0259 - mean_absolute_error: 0.1390\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0293 - mean_absolute_error: 0.1315\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1343\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1351\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0313 - mean_absolute_error: 0.1356 - val_loss: 0.0288 - val_mean_absolute_error: 0.1417\n",
            "\n",
            "Epoch 75/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0331 - mean_absolute_error: 0.1374\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0322 - mean_absolute_error: 0.1398\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1347\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1362\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0310 - mean_absolute_error: 0.1356 - val_loss: 0.0284 - val_mean_absolute_error: 0.1398\n",
            "\n",
            "Epoch 76/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0240 - mean_absolute_error: 0.1208\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1394\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1340\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1350\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0309 - mean_absolute_error: 0.1362 - val_loss: 0.0278 - val_mean_absolute_error: 0.1375\n",
            "\n",
            "Epoch 77/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0290 - mean_absolute_error: 0.1227\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0361 - mean_absolute_error: 0.1459\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0333 - mean_absolute_error: 0.1410\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1370\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1367 - val_loss: 0.0273 - val_mean_absolute_error: 0.1352\n",
            "\n",
            "Epoch 78/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1262\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1344\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1302\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1327\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0307 - mean_absolute_error: 0.1344 - val_loss: 0.0287 - val_mean_absolute_error: 0.1407\n",
            "\n",
            "Epoch 79/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0445 - mean_absolute_error: 0.1613\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1341\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0295 - mean_absolute_error: 0.1325\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1350\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1353 - val_loss: 0.0288 - val_mean_absolute_error: 0.1412\n",
            "\n",
            "Epoch 80/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0330 - mean_absolute_error: 0.1486\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0321 - mean_absolute_error: 0.1415\n",
            "17/30 [================>.............] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1355\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1329\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1347 - val_loss: 0.0293 - val_mean_absolute_error: 0.1432\n",
            "\n",
            "Epoch 81/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0217 - mean_absolute_error: 0.1202\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0284 - mean_absolute_error: 0.1307\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1331\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1352\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0308 - mean_absolute_error: 0.1353 - val_loss: 0.0299 - val_mean_absolute_error: 0.1453\n",
            "\n",
            "Epoch 82/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0172 - mean_absolute_error: 0.1099\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1362\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0298 - mean_absolute_error: 0.1355\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1346\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0309 - mean_absolute_error: 0.1357 - val_loss: 0.0295 - val_mean_absolute_error: 0.1437\n",
            "\n",
            "Epoch 83/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0235 - mean_absolute_error: 0.1279\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1348\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1362\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1376\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0308 - mean_absolute_error: 0.1366 - val_loss: 0.0286 - val_mean_absolute_error: 0.1403\n",
            "\n",
            "Epoch 84/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0277 - mean_absolute_error: 0.1275\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1314\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1329\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1347\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0306 - mean_absolute_error: 0.1347 - val_loss: 0.0291 - val_mean_absolute_error: 0.1420\n",
            "\n",
            "Epoch 85/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1398\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0291 - mean_absolute_error: 0.1347\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0329 - mean_absolute_error: 0.1398\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0310 - mean_absolute_error: 0.1377\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1367 - val_loss: 0.0274 - val_mean_absolute_error: 0.1352\n",
            "\n",
            "Epoch 86/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0288 - mean_absolute_error: 0.1299\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0314 - mean_absolute_error: 0.1355\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1326\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1341\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1349 - val_loss: 0.0279 - val_mean_absolute_error: 0.1373\n",
            "\n",
            "Epoch 87/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0286 - mean_absolute_error: 0.1415\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1349\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1311\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1320\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0302 - mean_absolute_error: 0.1335 - val_loss: 0.0288 - val_mean_absolute_error: 0.1407\n",
            "\n",
            "Epoch 88/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0225 - mean_absolute_error: 0.1320\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0262 - mean_absolute_error: 0.1284\n",
            "19/30 [==================>...........] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1334\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1339\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0304 - mean_absolute_error: 0.1344 - val_loss: 0.0294 - val_mean_absolute_error: 0.1432\n",
            "\n",
            "Epoch 89/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0218 - mean_absolute_error: 0.1218\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1403\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1355\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1342\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0305 - mean_absolute_error: 0.1342 - val_loss: 0.0291 - val_mean_absolute_error: 0.1418\n",
            "\n",
            "Epoch 90/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0187 - mean_absolute_error: 0.1023\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0316 - mean_absolute_error: 0.1378\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1360\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1349\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0301 - mean_absolute_error: 0.1342 - val_loss: 0.0287 - val_mean_absolute_error: 0.1404\n",
            "\n",
            "Epoch 91/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1498\n",
            "10/30 [=========>....................] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1374\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1329\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0301 - mean_absolute_error: 0.1334\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0305 - mean_absolute_error: 0.1338 - val_loss: 0.0291 - val_mean_absolute_error: 0.1418\n",
            "\n",
            "Epoch 92/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0239 - mean_absolute_error: 0.1128\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0325 - mean_absolute_error: 0.1392\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1357\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1368\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0305 - mean_absolute_error: 0.1356 - val_loss: 0.0289 - val_mean_absolute_error: 0.1408\n",
            "\n",
            "Epoch 93/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0274 - mean_absolute_error: 0.1119\n",
            "11/30 [==========>...................] - ETA: 0s - loss: 0.0303 - mean_absolute_error: 0.1336\n",
            "20/30 [===================>..........] - ETA: 0s - loss: 0.0297 - mean_absolute_error: 0.1334\n",
            "28/30 [===========================>..] - ETA: 0s - loss: 0.0296 - mean_absolute_error: 0.1338\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0305 - mean_absolute_error: 0.1358 - val_loss: 0.0285 - val_mean_absolute_error: 0.1390\n",
            "\n",
            "Epoch 94/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0268 - mean_absolute_error: 0.1209\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1294\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1269\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1333\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0305 - mean_absolute_error: 0.1345 - val_loss: 0.0290 - val_mean_absolute_error: 0.1413\n",
            "\n",
            "Epoch 95/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0385 - mean_absolute_error: 0.1509\n",
            " 8/30 [=======>......................] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1289\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1325\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0311 - mean_absolute_error: 0.1355\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.0305 - mean_absolute_error: 0.1347\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0305 - mean_absolute_error: 0.1347 - val_loss: 0.0299 - val_mean_absolute_error: 0.1448\n",
            "\n",
            "Epoch 96/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0183 - mean_absolute_error: 0.1157\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1376\n",
            "16/30 [===============>..............] - ETA: 0s - loss: 0.0308 - mean_absolute_error: 0.1369\n",
            "24/30 [=======================>......] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1366\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0303 - mean_absolute_error: 0.1346 - val_loss: 0.0287 - val_mean_absolute_error: 0.1400\n",
            "\n",
            "Epoch 97/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0328 - mean_absolute_error: 0.1402\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0276 - mean_absolute_error: 0.1292\n",
            "18/30 [=================>............] - ETA: 0s - loss: 0.0299 - mean_absolute_error: 0.1332\n",
            "26/30 [=========================>....] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1336\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0303 - mean_absolute_error: 0.1338 - val_loss: 0.0300 - val_mean_absolute_error: 0.1453\n",
            "\n",
            "Epoch 98/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0250 - mean_absolute_error: 0.1378\n",
            " 7/30 [======>.......................] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1425\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1349\n",
            "22/30 [=====================>........] - ETA: 0s - loss: 0.0306 - mean_absolute_error: 0.1366\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0307 - mean_absolute_error: 0.1366\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.0307 - mean_absolute_error: 0.1363 - val_loss: 0.0289 - val_mean_absolute_error: 0.1412\n",
            "\n",
            "Epoch 99/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0312 - mean_absolute_error: 0.1315\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1372\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0289 - mean_absolute_error: 0.1359\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0309 - mean_absolute_error: 0.1362\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.0299 - mean_absolute_error: 0.1331 - val_loss: 0.0281 - val_mean_absolute_error: 0.1378\n",
            "\n",
            "Epoch 100/100\n",
            "\n",
            " 1/30 [>.............................] - ETA: 0s - loss: 0.0304 - mean_absolute_error: 0.1327\n",
            " 9/30 [========>.....................] - ETA: 0s - loss: 0.0285 - mean_absolute_error: 0.1317\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1285\n",
            "23/30 [======================>.......] - ETA: 0s - loss: 0.0281 - mean_absolute_error: 0.1297\n",
            "29/30 [============================>.] - ETA: 0s - loss: 0.0302 - mean_absolute_error: 0.1328\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.0304 - mean_absolute_error: 0.1330 - val_loss: 0.0290 - val_mean_absolute_error: 0.1411\n",
            "\n",
            "100%|██████████| 10/10 [05:34<00:00, 33.41s/it, best loss: 0.024230454117059708]\n",
            "Mejores hiperparámetros: {'batch_size': 64, 'epochs': 150, 'learning_rate': 0.001, 'units': 64}\n",
            "Pérdida mínima: 0.024230454117059708\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "\n",
        "def objetive_img(params_img):\n",
        "  input_shape = (48, 48, 3)\n",
        "  # Inizializamos el modelo\n",
        "  img_model = Sequential()\n",
        "\n",
        "  # Definimos una capa convolucional\n",
        "  img_model.add(Conv2D(params_img['units'], kernel_size=(3, 3), activation='relu', input_shape=(input_shape)))\n",
        "  img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  img_model.add(Dropout(0.3))\n",
        "\n",
        "  # Definimos una segunda capa convolucional\n",
        "  img_model.add(Conv2D(params_img['units'], kernel_size=(3, 3), activation='relu'))\n",
        "  img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  img_model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  # Definimos una tercera capa convolucional\n",
        "  img_model.add(Conv2D(params_img['units'], kernel_size=(3, 3), activation='relu'))\n",
        "  img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  img_model.add(Dropout(0.3))\n",
        "\n",
        "  # Definimos una cuarta capa convolucional\n",
        "  img_model.add(Conv2D(params_img['units'], kernel_size=(3, 3), activation='relu'))\n",
        "  img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  img_model.add(Dropout(0.3))\n",
        "\n",
        "  # Añadimos nuestra regresión\n",
        "  img_model.add(Flatten())\n",
        "  img_model.add(Dense(1024, activation='relu'))\n",
        "  img_model.add(Dropout(0.3))\n",
        "  img_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Compilamos el modelo\n",
        "  img_model.compile(loss='mean_squared_error',\n",
        "                optimizer=Adam(lr=params_img['learning_rate'], decay = 1e-6), metrics=['mean_absolute_error'])\n",
        "\n",
        "  history_img = img_model.fit(X_train_resized, y_train,\n",
        "          batch_size=params_img['batch_size'],\n",
        "          shuffle = True,\n",
        "          epochs=params_img['epochs'],\n",
        "          validation_data=(X_validation_resized,y_validation))\n",
        "\n",
        "  best_val_loss = np.min(history_img.history['val_loss'])\n",
        "  return {'loss': best_val_loss, 'status': STATUS_OK}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "space_img = {\n",
        "    'units': hp.choice('units', [32, 64, 128]),\n",
        "    'epochs': hp.choice('epochs', [50, 100, 150]),\n",
        "    'batch_size': hp.choice('batch_size', [32,64,128]),\n",
        "    'learning_rate': hp.choice('lr', [0.01, 0.001, 0.0001])\n",
        "\n",
        "}\n",
        "\n",
        "# Configurar el algoritmo de optimización\n",
        "trials = Trials()\n",
        "best = fmin(fn=objetive_img,\n",
        "            space=space_img,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10,\n",
        "            trials=trials)\n",
        "\n",
        "# Obtener los mejores hiperparámetros y la pérdida mínima\n",
        "best_params_img = hyperopt.space_eval(space_img, best)\n",
        "min_loss_img = trials.best_trial['result']['loss']\n",
        "\n",
        "\n",
        "# Imprimir los resultados\n",
        "print('Mejores hiperparámetros:', best_params_img)\n",
        "print('Pérdida mínima:', min_loss_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRZ21JojiW2O"
      },
      "source": [
        "**CREAMOS MODELO Y ENTRENAMOS EL MODELO CONVUNSIONAL CON LOS MEJORES HIPERPARÁMETROS**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3MTsv2iiLdp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import Activation\n",
        "n_epochs_img = 150\n",
        "input_shape = (48, 48, 3)\n",
        "\n",
        "# Inizializamos el modelo\n",
        "img_model = Sequential()\n",
        "\n",
        "# Definimos una capa convolucional\n",
        "img_model.add(Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation='relu', input_shape=(input_shape)))\n",
        "img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "img_model.add(Dropout(0.5))\n",
        "\n",
        "# Definimos una segunda capa convolucional\n",
        "img_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "img_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Definimos una tercera capa convolucional\n",
        "img_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "img_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "img_model.add(Dropout(0.5))\n",
        "\n",
        "# Definimos una cuarta capa convolucional\n",
        "img_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "img_model.add(Dropout(0.5))\n",
        "\n",
        "# Añadimos nuestra regresión\n",
        "img_model.add(Flatten())\n",
        "img_model.add(Dense(512, activation='relu'))\n",
        "img_model.add(Dropout(0.5))\n",
        "img_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilamos el modelo\n",
        "img_model.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(lr=0.001, decay = 1e-6), metrics=['mean_absolute_error'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv2wVdPtrhvS",
        "outputId": "50d40d56-7380-44e7-f53b-b5512a87a461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "15/15 [==============================] - 1s 29ms/step - loss: 0.0432 - mean_absolute_error: 0.1629 - val_loss: 0.0526 - val_mean_absolute_error: 0.2044\n",
            "Epoch 2/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0364 - mean_absolute_error: 0.1495 - val_loss: 0.0499 - val_mean_absolute_error: 0.1984\n",
            "Epoch 3/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0357 - mean_absolute_error: 0.1494 - val_loss: 0.0364 - val_mean_absolute_error: 0.1651\n",
            "Epoch 4/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0343 - mean_absolute_error: 0.1441 - val_loss: 0.0343 - val_mean_absolute_error: 0.1593\n",
            "Epoch 5/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0338 - mean_absolute_error: 0.1419 - val_loss: 0.0351 - val_mean_absolute_error: 0.1618\n",
            "Epoch 6/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0330 - mean_absolute_error: 0.1406 - val_loss: 0.0333 - val_mean_absolute_error: 0.1570\n",
            "Epoch 7/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0329 - mean_absolute_error: 0.1409 - val_loss: 0.0282 - val_mean_absolute_error: 0.1411\n",
            "Epoch 8/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0334 - mean_absolute_error: 0.1427 - val_loss: 0.0274 - val_mean_absolute_error: 0.1384\n",
            "Epoch 9/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0338 - mean_absolute_error: 0.1431 - val_loss: 0.0252 - val_mean_absolute_error: 0.1297\n",
            "Epoch 10/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0331 - mean_absolute_error: 0.1396 - val_loss: 0.0248 - val_mean_absolute_error: 0.1283\n",
            "Epoch 11/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0327 - mean_absolute_error: 0.1390 - val_loss: 0.0270 - val_mean_absolute_error: 0.1375\n",
            "Epoch 12/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0323 - mean_absolute_error: 0.1377 - val_loss: 0.0269 - val_mean_absolute_error: 0.1371\n",
            "Epoch 13/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - mean_absolute_error: 0.1397 - val_loss: 0.0261 - val_mean_absolute_error: 0.1333\n",
            "Epoch 14/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0318 - mean_absolute_error: 0.1366 - val_loss: 0.0267 - val_mean_absolute_error: 0.1361\n",
            "Epoch 15/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0328 - mean_absolute_error: 0.1409 - val_loss: 0.0288 - val_mean_absolute_error: 0.1433\n",
            "Epoch 16/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0322 - mean_absolute_error: 0.1381 - val_loss: 0.0263 - val_mean_absolute_error: 0.1344\n",
            "Epoch 17/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1366 - val_loss: 0.0267 - val_mean_absolute_error: 0.1342\n",
            "Epoch 18/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0313 - mean_absolute_error: 0.1370 - val_loss: 0.0267 - val_mean_absolute_error: 0.1342\n",
            "Epoch 19/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0324 - mean_absolute_error: 0.1390 - val_loss: 0.0247 - val_mean_absolute_error: 0.1257\n",
            "Epoch 20/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0325 - mean_absolute_error: 0.1383 - val_loss: 0.0253 - val_mean_absolute_error: 0.1286\n",
            "Epoch 21/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1378 - val_loss: 0.0247 - val_mean_absolute_error: 0.1245\n",
            "Epoch 22/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1361 - val_loss: 0.0252 - val_mean_absolute_error: 0.1285\n",
            "Epoch 23/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0313 - mean_absolute_error: 0.1367 - val_loss: 0.0252 - val_mean_absolute_error: 0.1270\n",
            "Epoch 24/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0305 - mean_absolute_error: 0.1345 - val_loss: 0.0277 - val_mean_absolute_error: 0.1330\n",
            "Epoch 25/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0331 - mean_absolute_error: 0.1417 - val_loss: 0.0258 - val_mean_absolute_error: 0.1326\n",
            "Epoch 26/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0325 - mean_absolute_error: 0.1397 - val_loss: 0.0263 - val_mean_absolute_error: 0.1337\n",
            "Epoch 27/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0314 - mean_absolute_error: 0.1384 - val_loss: 0.0261 - val_mean_absolute_error: 0.1285\n",
            "Epoch 28/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1362 - val_loss: 0.0247 - val_mean_absolute_error: 0.1254\n",
            "Epoch 29/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1363 - val_loss: 0.0250 - val_mean_absolute_error: 0.1247\n",
            "Epoch 30/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1360 - val_loss: 0.0254 - val_mean_absolute_error: 0.1277\n",
            "Epoch 31/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1371 - val_loss: 0.0273 - val_mean_absolute_error: 0.1325\n",
            "Epoch 32/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0311 - mean_absolute_error: 0.1347 - val_loss: 0.0243 - val_mean_absolute_error: 0.1229\n",
            "Epoch 33/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0315 - mean_absolute_error: 0.1373 - val_loss: 0.0249 - val_mean_absolute_error: 0.1259\n",
            "Epoch 34/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0310 - mean_absolute_error: 0.1365 - val_loss: 0.0262 - val_mean_absolute_error: 0.1295\n",
            "Epoch 35/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1366 - val_loss: 0.0267 - val_mean_absolute_error: 0.1315\n",
            "Epoch 36/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0310 - mean_absolute_error: 0.1363 - val_loss: 0.0253 - val_mean_absolute_error: 0.1264\n",
            "Epoch 37/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0303 - mean_absolute_error: 0.1344 - val_loss: 0.0248 - val_mean_absolute_error: 0.1227\n",
            "Epoch 38/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0308 - mean_absolute_error: 0.1354 - val_loss: 0.0253 - val_mean_absolute_error: 0.1255\n",
            "Epoch 39/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0301 - mean_absolute_error: 0.1342 - val_loss: 0.0251 - val_mean_absolute_error: 0.1238\n",
            "Epoch 40/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0299 - mean_absolute_error: 0.1322 - val_loss: 0.0259 - val_mean_absolute_error: 0.1278\n",
            "Epoch 41/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0317 - mean_absolute_error: 0.1369 - val_loss: 0.0260 - val_mean_absolute_error: 0.1309\n",
            "Epoch 42/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0307 - mean_absolute_error: 0.1354 - val_loss: 0.0263 - val_mean_absolute_error: 0.1317\n",
            "Epoch 43/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0302 - mean_absolute_error: 0.1343 - val_loss: 0.0256 - val_mean_absolute_error: 0.1264\n",
            "Epoch 44/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0303 - mean_absolute_error: 0.1344 - val_loss: 0.0260 - val_mean_absolute_error: 0.1283\n",
            "Epoch 45/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0303 - mean_absolute_error: 0.1349 - val_loss: 0.0252 - val_mean_absolute_error: 0.1254\n",
            "Epoch 46/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0309 - mean_absolute_error: 0.1357 - val_loss: 0.0263 - val_mean_absolute_error: 0.1313\n",
            "Epoch 47/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0302 - mean_absolute_error: 0.1342 - val_loss: 0.0280 - val_mean_absolute_error: 0.1368\n",
            "Epoch 48/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0305 - mean_absolute_error: 0.1348 - val_loss: 0.0261 - val_mean_absolute_error: 0.1297\n",
            "Epoch 49/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0308 - mean_absolute_error: 0.1356 - val_loss: 0.0246 - val_mean_absolute_error: 0.1252\n",
            "Epoch 50/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0305 - mean_absolute_error: 0.1353 - val_loss: 0.0260 - val_mean_absolute_error: 0.1287\n",
            "Epoch 51/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0305 - mean_absolute_error: 0.1339 - val_loss: 0.0243 - val_mean_absolute_error: 0.1239\n",
            "Epoch 52/150\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0306 - mean_absolute_error: 0.1347 - val_loss: 0.0249 - val_mean_absolute_error: 0.1236\n",
            "Epoch 53/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0301 - mean_absolute_error: 0.1343 - val_loss: 0.0252 - val_mean_absolute_error: 0.1265\n",
            "Epoch 54/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0294 - mean_absolute_error: 0.1330 - val_loss: 0.0259 - val_mean_absolute_error: 0.1285\n",
            "Epoch 55/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0300 - mean_absolute_error: 0.1332 - val_loss: 0.0252 - val_mean_absolute_error: 0.1260\n",
            "Epoch 56/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1305 - val_loss: 0.0257 - val_mean_absolute_error: 0.1286\n",
            "Epoch 57/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0294 - mean_absolute_error: 0.1327 - val_loss: 0.0295 - val_mean_absolute_error: 0.1421\n",
            "Epoch 58/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0300 - mean_absolute_error: 0.1331 - val_loss: 0.0266 - val_mean_absolute_error: 0.1327\n",
            "Epoch 59/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0292 - mean_absolute_error: 0.1317 - val_loss: 0.0257 - val_mean_absolute_error: 0.1287\n",
            "Epoch 60/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0296 - mean_absolute_error: 0.1319 - val_loss: 0.0257 - val_mean_absolute_error: 0.1286\n",
            "Epoch 61/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1313 - val_loss: 0.0256 - val_mean_absolute_error: 0.1262\n",
            "Epoch 62/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0298 - mean_absolute_error: 0.1343 - val_loss: 0.0267 - val_mean_absolute_error: 0.1300\n",
            "Epoch 63/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0293 - mean_absolute_error: 0.1315 - val_loss: 0.0271 - val_mean_absolute_error: 0.1346\n",
            "Epoch 64/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0297 - mean_absolute_error: 0.1325 - val_loss: 0.0254 - val_mean_absolute_error: 0.1281\n",
            "Epoch 65/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0292 - mean_absolute_error: 0.1327 - val_loss: 0.0259 - val_mean_absolute_error: 0.1243\n",
            "Epoch 66/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1311 - val_loss: 0.0243 - val_mean_absolute_error: 0.1226\n",
            "Epoch 67/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0290 - mean_absolute_error: 0.1307 - val_loss: 0.0266 - val_mean_absolute_error: 0.1271\n",
            "Epoch 68/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0300 - mean_absolute_error: 0.1340 - val_loss: 0.0252 - val_mean_absolute_error: 0.1243\n",
            "Epoch 69/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0299 - mean_absolute_error: 0.1336 - val_loss: 0.0259 - val_mean_absolute_error: 0.1281\n",
            "Epoch 70/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0299 - mean_absolute_error: 0.1323 - val_loss: 0.0268 - val_mean_absolute_error: 0.1296\n",
            "Epoch 71/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0296 - mean_absolute_error: 0.1334 - val_loss: 0.0253 - val_mean_absolute_error: 0.1245\n",
            "Epoch 72/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - mean_absolute_error: 0.1308 - val_loss: 0.0262 - val_mean_absolute_error: 0.1286\n",
            "Epoch 73/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0288 - mean_absolute_error: 0.1291 - val_loss: 0.0251 - val_mean_absolute_error: 0.1261\n",
            "Epoch 74/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1314 - val_loss: 0.0263 - val_mean_absolute_error: 0.1287\n",
            "Epoch 75/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1317 - val_loss: 0.0263 - val_mean_absolute_error: 0.1324\n",
            "Epoch 76/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0293 - mean_absolute_error: 0.1319 - val_loss: 0.0284 - val_mean_absolute_error: 0.1358\n",
            "Epoch 77/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0291 - mean_absolute_error: 0.1307 - val_loss: 0.0259 - val_mean_absolute_error: 0.1307\n",
            "Epoch 78/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0289 - mean_absolute_error: 0.1305 - val_loss: 0.0275 - val_mean_absolute_error: 0.1343\n",
            "Epoch 79/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0282 - mean_absolute_error: 0.1280 - val_loss: 0.0276 - val_mean_absolute_error: 0.1333\n",
            "Epoch 80/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0286 - mean_absolute_error: 0.1296 - val_loss: 0.0255 - val_mean_absolute_error: 0.1274\n",
            "Epoch 81/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0280 - mean_absolute_error: 0.1280 - val_loss: 0.0282 - val_mean_absolute_error: 0.1333\n",
            "Epoch 82/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0295 - mean_absolute_error: 0.1315 - val_loss: 0.0254 - val_mean_absolute_error: 0.1283\n",
            "Epoch 83/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0299 - mean_absolute_error: 0.1338 - val_loss: 0.0260 - val_mean_absolute_error: 0.1292\n",
            "Epoch 84/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - mean_absolute_error: 0.1286 - val_loss: 0.0250 - val_mean_absolute_error: 0.1245\n",
            "Epoch 85/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - mean_absolute_error: 0.1296 - val_loss: 0.0277 - val_mean_absolute_error: 0.1299\n",
            "Epoch 86/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1299 - val_loss: 0.0250 - val_mean_absolute_error: 0.1250\n",
            "Epoch 87/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0284 - mean_absolute_error: 0.1287 - val_loss: 0.0257 - val_mean_absolute_error: 0.1276\n",
            "Epoch 88/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0288 - mean_absolute_error: 0.1304 - val_loss: 0.0276 - val_mean_absolute_error: 0.1320\n",
            "Epoch 89/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1281 - val_loss: 0.0268 - val_mean_absolute_error: 0.1287\n",
            "Epoch 90/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0292 - mean_absolute_error: 0.1310 - val_loss: 0.0255 - val_mean_absolute_error: 0.1289\n",
            "Epoch 91/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0293 - mean_absolute_error: 0.1316 - val_loss: 0.0250 - val_mean_absolute_error: 0.1255\n",
            "Epoch 92/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0293 - mean_absolute_error: 0.1314 - val_loss: 0.0258 - val_mean_absolute_error: 0.1282\n",
            "Epoch 93/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0284 - mean_absolute_error: 0.1284 - val_loss: 0.0262 - val_mean_absolute_error: 0.1287\n",
            "Epoch 94/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - mean_absolute_error: 0.1274 - val_loss: 0.0248 - val_mean_absolute_error: 0.1246\n",
            "Epoch 95/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1287 - val_loss: 0.0277 - val_mean_absolute_error: 0.1306\n",
            "Epoch 96/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1275 - val_loss: 0.0258 - val_mean_absolute_error: 0.1291\n",
            "Epoch 97/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0277 - mean_absolute_error: 0.1285 - val_loss: 0.0286 - val_mean_absolute_error: 0.1318\n",
            "Epoch 98/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0284 - mean_absolute_error: 0.1285 - val_loss: 0.0282 - val_mean_absolute_error: 0.1385\n",
            "Epoch 99/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0296 - mean_absolute_error: 0.1318 - val_loss: 0.0249 - val_mean_absolute_error: 0.1258\n",
            "Epoch 100/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0282 - mean_absolute_error: 0.1283 - val_loss: 0.0268 - val_mean_absolute_error: 0.1273\n",
            "Epoch 101/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0277 - mean_absolute_error: 0.1277 - val_loss: 0.0251 - val_mean_absolute_error: 0.1242\n",
            "Epoch 102/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0278 - mean_absolute_error: 0.1283 - val_loss: 0.0259 - val_mean_absolute_error: 0.1277\n",
            "Epoch 103/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0280 - mean_absolute_error: 0.1280 - val_loss: 0.0267 - val_mean_absolute_error: 0.1282\n",
            "Epoch 104/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0278 - mean_absolute_error: 0.1278 - val_loss: 0.0283 - val_mean_absolute_error: 0.1324\n",
            "Epoch 105/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - mean_absolute_error: 0.1282 - val_loss: 0.0276 - val_mean_absolute_error: 0.1334\n",
            "Epoch 106/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0285 - mean_absolute_error: 0.1283 - val_loss: 0.0274 - val_mean_absolute_error: 0.1296\n",
            "Epoch 107/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0278 - mean_absolute_error: 0.1277 - val_loss: 0.0274 - val_mean_absolute_error: 0.1313\n",
            "Epoch 108/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0279 - mean_absolute_error: 0.1282 - val_loss: 0.0278 - val_mean_absolute_error: 0.1334\n",
            "Epoch 109/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0282 - mean_absolute_error: 0.1285 - val_loss: 0.0283 - val_mean_absolute_error: 0.1374\n",
            "Epoch 110/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0287 - mean_absolute_error: 0.1306 - val_loss: 0.0281 - val_mean_absolute_error: 0.1326\n",
            "Epoch 111/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0275 - mean_absolute_error: 0.1270 - val_loss: 0.0259 - val_mean_absolute_error: 0.1263\n",
            "Epoch 112/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0270 - mean_absolute_error: 0.1267 - val_loss: 0.0267 - val_mean_absolute_error: 0.1283\n",
            "Epoch 113/150\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0282 - mean_absolute_error: 0.1273 - val_loss: 0.0261 - val_mean_absolute_error: 0.1271\n",
            "Epoch 114/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0278 - mean_absolute_error: 0.1281 - val_loss: 0.0274 - val_mean_absolute_error: 0.1346\n",
            "Epoch 115/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0282 - mean_absolute_error: 0.1290 - val_loss: 0.0271 - val_mean_absolute_error: 0.1316\n",
            "Epoch 116/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0275 - mean_absolute_error: 0.1260 - val_loss: 0.0260 - val_mean_absolute_error: 0.1256\n",
            "Epoch 117/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1282 - val_loss: 0.0264 - val_mean_absolute_error: 0.1247\n",
            "Epoch 118/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0281 - mean_absolute_error: 0.1287 - val_loss: 0.0292 - val_mean_absolute_error: 0.1311\n",
            "Epoch 119/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0273 - mean_absolute_error: 0.1262 - val_loss: 0.0258 - val_mean_absolute_error: 0.1286\n",
            "Epoch 120/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0274 - mean_absolute_error: 0.1267 - val_loss: 0.0306 - val_mean_absolute_error: 0.1389\n",
            "Epoch 121/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0274 - mean_absolute_error: 0.1269 - val_loss: 0.0267 - val_mean_absolute_error: 0.1313\n",
            "Epoch 122/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - mean_absolute_error: 0.1275 - val_loss: 0.0281 - val_mean_absolute_error: 0.1328\n",
            "Epoch 123/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0273 - mean_absolute_error: 0.1261 - val_loss: 0.0272 - val_mean_absolute_error: 0.1305\n",
            "Epoch 124/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0269 - mean_absolute_error: 0.1251 - val_loss: 0.0293 - val_mean_absolute_error: 0.1366\n",
            "Epoch 125/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - mean_absolute_error: 0.1259 - val_loss: 0.0266 - val_mean_absolute_error: 0.1325\n",
            "Epoch 126/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0288 - mean_absolute_error: 0.1301 - val_loss: 0.0281 - val_mean_absolute_error: 0.1315\n",
            "Epoch 127/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0272 - mean_absolute_error: 0.1263 - val_loss: 0.0262 - val_mean_absolute_error: 0.1283\n",
            "Epoch 128/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0268 - mean_absolute_error: 0.1256 - val_loss: 0.0275 - val_mean_absolute_error: 0.1342\n",
            "Epoch 129/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0274 - mean_absolute_error: 0.1267 - val_loss: 0.0267 - val_mean_absolute_error: 0.1285\n",
            "Epoch 130/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0274 - mean_absolute_error: 0.1260 - val_loss: 0.0281 - val_mean_absolute_error: 0.1315\n",
            "Epoch 131/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0279 - mean_absolute_error: 0.1284 - val_loss: 0.0253 - val_mean_absolute_error: 0.1261\n",
            "Epoch 132/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0272 - mean_absolute_error: 0.1266 - val_loss: 0.0284 - val_mean_absolute_error: 0.1289\n",
            "Epoch 133/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0273 - mean_absolute_error: 0.1256 - val_loss: 0.0270 - val_mean_absolute_error: 0.1309\n",
            "Epoch 134/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0270 - mean_absolute_error: 0.1254 - val_loss: 0.0291 - val_mean_absolute_error: 0.1369\n",
            "Epoch 135/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0270 - mean_absolute_error: 0.1244 - val_loss: 0.0266 - val_mean_absolute_error: 0.1316\n",
            "Epoch 136/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0271 - mean_absolute_error: 0.1248 - val_loss: 0.0281 - val_mean_absolute_error: 0.1332\n",
            "Epoch 137/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0268 - mean_absolute_error: 0.1245 - val_loss: 0.0265 - val_mean_absolute_error: 0.1297\n",
            "Epoch 138/150\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.0262 - mean_absolute_error: 0.1242 - val_loss: 0.0276 - val_mean_absolute_error: 0.1325\n",
            "Epoch 139/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0270 - mean_absolute_error: 0.1246 - val_loss: 0.0289 - val_mean_absolute_error: 0.1373\n",
            "Epoch 140/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0275 - mean_absolute_error: 0.1262 - val_loss: 0.0273 - val_mean_absolute_error: 0.1306\n",
            "Epoch 141/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0274 - mean_absolute_error: 0.1267 - val_loss: 0.0259 - val_mean_absolute_error: 0.1269\n",
            "Epoch 142/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0276 - mean_absolute_error: 0.1276 - val_loss: 0.0282 - val_mean_absolute_error: 0.1313\n",
            "Epoch 143/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0265 - mean_absolute_error: 0.1241 - val_loss: 0.0277 - val_mean_absolute_error: 0.1301\n",
            "Epoch 144/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0268 - mean_absolute_error: 0.1248 - val_loss: 0.0273 - val_mean_absolute_error: 0.1278\n",
            "Epoch 145/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0264 - mean_absolute_error: 0.1246 - val_loss: 0.0275 - val_mean_absolute_error: 0.1317\n",
            "Epoch 146/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0275 - mean_absolute_error: 0.1263 - val_loss: 0.0262 - val_mean_absolute_error: 0.1275\n",
            "Epoch 147/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0261 - mean_absolute_error: 0.1209 - val_loss: 0.0285 - val_mean_absolute_error: 0.1319\n",
            "Epoch 148/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0270 - mean_absolute_error: 0.1275 - val_loss: 0.0287 - val_mean_absolute_error: 0.1392\n",
            "Epoch 149/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0271 - mean_absolute_error: 0.1254 - val_loss: 0.0264 - val_mean_absolute_error: 0.1304\n",
            "Epoch 150/150\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0269 - mean_absolute_error: 0.1248 - val_loss: 0.0289 - val_mean_absolute_error: 0.1327\n"
          ]
        }
      ],
      "source": [
        "img_model_grafica = img_model.fit(X_train_resized, y_train,\n",
        "          batch_size=64,\n",
        "          shuffle = True,\n",
        "          epochs=n_epochs_img,\n",
        "          validation_data=(X_validation_resized,y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd7N7LPCw_uG",
        "outputId": "d9679a38-b28b-494a-9008-36f34d6a9db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0361 - mean_absolute_error: 0.1439\n",
            "Pérdida en el conjunto de prueba con los mejores hiperparámetros: [0.036140527576208115, 0.1439100205898285]\n"
          ]
        }
      ],
      "source": [
        "test_loss_img = img_model.evaluate(X_test_resized, y_test)\n",
        "print('Pérdida en el conjunto de prueba con los mejores hiperparámetros:', test_loss_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "T-E4gRRPsz2Q",
        "outputId": "e23416a5-1616-4ff0-c3a7-982a8f18efbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4e1e0c5a30>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEJCAYAAABVFBp5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd2BV5f348fdz7szNIoMkhCWEJUMZEQEpslTUiqhFraO2UGt/tViw1VarX1oVxVFHBUdbtGppixWromIREFEQBRWUTZiBJGTv5K7z/P44yQ2BADchC/m8/iH33jM+597L/ZxnK621RgghhGgCo60DEEIIcfqSJCKEEKLJJIkIIYRoMkkiQgghmkySiBBCiCaTJCKEEKLJ7G0dQFvIyspq0n6JiYnk5+c3czTNS2I8de09PpAYm4vEGL7U1NQGn5eSiBBCiCaTJCKEEKLJJIkIIYRosjOyTUQI8d2itaa6uhrTNFFKhb3f4cOH8Xq9LRjZqWvNGLXWGIaB2+0O+32UJCKEOO1VV1fjcDiw2xv3k2a327HZbC0UVfNo7RgDgQDV1dVERESEtb1UZwkhTnumaTY6gYiG2e12TNMMe3tJIkKI015jqrDEyTXm/ZTUHab3dhTRuVAzOF6+rEIIUUtKImH6cHcxy7bntnUYQgjRrkgSCVNChJ28cl9bhyGEaIdKSkr4+9//3uj9br75ZkpKShq938yZM3n33XcbvV9LkCQSpgSPg1xJIkKIBpSWlvLqq68e83wgEDjhfq+99hqxsbEtFVarkDaRMCV47BRX+fEHTRw2yb1CtFfmv/+Kztwb3rZKEc4K4aprD4zrbz3u6w8//DD79+/noosuwuFw4HK5iI2NJSMjg08//ZRp06aRlZWF1+tl+vTp3HTTTQCcf/75LF26lIqKCm666SaGDx/Ohg0bSElJ4aWXXgqrm+0nn3zCgw8+SDAY5Nxzz+WRRx7B5XLx8MMPs2zZMux2O2PGjOH//u//WLJkCU899RSGYRATE8Obb74Z1vt0IpJEwpTgsd6qwqoAyVHONo5GCNGe3HvvvezYsYMPP/yQtWvX8qMf/YiVK1fSrVs3AP70pz8RFxdHVVUVl19+OZdddhnx8fH1jrF3717mz5/P448/zm233cb777/PNddcc8LzVldXM2vWLBYtWkRaWhp33HEHr776Ktdccw1Lly5l9erVKKVCVWZPP/00CxcupFOnTk2qRmuIJJEwJXgcABRUShIRoj07UYnhaHa7/aRVTk0xePDgUAIBeOmll1i6dClgzSK+d+/eY5JI165dGThwIADnnHMOmZmZJz3P7t276datG2lpaQBMnTqVV155hZ/85Ce4XC5+/etfM3HiRCZOnAhAeno6s2bN4oorruDSSy9tlmuVepkw1ZZE8iub/wsnhPhu8Xg8ob/Xrl3LJ598wpIlS1i+fDkDBw5scBoTl8sV+ttmsxEMBpt8frvdznvvvcfll1/O8uXLufHGGwF49NFHufvuu8nKyuLSSy+lsLCwyecIneuUj3CGSIiorc7yt3EkQoj2JjIykvLy8gZfKysrIzY2loiICDIyMvjqq6+a7bxpaWlkZmayd+9eevToweLFixkxYgQVFRVUVVUxYcIEzjvvPEaOHAnAvn37GDp0KEOHDuWjjz4iKyvrmBJRY0kSCZPHYRDhsElJRAhxjPj4eM477zzGjx+P2+0mMTEx9NrYsWN57bXXuPDCC0lLS2Po0KHNdl63282TTz7JbbfdFmpYv/nmmykuLmbatGl4vV601syePRuAhx56iL1796K1ZvTo0QwYMOCUY1A6nK4J3zFNXdlwxvv76RJt57ff69zMETWf9rIK2om09xjbe3wgMR6tsrKyXhVSuFqqTaQ5tUWMDb2fsrJhM0iKclIgJREhhAiR6qxGSIxysa+goq3DEEKcIe699142bNhQbyzLT3/6U6677ro2jKo+SSKNkBTlpKgqQNDU2AyZiFEI0bIefvjhdl/lJtVZjdAx0kVQQ4m36V3vhBDiu0SSSCN0jLYGGRZUSjdfIYSAVqzO2rhxIy+//DKmaTJhwgSmTJlS73W/38+8efPYs2cP0dHRzJw5k6SkJHJzc5k1a1aoZ0Dv3r352c9+BsCePXuYP38+Pp+PIUOG8JOf/KRFF6fpGGkNBiqoDNA7ocVOI4QQp41WSSKmabJgwQLuu+8+EhISuOeee0hPT6dLly6hbVauXElkZCTPPvssa9asYeHChcyaNQuAlJQUHn/88WOO+9e//pXbbruN3r1788gjj7Bx40aGDBnSYteRFFVbEmm/9ZNCCNGaWqU6KyMjg5SUFJKTk7Hb7YwaNYr169fX22bDhg2MHTsWgBEjRrB58+YTzq5ZVFREVVUVffr0QSnFmDFjjjlmc+vgcWA3pDpLCHFqevfufdzXMjMzGT9+fCtGc2papSRSWFhIQkJd/U9CQgK7du067jY2mw2Px0NZWRkAubm53H333URERHD99ddz9tlnN3jM480Ds3z5cpYvXw7A3Llz640mbQy73U5ipIty09bkY7Q0u93ebmOr1d5jbO/xgcR4tMOHD2O3N+3nrKn7narjnddmsx3zemvH6HK5wv7s2n0X37i4OJ577jmio6PZs2cPjz/+OH/6058adYwjZ7EEmjyKNjExkSiHIrekst2OFpaRzKeuvccHEuPRvF5v6Mf3bxsOs7eoOqz9VJjrifSIc/PT9OTjvv7www+TmprKj3/8Y8Ca+t1ms7F27VpKSkoIBALcfffdXHLJJaF9jtdtt3bixUAgQHV1Nb///e/ZuHEjNpuN2bNnc8EFF7Bjxw7uvPNOfD4fWmv+8pe/kJKSwm233UZ2djamafKrX/2KK6+8Mqz34Wher/eYz+54I9ZbJYnEx8dTUFAQelxQUHDMpF+12yQkJBAMBqmsrCQ6OhqlFA6HNQ17z549SU5OJjs7O6xjtgSHTRE0z7iZYoQQJzB58mRmz54dSiJLlixh4cKFTJ8+nejoaAoLC7niiiu4+OKLG9X5p3bJ3RUrVpCRkcEPf/hDPvnkE1577TWmT5/O1Vdfjc/nIxgMsnLlSlJSUnjttdcAa7XF1tAqSSQtLY3s7Gxyc3OJj49n7dq13HHHHfW2GTZsGKtWraJPnz6sW7eOAQMGoJSitLSUqKgoDMPg8OHDZGdnk5ycTFRUFBEREezcuZPevXuzevVqJk2a1OLXYjcUAUkiQrRbJyoxHK25BvINHDiQ/Px8cnJyKCgoIDY2lqSkJP7whz/w+eefo5QiJyeHvLw8kpKSwj7u+vXr+elPfwpAr1696NKlC3v27GHYsGH8+c9/Jjs7m0svvZSePXvSr18/HnjgAebMmcPEiRM5//zzT/m6wtEqScRmszFt2jTmzJmDaZqMGzeOrl27hlbjSk9PZ/z48cybN48ZM2YQFRXFzJkzAdi6dSuvv/46NpsNwzC49dZbiYqKAqzh/8899xw+n4/Bgwe3aM+s0LUYCm/AbPHzCCFOL9///vd57733yM3NZfLkybz55psUFBSwdOlSHA4H559/foPriDTFVVddxZAhQ1ixYgU333wzjz76KKNHj+aDDz5g5cqVPPbYY4wePTrUw7UltVqbSO0c9kc6cv4Xp9PJnXfeecx+I0aMYMSIEQ0eMy0trdHtI6fKYSAlESHEMSZPnsxdd91FYWEhixcvZsmSJSQmJuJwOFizZg0HDx5s9DGHDx/O4sWLGTlyJLt37+bQoUOkpaWxf/9+unfvzvTp0zl06BDbtm2jV69edOjQgWuuuYaYmBj+9a9/tcBVHqvdN6y3NzZDEZSCiBDiKH379qWioiI0nOHqq6/mlltuYcKECZxzzjn06tWr0ce85ZZb+P3vf8+ECROw2Ww89dRTuFwulixZwuLFi7Hb7SQlJTFjxgw2bdrEQw89FGpHfuSRR1rgKo8l64k0QmJiIr99axN7Cr08P7lnM0fVPKTXzqlr7/GBxHg0WU+kecl6Ii3IrhTBMy/vCiFEg6Q6q5HsNkUgKElECHFqtm3bdkwvVZfLxbvvvttGETWNJJFGsilFQEoiQrQrp2Ot/Nlnn82HH37Y1mE0qDHvp1RnNZLdJuNEhGhvDMNo920bp4tAIIBhhJ8apCTSSA5DqrOEaG/cbjfV1dV4vd5GjQh3uVzNNnajpbRmjFprDMPA7XaHvY8kkUayKaRhXYh2RilFREREo/eTXm6nTqqzGsmqzjo962CFEKK5SRJpJHtNUVlqtIQQQpJIo9kNK4lI47oQQkgSaTSbJBEhhAiRJNJIUhIRQog6kkQaqTaJyMJUQgghSaTR7DXvmJREhBBCkkij1ZZE/JJEhBBCkkhj1VVntXEgQgjRDkgSaSRpWBdCiDqSRBpJuvgKIUQdSSKNJCURIYSoI0mkkaSLrxBC1JEk0khSEhFCiDqSRBpJkogQQtSRJNJIMthQCCHqSBJppLqSSBsHIoQQ7YAkkUaSLr5CCFGn1ZbH3bhxIy+//DKmaTJhwgSmTJlS73W/38+8efPYs2cP0dHRzJw5k6SkpNDr+fn5zJo1i6lTpzJ58mQAbr/9dtxuN4ZhYLPZmDt3botfh7SJCCFEnVZJIqZpsmDBAu677z4SEhK45557SE9Pp0uXLqFtVq5cSWRkJM8++yxr1qxh4cKFzJo1K/T6K6+8wpAhQ4459uzZs4mJiWmNywCki68QQhypVaqzMjIySElJITk5GbvdzqhRo1i/fn29bTZs2MDYsWMBGDFiBJs3bw6tY/7FF1+QlJRUL+m0FSmJCCFEnVYpiRQWFpKQkBB6nJCQwK5du467jc1mw+PxUFZWhtPp5O233+b+++/nnXfeOebYc+bMAeCiiy5i4sSJDZ5/+fLlLF++HIC5c+eSmJjYpOuw2+0kdUwAduGK8DT5OC3Jbre3y7iO1N5jbO/xgcTYXCTGU9dqbSJN9frrr3P55ZfjdruPee3BBx8kPj6ekpISHnroIVJTU+nfv/8x202cOLFegsnPz29SLImJiZQWFQJQUlbe5OO0pMTExHYZ15Hae4ztPT6QGJuLxBi+1NTUBp9vlSQSHx9PQUFB6HFBQQHx8fENbpOQkEAwGKSyspLo6GgyMjL4/PPPWbhwIRUVFSilcDqdTJo0KXSM2NhYzjvvPDIyMhpMIs3JJlPBCyFESKskkbS0NLKzs8nNzSU+Pp61a9dyxx131Ntm2LBhrFq1ij59+rBu3ToGDBiAUooHHnggtM3rr7+O2+1m0qRJVFdXo7UmIiKC6upqvvnmG37wgx+0+LUYSmEoWZRKCCGglZKIzWZj2rRpzJkzB9M0GTduHF27dmXRokWkpaWRnp7O+PHjmTdvHjNmzCAqKoqZM2ee8JglJSU88cQTAASDQUaPHs3gwYNb43KwG0oa1oUQglZsExk6dChDhw6t99x1110X+tvpdHLnnXee8BjXXntt6O/k5GQef/zx5g0yTHZDSRdfIYRARqw3iZREhBDCIkmkCWySRIQQApAk0iQOQwYbCiEESBJpEpuhpIuvEEIgSaRJ7IaSLr5CCIEkkbBpM4j2eYGa3llakogQQkgSCZM5+5eU/PkhoKZ3VlCSiBBCSBIJl9OFrq4CpIuvEELUkiQSLqcb7a0GpIuvEELUkiQSLpeURIQQ4miSRMLlqiuJ2BXSsC6EEEgSCZtyuutKIjZFINjGAQkhRDsgSSRcLlddm4hSBKQkIoQQkkTC5qoriTikTUQIIQBJIuFzusHnRZumVZ0lSUQIISSJhM3lsv71ea3qLEkiQgghSSRsLrf1r69aSiJCCFFDkki4nDVJxOu1uvhKEhFCCEki4VK11VneahlsKIQQNSSJhKu2OstbXTPtCWjp5iuEOMNJEglXbXWWz4vDUADIRL5CiDOdJJFwHVGdZatNIlKlJYQ4w0kSCZcrAgBd0yYCyOqGQogzniSRcB0xTsQuJREhhAAkiYTviIb12iQiPbSEEGc6SSLhch6ZRKw/JYkIIc509tY60caNG3n55ZcxTZMJEyYwZcqUeq/7/X7mzZvHnj17iI6OZubMmSQlJYVez8/PZ9asWUydOpXJkyeHdcxmZbeDYbOmPQmVRFrudEIIcTpolZKIaZosWLCAe++9l6eeeoo1a9Zw8ODBetusXLmSyMhInn32WS6//HIWLlxY7/VXXnmFIUOGNOqYzUkphXK7wVsd6uIrJREhxJmuVZJIRkYGKSkpJCcnY7fbGTVqFOvXr6+3zYYNGxg7diwAI0aMYPPmzaHBfF988QVJSUl06dKlUcdsbsoVUa8kIg3rQogzXatUZxUWFpKQkBB6nJCQwK5du467jc1mw+PxUFZWhtPp5O233+b+++/nnXfeadQxay1fvpzly5cDMHfuXBITE5t0HfnuCJxo4jvEAoeIjIklMTG6ScdqKXa7vcnX11rae4ztPT6QGJuLxHjqWq1NpKlef/11Lr/8ctxud5OPMXHiRCZOnBh6nJ+f36TjKJeb6tISKsvLACgoLCLf7m1yXC0hMTGxydfXWtp7jO09PpAYm4vEGL7U1NQGnw87iWzevJmkpCSSkpIoKipi4cKFGIbBDTfcQIcOHU64b3x8PAUFBaHHBQUFxMfHN7hNQkICwWCQyspKoqOjycjI4PPPP2fhwoVUVFSglMLpdNKzZ8+THrO5Kbe73jgRaRMRQpzpwm4TWbBgAYZhbf7qq68SDAZRSvHiiy+edN+0tDSys7PJzc0lEAiwdu1a0tPT620zbNgwVq1aBcC6desYMGAASikeeOAB5s+fz/z587nsssu46qqrmDRpUljHbG7K5ZZxIkIIcYSwSyKFhYUkJiYSDAbZtGkTzz33HHa7ndtuu+2k+9psNqZNm8acOXMwTZNx48bRtWtXFi1aRFpaGunp6YwfP5558+YxY8YMoqKimDlzZpOO2ZKUOwLyc7HJOBEhhAAakUQiIiIoLi4mMzOTLl264Ha7CQQCBAKBsPYfOnQoQ4cOrffcddddF/rb6XRy5513nvAY11577UmP2ZKUy11vFl9JIkKIM13YSWTSpEncc889BAIBfvzjHwOwfft2Onfu3FKxtTvKHVFvFl8ZbCiEONOFnUSmTJnC8OHDMQyDlJQUwGoM//nPf95iwbU3VpuINKwLIUStRnXxPbKL1+bNmzEMg/79+zd7UO2VckeArxqblUNksKEQ4owXdu+s2bNns337dgDeeustnnnmGZ555hnefPPNFguuvVEuN2iN3fQDUhIRQoiwk0hmZiZ9+vQBYMWKFcyePZs5c+bw4Ycftlhw7Y1yWwtT2fySRIQQAhpRnVU7j1VOTg5AaB6rioqKFgirfVI1qxs6AtYodUkiQogzXdhJpG/fvrz00ksUFRVx3nnnAVZCiY5uX3NHtSRVM/WK3V8NQFB6ZwkhznBhV2fdfvvteDweunfvHhqvkZWVxWWXXdZiwbU3tSURm09KIkIIAY0oiURHR3PDDTfUe641B/q1B7UlEcPvxVAO/JJEhBBnuLCTSCAQ4M0332T16tUUFRURFxfHmDFjuPrqq7Hb2/1kwM2itiRizZ/llC6+QogzXti//v/4xz/YvXs3t956Kx07diQvL4/FixdTWVkZGsH+XVdbEtE1Aw6lOksIcaYLO4msW7eOxx9/PNSQnpqaSo8ePbjrrrvOoCRSUxLxWVOfSBIRQpzpwm5Yr+3ieyZTrpqFsWqmg5ckIoQ404VdEhk5ciSPPvooP/jBD0IrbS1evJiRI0e2ZHztSqgk4vViVxCUxCqEOMOFnURuuukmFi9ezIIFCygqKiI+Pp5Ro0aFPRX8d4LTBUqBrxq7TREItnVAQgjRtsJOIna7neuuu67eGiA+n4+bb76Zm266qUWCa2+UUlYi8VZj9ygCUhIRQpzhwm4TaYhSqrniOH04XaHp4KVNRAhxpjulJHJGcrmt6ixDEQhKEhFCnNlOWp21efPm4752RrWH1HK50d5qbEqqs4QQ4qRJ5Pnnnz/h64mJic0WzGkhviPs342rr6LSLzMwCiHObCdNIvPnz2+NOE4bxgUTMV+YS7K3mHWVEW0djhBCtClpE2msc4dDh3hSDm6l1Buk3Cf9fIUQZy5JIo2k7HbU9y6h095NAGSX+do4IiGEaDuSRJpAfe9iUqoLAcgu87dxNEII0XYkiTSBiksg5SxreWApiQghzmSSRJrI3aMXCdXFZBdXtXUoQgjRZlptNamNGzfy8ssvY5omEyZMYMqUKfVe9/v9zJs3jz179hAdHc3MmTNJSkoiIyODF198MbTd1KlTGT58OGAt2et2uzEMA5vNxty5c1vrclDde9HpQC5ZBbGtdk4hhGhvWiWJmKbJggULuO+++0hISOCee+4hPT2dLl26hLZZuXIlkZGRPPvss6xZs4aFCxcya9Ysunbtyty5c7HZbBQVFXHXXXcxbNgwbDYbALNnzyYmJqY1LqO+7ml0WraVzyu7W9dYM/DQOBOnghFCnLFapTorIyODlJQUkpOTsdvtjBo1ivXr19fbZsOGDYwdOxaAESNGsHnzZrTWuFyuUMLw+/3tZr4u1SGeFCop1XYqfEGe+zyH+1dktnVYQgjRqlqlJFJYWEhCQkLocUJCArt27TruNjabDY/HQ1lZGTExMezatYvnn3+evLw8ZsyYEUoqAHPmzAHgoosuYuLEiQ2ef/ny5SxfvhyAuXPnNnmUvd1ur7dv1/goALJ9Tj7aW4qhoEN8Anaj7RLd0TG2R+09xvYeH0iMzUViPHWt1iZyKnr37s2TTz7JwYMHmT9/PoMHD8bpdPLggw8SHx9PSUkJDz30EKmpqfTv3/+Y/SdOnFgvweTn5zcpjtrFuGolJURDBTz38a7QjL5b92WTGuNs0vGbw9ExtkftPcb2Hh9IjM1FYgxfampqg8+3SnVWfHw8BQUFoccFBQXEx8cfd5tgMEhlZWVoPfdaXbp0we12k5mZGdoHIDY2lvPOO4+MjIyWvIxjdOphtensLvYR47JKR5ml3laNQQgh2lKrJJG0tDSys7PJzc0lEAiwdu1a0tPT620zbNgwVq1aBcC6desYMGAASilyc3MJBq2pRfLy8sjKyqJjx45UV1dTVWV1r62uruabb76hW7durXE5Ia4eacR7iwH44TlWcTOzRMaNCCHOHK1SnWWz2Zg2bRpz5szBNE3GjRtH165dWbRoEWlpaaSnpzN+/HjmzZvHjBkziIqKYubMmQBs376dt956C5vNhmEYTJ8+nZiYGA4fPswTTzwBWCWX0aNHM3jw4Na4nBAVE0eqvxSf08PEtFje2FzAwRIpiQghzhxK6zNvUYysrKwm7ddQ3eSuv/2Fyr27OefXd/GHryup8Js8MemsZoiyadpL/emJtPcY23t8IDE2F4kxfG3aJvJd1mvyFQws3o35j+foEuMks8THGZiXhRBnKEkip0gldUJddTN8u4HOhfupDpjkVx674qPOOYj50fttEKEQQrQcSSLNQI3/PvToQ5fP3gUg86h2ER0MYv71CfQ/X0Af2N0WIQohRIuQJNIMlGHDuOQquuRaXYwPltbvoaVXvQ8H9oBS6E8+bIsQhRCiRUgSaS7nDCfWoYjR3nolEV1ciH7rHzBgCOr8C9Gff4z2Sg8uIcR3gySRZqIcDtT5Y+hSmk1mkTV+RWuN+a8XIRDAuOE21PcuhqoK9JeftnG0QgjRPCSJNCM1cgIplXkcLq4EQH+xGr76DHXlDaikVOg9AJI7oz9Z1ibx6a/XobdubJNzCyG+mySJNKezehHpslPpMzH/91/0P1+Enn1RF1trpyilUBdOgoxtmGtXtHp45ht/x/zbn9De6lY/txDiu0mSSDNSShHVfyDVNieBN/4Ofh/GT36FMupmHVbjvw/9zkG/9hx6784THk+bZrPFprWG4nwoK0F//EGzHVcIcWaTJNLMPJ07A+D94/MY9z+NSulS73Vls2H87G6IjcN87hF0RXmDx9EH92HOuA69/ZvmCayiDHw+UAb6f29K474QollIEmlmHof1llbGJKI6dWlwGxUdg/H/7oGSIvTb/2hwG/3lGvB5MRctQJvBUw+syJohWY2/HEqL0Z9IaUQIceokiTSzSIdVdVXpP3FVlOqehhp3GXrVB+gDu9HeavS+uoW69DcbIMIDB/ei161q8Bjm+k8JPj+X4G+nY67/5MSBFVpz76jhYyCtH3rNyvAvSgghjkOSSDPzOGtKIr6Tt2eoK2+AqGjM5x7BvOsnmHN+jf72S3RxARzYjZp0DZzVG/3WQrTvqFHwOYfQf3kM9u4Enxe98r0TnksX1UzgFp+IGjjMSk7lpU27SCGEqCFJpJmFqrNOUhIBUJ4o1PW3QkkhauBQiO+IueRf6G+/tF4/5zyMH/wEivLRa+r35tJbvgLAuOth1MTJkLEVXZB3/JMV5YPNBjEdUP0GWc/t3NyEKxRCiDqSRJqZp6Y6q8IfXjuGMXwMxnOLMX52F+rSH8Denej3Xof4jtC5O/QZAN3S0B8vrTc7sN7yNSSlojqmoM4bbT234QRVWkX5EBtv9RQ7qzc4Xejt3zb9QoUQAkkizS6yESWRWkop698LJkKHBCjIRZ2Tbo0rUQo19lI4tB8ytgGg/X7Y8S1qwBBrv6RUq9rri+MnEV2YD3EJ1vZ2B/Tqj94hSUQIcWokiTSzxrSJHE05HFY7CKDOGV73/PAxEBGJXrXUeiJjK/i8qAFD629zYDeBQwcaPnhRASq+Y932/QZB1gF0aVGj42wqHQxivvF3gvmHW+2cQoiWJUmkmTltBnZDhV2ddTQ17lKMX/0BBh6RIFxu1Mhx6K/WoEuKrPYQmx36DqzbJn00KEXxnN9gvvNPdHFh6DWttVWdVVMSAVD9zrFe29GK7SKZe9D/e5OqD/7beucUQrQoSSItwOMwqGpEddaRlGFDDRwaquIKPT/2MtAa88FZ6M9XQ+/+KHdE3etxCRi3/RYjviP63UWYf7wDvdlqoKeiDPw+iEusO2C3NHBHQCMGM5rL3yH4wK/QZSVNujadlQmAd+MXTdpfCNH+SBJpAR6HQUUTk8jxqE5dMH73GMTGQXGB1U336G2GjSL+ofkYf5xnjYh/5k1toL0AACAASURBVI+YnyyrGyNyRBJRNhtq4DD02hXobZtOen5z/afoRX+DzL3ohS807SKyrKq2wJ4dTU5EQoj2RZJIC4h0GlT6mmGU+VHUWb0x7n0C41ezrZHnx9uuU1eMe5+Ann3RS9+wqrIA4hPrb3fT/4Pkzpjz52Cu+wj91VrMFUswX34G899/RVdWAKA3f4l+6Sno1R91xfXoL9dgrm/8dPY6OxOcLtBaZhMW4jvC3tYBfBd5HLZG9c5qDGWzQQOlkGO2c7pQF05Cv/wMesMa68kj2kQAVGQ0xsw/Yj72O/SCpwh1II6OhYoy9DfrUX0Gotcsh87dMW6/12rg//ZL9KvPYu7aguo7EJ2bDeVlqCk3ohzO4weVnQmDhqF2boEtX8H5Fx53U52XA5HRKE/kSa9VCNF2JIm0AI/DIKfc39ZhoIaORC98Hv3Fx6GBhsds0yEe4/+ehoP7weW2BiPGxqEztlrrwq9dgZp4Jeqqm1BOFwDGz+7C/M9L6E8/RH90xEj5jimosZeiAwHY9AUMPt9KemBN+Jh/GDVyPM4ID95vNqBNE2UcWxjWleWYD85CDRqGuvU39V/btgkcTlSvs5vxnRJCNJUkkRZgNaw3f3VWYym3BzV4pJVE4jvWm5L+6O046kdZ9eqPMftZq/0ltVv91zqmYPvFvejqSsjKhJTOmE//Ab3sv+gxF6Pf/w96yb9QP/qltZojQM5B0BqV2hVX9x54P10OB/dBt57HxKM//qBmBci16OuKUTXJT3+1FvOFx8DhwLjnMVSXHqf+JgkhTom0ibQAj9PW7A3rTaVGjrP+OKoqK6x9PZHHJJB6r7s9qJ59UZ4ojEuugrwc9NLF6KX/AUCvWBIaZa+za8avpHbDOfh8MAz0ynePOab2+9ArlkBqNwgG0J9ZE0XqLV9j/uUJOKsXeCIx5z+MzstB7/gW88O3MV96CvOdfzX6GsWZZ8vhSrYcrmzrML4zpCTSAiJruvhqrY/pqtvqzj4X4hJRyZ1b9jxDRkDHFPRb/wBPJOqKH6L/+5rVhfjsc60Si80GHTthi09EXXKVlXCGfw/Vfwi6rBRshtV+U1KEMf1OzHf+hV79P3RaP8znHoZOXTFm/gGyD2I+fi/mvT+rO39EpFV66dYTNfj8lr1WcVp7bVMepobHLune1qF8J7RaEtm4cSMvv/wypmkyYcIEpkyZUu91v9/PvHnz2LNnD9HR0cycOZOkpCQyMjJ48cUXQ9tNnTqV4cOHh3XMtuJxGJgaqgJmaC6ttqJsNqtrsMvdsucxbKiLp6AXvoC65hbUyPHo5e9grliC7exzrZ5ZSakou/WVU1f8EP31OsxX56PS+qHXfwraBGVA917Q7xxUcSH6pacw/3Q/xHfEmPUHlCcK0vph3P579MG9qK49rCoxTxTmQ3diLnweo89AaZAXx1XuCxI09ck3FGFplSRimiYLFizgvvvuIyEhgXvuuYf09HS6dKlbtGnlypVERkby7LPPsmbNGhYuXMisWbPo2rUrc+fOxWazUVRUxF133cWwYcNQSp30mG3Fc8SaIm2dRADUUV17W+w8F16K6tEXuvW05vwac4nVPrJjs1US6XpW3bYOJ8YtMzAfuwddXoa6aDLExNU0vo+zSnDDRlljU1wujDsfRMXE1e0/aBhqUP1easYtd2A+chd68d9RN9/eKtcsTj8VPhNfsH1UN38XtEoSycjIICUlheTkZABGjRrF+vXr6/3gb9iwgalTpwIwYsQIXnrpJbTWuFyu0DZ+vz9UPRTOMdtKaDp4nwmeNg6mFSmloHta3ePx30d/sRrzT/cB2prf68jte/XH+L9nrOq2yKhjj+d0YdzzuFU9Fh178vP36G31Dvt4KfqKH6I6xFtdhfdnWNPCHEEX5qM//xh1yZTjdjhoDB0MYv7hl2Czo0aOt6rUkjq1WnVmu6g6PU1U+IL4glpKI82kVZJIYWEhCQl1DbsJCQns2rXruNvYbDY8Hg9lZWXExMSwa9cunn/+efLy8pgxYwY2my2sY9Zavnw5y5cvB2Du3LkkJjbtztxut4e1b6dyG5CFMzKaxMSYJp2rqcKNsVUkJmI+/RplC56ieuX7xA5Ox5WYWD/Gk8XayGsJXHMzBR+9h2fjZ0T+4BYKn56Nf8vXJKaPxJaYHNqu+O/P4F2zgtiB5+IaMqLeMex2OwkdOlC9ainu712MOuJG5nh8WzdRlHMIW3IqwTdeRr/xMkZcAhGTf4jnyh82+w/8ke9h9dqVlM6fS/wz/8CWmNSs5zkV7eq7WCMQNPEGreThjOrQLmM8WnuP8bRoWO/duzdPPvkkBw8eZP78+QwePLhR+0+cOJGJEyeGHufn5zcpjsTExLD2DVRVAZCVV0iKw9ekczVVuDG2qh/+HGPSVMriEijLz2/ZGF0e6DuI8g/+S2VyF8wtXwNQsGwJxsVWm5k+uA9zrdXrq2TpfzG69rJ6kRXkohKTSUxMJO+dRejX5lN2cD/G969HB4Po9atR55xntcscxfx0hdXj7N4nMMrL0Ns3YX75GeWvzKMicx/qup82OCamqWrfQ11Wivn8Y1BZTsG61RgjxjbbORpDV1eCzxfqjn1kjO1JaXUg9Pf+7FziPJ3bXYxHay/vY2pqaoPPt0oX3/j4eAoKCkKPCwoKiI+PP+42wWCQyspKoqOj623TpUsX3G43mZmZYR2zrdROB1/RhOngv6tUE7oYN/lcF06CglzMBU9Ch3jo3B1dswZ9ld9ky/vLwOVGDb8Q/fU6dEU5+oM3Me+5Fb3xc7TWoe7Hetlb6Ioy9AeLrVH9/3i+wXPqb7+EXmdbq1UmdcIYM8manuaiK9Er30W/vbBFrlX/+69QVQl2B+xruCTeGvTCFzCf+H2bnT9cR3a9L/O2/Viu74JWSSJpaWlkZ2eTm5tLIBBg7dq1pKen19tm2LBhrFq1CoB169YxYMAAlFLk5uYSDFofdl5eHllZWXTs2DGsY7aVxiyRK5qfGjwComKgpAh12VRrrMy+XejcbJZvyOB+z2jKx09BXTwFAn70kn+h3/knAOZ/XsL3zQY4tB814QqorsJ85Vn0kn9BbBx6/Sfob9bXO58uzIeDe1GD6n//lGFgXDsdBqWjP/+43sqUxxPONqFtd2xGf/Ex6rKp0LMPes+OsPc9lfM2tK/e9g1kZ6LLS5t8nNZQfsScdqWSRJpFq1Rn2Ww2pk2bxpw5czBNk3HjxtG1a1cWLVpEWloa6enpjB8/nnnz5jFjxgyioqKYOXMmANu3b+ett97CZrNhGAbTp08nJsZqZ2jomO1BbRJp6poi4tQohwM14fvoLz5Bjb4YSovQb/wd/f7rFBTGYCaPpPD8ScR06mCVUlYssebpuvkX6JefoeSJ+8EThbrqR1BWgv5iNXSIx7jvKcwn77e6EfcegIqwek3UTrl/dBIJxXNOOvrbDZCbDckNVwno6kprMGVuNsYv70OlnHxcj966EQwDdcnV4K1Gr1yC9vtRDkfY75WurLAGha5YYnVgOHsw6vJrG9ejryAXSmrWr9mXUW8tnPZgZ34VkU4bnWOc9WoHyo4zSWpmiZeDpT5Gdo1u8HVRX6u1iQwdOpShQ+t/ua677rrQ306nkzvvvPOY/caMGcOYMWOOef54x2wPIuwGhqLJa4qIU2d8/3r4/vXWg4QkSOuHXrOC0oE3AFCEgx5KoS6YiH59Aer6WzFGjCW4/hP05q9Ql1xlNahfeQM6KxPj2mmo2DiMH/0S89HfYf7xDoxrp8HZg62SSXxHa5R9A1T/IWhAb/0adUQS0Rs/R+/ZDqnd0B++bU0D4/ZgPno3xi/vR6X1O+E16gO7IbWbFWfPPuhlAesYPXqH9R5pnxfzj3dAYR6ccx4oZS0NUFGK7ee/C+sYALpm2WYAvT8D1c6SyFNrs+jewc3vxnSm8ogbu9LqhpPI4i0FrD1Qxojr+jRbh4ji6gCxLtt3sgfdadGwfrpRShHRAmuKiKYzLpqC6VtEWb9hkB+ksMpqYFXjLkd1S4M+A6ztrrsVu+0lAuOvsF5PSsU2+5nQcVRaP4zfPIT5zxcxn59b9/yFk477A6GSOlmj+bd8DeOsKfzNNcvRrzwLtdVILjfGL++H5E7WOjBP3Iu66mZr8suGJqnU2uq6XFv66dHHen7vDlSYSYRdW6EwD/XTX2PUzKhsLnzBSiReb1i90gDYvR1cERATi96XEd4+rURrTV5FgBiX9XmHUxLJKvPhDWoqfCZRrlPv/p1X4ee2t3dz74VdSO98bKeM1lBQ6afcZ9IlxonNaOaegs16NBHisbfMmiKiadSwUdiGjaJ82X6gqi6J2I9aZjilM3F/eOaEvWFUn4EY9z+N3vCpVY0TCKBO0itK9R+MXvcxOuBHf7HaSiBnD8b4+W+h4DBExaA6WJ0PjN89jvnqs+j/vIzeuQXj9t8fk6DMwnwoK7FWqARr1crYONh74sZ17a1G1cxeoLd8BXaH1YZ0xPukV70PW76EoaNOeKzQMTO2Qc8+qOgO6F1bwtqntZT7TPympsRbk0RqSiJuu3HcNpGsMmsG7vxKP1EuG9rntZJtStPGoO0tqiaoYX+x96RJ5IUvchiSGsn5XZq3Ku2jvaW8tjGPf1/bh4hmTiIyAWML8ThPbU2R7DIftyzexcESbzNGJWp/OAorAyfZ8sSUzYZx/oUYF1+FcdlUVHzHE2/ffwh4q9CLFqD//mfodw7G7feiIjyoLj1CCQRARcdg/OJe1OQbrCn1d9b9MGuf9X0I1DSiq+7WLMhKKejRB71353Fj0BnbMGfdhLlmhfV4y9fWMstHljh6D4CoGPSXa094Paa2BuvpqkqrE0Kvs63JMYvy0SVFJ9y3MXRhPsEnfo/OPtik/QsqrYRQUlN1VeEzMRQkRzoa7J1V7g2Gni+o+Y7opYsxH5xpLWfQBNk1SSmv4sTLQxRWBVi6q5iVe0591c/lu4tZuCkv9Di/wk+U0yDC0fw/+ZJEWkjkKVZn7civorg6yK6C6maMSoSSSNWpJZFG6zfIGkey6n3oOwjj9vtC67M0RCmFuuQqiIzGrOlubL79T8y7p6FLi/Dv2QFKwRHT4auzesPhQ+hvNxzTS0pXV2G+9BT4fej3FqEL8iDrAGpA/fYLZbOhhoxAb1qP9h9/jNPTa7P53bL9+HfvAG2i0s62zg9W43ojnKhnmH7jZdjxLfrLxq+kCXWfc6XfxB80qfAF8TgMYty2BpNIdnndNRfU7Ku3bwKfD7L2NymGrDLrmPmVJ04i23KtmYX3FjX9xjFgal74Iodn1+Xwn80F+Gumd8mv9NMxMvwOF40hSaSFnOqaIrVfvJPdvYjwmVqHungWtXISUZ4o1JCRMCjd6n3VQHvD6n2lvPp1bt0+Tpe1HsvX69BffYZ+/3VrxclVHxDYvQOSO6PcEXXb9x8ChoH55wcwf/Nj9KYvQq/pN1625iWbcAXk5WD+8wVrnwFDjo112AXgrYKagZoN2VtUzc6Cav69rcRKZj37QtceoAz0/vDHq+jNX2HOuB6dc+jY13ZuDo3v0TubVk125M1CiTdIhd8k0mkj2mVrsDorq/SIJFLptxJpzfgbnbkn7POWHDGose7/8om/c1vyrEHKh8v99boiN8brm/NZuquYXvFuNJBfU5rKqwiQ6GmZ1gtJIi3E47Sd0mDD7FIreeRKEmk2FT6T2umSWr0kAqjb7sZ2x/+F2iSOtnJPCUt3FdffZ+ylAJgvPGqtTNlnIL7Vy9hxqNDqEHDktj16Yzz5D4w7H4TO3TBfehpdkIu5dDH64w9QF01BXTsNEpPhm/WhgZjH6DsIIqOtmZWPo7AqgN1Q/NebxLZeI61qOXcEdOpywsb1Q6U+Xv06NzRvlV67wqrmW/bfetuVVfl4adlmdncegBp9Eezebq2YeQK6qOCYbY6stiypDlLhM4l0GMS4jlMSKfOjgGinYf0A790FtcfM3HvC89faV1TNLYsz2JZnlSyyS8O7IdyWW4nLpmqOUb80orXGDGMsT0ZBNT3iXPxkqDX9zeHyuvadRI+URE4rkQ6DkuoggSZO8ha6eznFuntRp/ZHo6PHTlFVIKz/lM3pZN07c8p9VPqtKpfQPglJMOR80CbGjf8P4/KpfOTpxW9630xJ12N7YanIKNTZ52Lc9lvQJuZDd6LffAU1fIy1xLFhQ110pbXtgCENxqTsdtR5o9EbP7PaPABdWoze8jV6y9dUF5dQ7jO5MilAYnUxr/WYVLdvjz6QsRVdWd7gNa7YXczirYWsP1RuLUD2zQaw2dGfrUQXW2NNtNa8uvgT3okbzG97/4i/Jo4m4PfDgd2h4+hAgOALczG/WG093rsT895b0f/+S902xYUU5NbNalFSHbCqs5w2op02ynxBTK3ZklvJp/ut6r+sMh8dI+0kRzkpqAygd23Bazg4eNa56OMkEa01B4rrfvQPlvrQwKacSnxBk/zKAJ6a6u3az3btgdJ6SazSH2RfsZexPayJRvcW1a/GnvPxIR77JOukg0Jzyv2kRDlJqqm6yq3wU+U3KfeZJEp11ullSKdIqgImX2U1/J/pRLTWZEt1FmBV8ezIr2qWY9VWX3Tv4CKo29eI5aCpyQ3dNda/cTBu/DnG/7vHmhn47MHkdDwLU9nI73j85YFVUieMW+6AijLUxMmo6Xei7NaPiLpgIgxKt+7wj7f/yPHg86E3fGoNhHxwJubTszGfnk3+n/4IQOquDQyqOMBho27tFjXhCqiqRP+vfslCZ2zDfHshe/MrAHh3RxFs3QTeKtR10yFoWoMltWb7W0tYpjpzie0wF/eO4/3iCD5PHFi/59e+nfDlWvSCJzE/WWZ1tw5YK2HqivJQzAWbN+MOWj/wxdU11VkOg2iXDVNbDekLN+Xx7LpsvAGTrDIfKdFOEjx2qzorYxtv9Z/Mb866Hm/WQbR5bO3CusxyZry3l0M1JY7aqtIdeVXklPvRwMBkT+izzS338+gnWSzdWdcBYXteFaaGC7pH08FtY89RJZHt+VV8llnGx/uOPyOAqa3vUHKUgwSPHUNBbrk/1BYj1VmnmWGdo4h121i+u/E9LUpr6m6dNkVehf+UpqQ4nWmtef6LHP6zuXkmnyut6eZ5VpxVnXSqPbSaU16Fn5rJZY+5cVAxcaihI62/laKwW38ACjp0OuEx1bBRGE//E+OoyR+Vy21Vq/Xqf/yde/SBlM7Wj/L7b0BxIerW32D84l4KA9bYifg9m+jQuRMl3mCoVKe69kANH4Ne/g7Bwny0aWK+/x/Mx+9Bv7uIvQfzcWLy7eFK9n39DUREor53sdW1eMUS/Hf9hBdyo0jQ1fz46tFMq6mWye7Ys167iN72TahjgX51HpSXon78KyvxrV2BXvY2lBZT2KkX3bESV0lpBRW+IJFOGzE14z+KqnzsLqymOqD5KruC7DIfqdFOEj12q3fW7m3sTOiFDxs5RhTk5RzzVm2pqbbK2r2P4IMzKSq0/s/vKKgKtbGcm+IJfba7C61SxpGJYmtuFYaCvokR9Ihz1yuJVPgClHmDGAr+tuEwxdUNf2+LqgL4TU1ylAOboUj0OMir8IduSqRh/TRjNxTjesSy4VD5cT/046n94g1I8uAL6lO+Y35jS0GouH46yasIUOk3Q3d4p6rsiJIItE27yPHklNcljpN2BfVYE40WBRseCKe15quscmuNkaNWeMwq9YVVjaeUskoju7ail73Fqgtu5KvOQ1FDRlB0iTUTQIJZTYfeva07+iPa/9SVN0AwQPHc32He+zP0f19DDbuA0l8/RpEzmsn7P8Kpg7xX5EadOxxld6C+fz2kdueNQdewLyqV6Rechcdpw2U3iIuwczixuxWLaX2Gevs30LUnxp0PwJARGNPvxLhggjUzwYol6GVvwdBRFNoj6ZKagMP0U7L/AJV+k0inVRIB+DarlOqA9X78b1cx5T6T1GgnCR4HFX6TKl+APXZrZuJDno7QQON6Rk0PyoJVK+HAHor2Wr24Knwm6w9ZNRHnpFifQ16Fnz01CWJfcV2i2JpXSVq8G7fdoEeci8wSL/6au4rDpVaymTowgaqA1fuqoRvL2vaPlCgrWSRFOcit8Ie+T1ISOQ1NSIslqOHjvY37Aa9tD6m9eznVxvW3txXyv6MabE8H+2vqmXPK/aGuiqeiNhmf1Q6TSG31JdRVZ/mDJp8fLOMvGw7ztw2HQz8cta8XHKcktSW3ij9+dJBvD1fWez6/0s/t7+5h6c7wvgtqxDjrbt9uZ1HMEBZvsdoXCpPOAiD+BzfSIdYaPHfkjZJKSkWNvYzA3p2Q2g3jtrtRt/6G/bHW3HaDBqUxJudLPk4YxLd9v2ft07kbW6Y/wOv23ozvGcMFPeqmlE+JcnDYkwhVFXDogDVeY892VL9zUJHR2H5xL2qYNTBSjbvcmsvL50VPvpGS6gAJHeOJCVZTeDjfSiI1DesAn23PAqBvVTZfZ1sllk7RVnUQQEZ0V0pqkvXByBR05l4CZl0bSNDUoZJFQaUfkjtTWFxGVM14jDX7y4hx2egS48Ru1CSRmu1zyqz2Cl/QZFdBNf07Wj3tesS5CZiQ+dVGdMBP5i4rcQ09vJkbz03ks8xylmUcW8NRm0SSapNIpIPDFVZ1lgISWqhhXUast6BusS76JLhZsbuEK88Of5r6rDI/hqqrR82r8NM7IeIkezXMGzAp9QY52Ex3862pNomYGrLL/XSLDXMajuMo9QaxG9Ap2gm0rySSU+7HaVPEuGzk19w0/PvbAt7YUtcwfO2gRKKdRijuguPEf7hmrMPRNx8Hir2YGlbsKeHyvnEN7VqPik9EXX4dumMnig5oqmu+QwVVAdx2RdT5o+hQk6iKqwL1Ph917XQ63nonBWVloedqq2h6XnwRnTp/w7atfmbvj2KSM4cYt41lu4rpHOPkZ+kp9eJIjnKwpSzC6j68+n+oIedbswT0OwetNYu3FNIn0c05KZFWtdh/X0MNSqc4LgVT7yY+wk6s205OpfVzF7F+FZHZX0OPH7F+XwFuZfCD/SuZ0+9GAFKjnaH3eH234aE4DsV3R2du5H+7ivnrhsPMG90B78cf4LNZI/4LU9IwJl5K8QcH6KtK2emMocxn0q1DBIZSJHgc5FUG2F3kJaami/GBEi/egIkvqBmUbJVWegStJL/n7Xfo/soj7EkcCr2n0PHj/3LlAxeyKaeSv315mAp/kM8OlNEl1smMgtXkHHaCu3+oUT050kFhZYCcMj9xEXbszTxSvZaURFrYeV2i2F/ipToQ/p10dpmP5CgHKVHWj93J+pefSO1da2FVoN7kc+H4365i7lnWtAFWzWF/sZfa731zjNwv8waJdtlx2BSxLlu7ahOp/cyTIh3k1TSE7iyookeci7u/lxraptxn/eAAFB5n8FrtZ55/1Pemtlpwd2E1mWG+n8aVN1A1bAy+oKakZjR3YWWA+AgHSik6RFg/zMVHTWaoDOOYsTD7irwkeOzEuGwkDx3Ck9cPYUJaLEt3FbPo2wIcNoO7RqceM6o6JcpBfrVJ4MLL0B9/gLl8Cdhs0Ls/eRUBXtuUxx8/ymTtgVKU3YHx4POoH/4sVFJL8NjpEBdDdoQ1M3Fk5k6iO1gzgVfYI0jrGMXgn/6EyEAVhjZJMitJPGjNCLAhaRAK6JcYwaGoZMjcw5bcSjSwetUGdu22xrdEBasp7NIX1b0XRRFxxGfvpne5Ncq+U4U19qejx86ugiqKqgJceJZ1/r1F1Xx7uBJDwYBk60Yx+d2/4wr62DvyCtSIsRQPGYsTk9jD+zBys5g1shMeh8ErX+dxoMTL6n2lVK9ZxeHiKuLdNpw26/1LinKggW15VS1WlQWSRFpcbSLILQ+/SiqrpnEvymngtqtT6qF15CjZxrYtfJVdzta8KnzNUJXUFPuLvfRPskpjzVGSKvUGiXHWNAp77GGXRKw7+Jbt3JBTZnXNTIx0kF8ZQGvN3iIvafHu0B1+dpkvNI2HzVDHjb/2x/PoEdJZZT6cNoWhYFUjqliPPM+hUh+FVQHia36UOritf0vCaPfbW+SlR4e6xOK2G8wY0Yl/X9uHN3/Yl79OSQt1ejhScpTTGjg3cSpERcO3G6BHH5Q7ItRzr2Okg8c/zWLDoXJrKQCjrsQWH+EgNjqCUqdV9Rb1g5uJvv231AzJoHdyNM7uPRnTLYruFTnYXnuWDisXA5ATsJMa46R3gptDtmjM4iK2Z1tVSat9HdjddxSRToOzuyVQGDAImppSm5u4slz65VtT0HTa+hl64zoSIx2hKVCGJxpEOgz2FXnZlFNJ7wQ3HocN/c16bJs3cJYrwB5HAsZNvyAvOY2kSDsKa3Bmhwg7j1zUnUcv7s6vL0glYEKG381hdxzJ9rrPoaPLusDcipYbrQ6SRFpcck39ZE55/R/B7DIf89Zl88XBstDAK6jr3tsp2olSio6RjlNqEzkyATU2iRzdZbE1+YOag6Ve+ia4SfTYOVRy6kmkzBsk2l2TRCLsYV3XB7uKmPHe3lADaUvQWpNT7qNTtIOONV1L8yutHjk949wkRzlQWImmNkH0SvQctzqrNnkc3WaSVeqjW6yLwSmRfLy3JOzEeGQSOVjqpaAyQEJNCSTKaS17cHRJ5Gi+oMnBUi89GkgSEQ7jhDPL1v4fOhx0oK7+EQCq7yDA6gHltCmemHQW8RF2lmXUtfccWRKJddfdiUd1TEApFWpc7xVvxXTrhb14tHcVfLsB165viVbWNfWMc9E5xolXG+zskU6B36CHWUq2J5E1tlR6xbtJ8DgorApQXB1Ao4gbfzFn32AtO9A5ysB88XESP1saiuGsubfT3VfI1txKdhVUMSg50urJ9p+XIKUzvXp0Yk9RNUFTk1NWTXJshNVbbstXAKTGOOnXMYKzO1o3WVs7nEWuO45kv5XgzFXvk/joHaHzJWTtHK6XtwAAIABJREFUQgdbpku7JJEWFvoPcFRJ5NP9pXy4u4Q5Hx/iF0v2hBp9i6qDVAc0qTX19kmRjpPOuXMitVUahoKDjfghDpo6dNdUVNX64ykOlXoJaqsnVZcYZ/OVRGp+OOIiTl4S2ZFfxV83HAbqeuA0xso9JWzPO/kYl6LqIN6gDpVEAiahRt6z4lw4bQaJHrtVEqmJ+ezkaCp8Jt4GqknzT1AS6RzjZGyPGPIqA2zJrTxm34Y0VBKpbXg2lCLWbQ81rOeU+dhy+NjjZpb4CGroEdf4dq2UI/4PqVETUDf+HDXemlJ/Z34VveLdRDltDO4UyZbcylByLKwKYCiIcdmIPWJK90iH9XcoiSRYScRmKJzjLoMhI6BDAgkx1vM94910ibX+P64871oAbv52EXZtUhHQ9E6IICHCTqk3GKp6ju+SyqDUaH73vc6M+PGNqPNG0zHR6iyQYvMRdcFYumdtYX+JD1PDOSkeyNgKOYdQl19Lr0QP1QHNoTIf2aVekiId1jxnOzZb68B8sgxz9QdEu2x0CxTzbdIAClwdSCqzvq/6kw9J6BCFgfVeJG77HPOJe9Glzd/BRpJIC4t12XDb1TFJJKfcT6zbxqxRncgp9/PxXusOorbXR2qM9aVN9DjIrbCqNzYfrmTtgVI2HCoPu7dSXqWfOLeNTtGN+yHOrfCHRtsf74690h9kzf7SFhnHUtuo3r2Di86xLmsU8Cmep8wbJNpZVxIprg7UKwUeqdwX5NFPDhEfYZUO9hc3rk2m0h9k/ufZvLHl5GNcantmWSUR6weztuRT25OsU4yT7HKrOksB/ZKsqpmGemgVNFAS8QZM8ioCpMY4Ob9rNDYFG7PDTCI1x0mKdLAtr4qAqYmPqLuz7+C2UVzzHfnnN/nM+fjgMZ9VbaN6Q9VVJxMXYcdhKHLK/Zgo/hGbTo6KxB802V3opW+i1ZYwMMlDuc8MfVaFVVaDss1QxLqPSCJO62fv/7d35vFRlffC/54ze2bJbNlDIAkJu4qAIFVBwbYurVy3tl69pfLWVlBKvXrBtq/Xz6sWrXKlVbwutdh69f3Y673QYl/1Uza5iigEcScSwhLIRjJZJsvs5/3jzDnJZIEQlon6fP9KZs7M/M7vnPP8nt/y/B6XxYDLatSNFKilzfLt9yI/sAa/XX0GSzxWCl3qdXg7IGEmweSuGs7PUj831mfVw3tapZbHZkSSJC4scmJye5Bv/TnZl39L/b4CH/ItixkzVt3EzESC8X4byrtbwGJDmnqh7h19XN9FeyjWY0SiEZS1v0X505Mo//HvKJUfM6Gpkk/thSiSRE5Dtbpd8+H9GGdfqp+D/6JL1Eq75G6cpxNhRM4wkiSRYzfT0NnfiOQ5zMwtzmSs18qmZPvnN/a1YDfLjE8+GNnJltUvf9TELzce5pH/qeWBrUfYMsSYdlNnFL/dRKHLzNH2oQ+EvUNfg83Yn9vVyG/erj3pAXYoHGoNY5CgwKV6IqFY4pSqqRKKQjDS44n4M0wklMHLp3ce6aC5K8ayC/Mo99uOe47rP2/ul/j/oK6TWAKqAyfWTb1uRMxk2dXBaE9dJzkOE/ak0ctzmKlLhrPcVgN5yVlyX52EYmqLC4dZbbOhFVPUBdVWHPlOM1ajzBiPhX3NQ+sEEAjFsJtkSr0WvkjmILwZvY2IUQ9n1bSF6Ywm+hWD7DzaQabVkDJgDxVZkshxmGjoiLCnrpP/+izACx80Ut0SJpZQeoxIsprxk6QnpBYAqHL2Dmdpnsg3ilzccF5+v9YvkiQhWTP0ktgSrxW31YDdJBOKJSjPtmP+zVqumJJHpsXAhCyb/jtVmhGx9k9ka3mJkqQ3VnLJRQCMazuIOVCPsuttpGmzkSxWClxmLAaJd2vU6rZshwnKJ4PRpO5jc+4F4M0iseYhJgb2o6CeQ3bTQZR3Nqrnce7MnnLfqech37MSyWQ+af2fCGFEzgI5ThMNwT5GJBjRH6h5pZkcaAnz9qF2dtR0cEWZR69Q0QaVP3/SzEWjnay+cgwWg8ThIVbXNHXF8GeYKHCZqQ1GB51596W3ERnIE6ls6tb3PRhOu/oTeRWHWsMUuiyYDBKFSa/sVEJaXcnmi67kjHRKcsCpGKQtzYf1nbgsBiZk2xjtttDQER1wu+P2cJy1u4+pbTx6sfOI+r3N3bETJp3rO9SS7iy7SW+SF4krKaGfPKdJLwn1ZpjIShZsNPcJWWnehzawal6EtvaoIKnLMp+NqubQkPIiga4YHpuRApdFX1Xvs/UYA7fVQGtI7UWm3Te9jW5bKMbOIx1cWpw57F31chwm6juiekHAjpoONiW7QZT7VYOaZTeR6zDxcUOXuqNhV0/Yrbcnoj1bV43zcOvMgbc0BphT7OL6ST5cyW1tNd2N89uQMuycn+/gT9eX4bYadYOjeSJuW/+FoIUuM7ecl8X8UjWsNdptIcMI05s/J7H6fgh1I82+DFBDa6Veqx5yzHGYkCwWpG/Mg/NnI//kX5D/aQl0dzEh2FNBmRMKoPx9PWTnQ26BXu6blWE6Y1vzCiNyFsixm2jo7AnHROMJmrti5DrVC3zJaBcmWeK379ZhlCWu7lXDr90EE7NsLLswj2KPlXyXOaVl9WCoW4NGybIbKXCZiSUUGjujPLurgcffqT1uu+mj7REcZhnvALmDhKLw3K4GPMnZ2ckakU/rgyxav5/thwf3pg60hvWV5drDezI5nb5oOSctnJXvMlPoMvP+kf5GRFEU9tR3cU5uBrIkMdptQYEBDbe2JqN3f694QqGitpOs5ACmtbdo7oqmGJSKox08sKWG1ypbyLabMMoSdrOM1ag+lsXuntCPtralqjmEL8Oohyn6Jte1PIhmRLT8SG2yK7SWayvzWemMJoZ0H2nVWNp1APqEs1RPpKkzRjhpZQ710tW2g+3EFbisJPOEvzUYuQ4TdcEIO44E+UaRE4tB4s2qVvwZxpRFdJNzMpINFYMcbY8wOVndl2lJrhExHj+J35tJ2Rnccl7PZmNaXmR8Vv81W1qhQU1bGIdZ1stseyNJEtdP8uFJHmsxyjyzoIyryzLVdireLHVTsCSlXqvedVobB+SbF2O4fQWSyYw0cSrSFdeRNWNm8v4BT6QDuruQzrsASZIo91nJyjDqk6czgTAiZ4Ech4lQTK2zBzVBqNBT/uuwGJg5ykEkrnBZSaZ+kwGU+238ZEYOv5xTiCl5Y+Y7zUOqtApGEoTjCll2kx7TXfdZgL9VtrD1YDt3vX5QXz3bl6PJJKxngCqmdw8H2dcc4odTsxnrsw45LALqTO2udZ/Q3BXjPz9pHtAjqQ9GaO6K6Q+r12bEZpRPKhzXF82IuHolWC8odPBJQ1dK11yAA4EuWrpjnJdsVaEZs4FCWlqu62BrWE9y72sO0R6Oc90kdbfC6kAIRVG4b1MNj2+v0z/7wgeN7GsOMWuUk9svUBfYqRV56vVP9UTUeyWuqAOW3WLEapT7rXXp64loRuVoMKzqMTkLL08uXv1igAlAVzTOLzce5m9J76qlO4rXZtQ9QiDlHnXbDMQSSsp90FtXm6rbGOu16nocDjkOM6GYQiSu8J3xHr5V5k45Tw0tL/LEjjpKvVauLFcnZJonouVDhkOxx4pR7v+b2veaDRIJpafseSi4LAaMV98IzkykS76V0uNMS/hbjXLKfdsb+dofIt+ymBkFdko8Vgx5BQBI56qLJL9d5ubZBaXIZ8gLAWFEzgp9K7S0PkmaJwJw9TgPvgwj/zAxdWW7QZa4styDo9dNVOAy09gZ1XvrDEZTr5452izyzapWRmda+PXlRUTjCk++VzfgZ4+2q0bEazPS0icc80FdJw6zzJxiF2U+W8oAOhixhMLrX7Rw36bD2C1Grp/ko7olTGVTiNbuGD/5y37e2KcOWh/Wqy681vZFkiRGZZpTBqa/VbawYW/guL/ZG61vVu8Z2QWFDuIK7K7tTDl21+HW5O+rRiTHYcJqlPTf76137VomlJ54+M6jHcgSXDzaRbbdxP5AiEOtYY60R/ikoYtwLEFrKMbhtgjfneDlZxfmcV5eT48rLaQ1ppcR6Z1L0EI0vuRal08buvjpX/cT6I7pRqMsOQBpRuVoe1Qv1gD1HrIa5X4TgHhC4bG3a/mkQW2PriiK6onYeu6hTKsBk6FnUNIGTS30Uuq16rqqDoQ40BI+JS+k9/nnOkyM99tYMMGLzSin6A168iKxhMLSWbm612Exqh6elmMaDleUufntlcUp+RUNSZL069LbSxsKksOF/MjzSFfekPK6llzPdVlPGIpaNC2HX18+Gql8EmR6oHSCLteZNCAgjMhZQfM4eoxIJOV1gAlZGfzhH8bqM87jke80k1B6QimDoa18zrKbcCbLHCVg8cxcJmVnMD+Zi+lrALqicVq6YxQ4LQOGsyqbuhnnV1s5lPlUl/t4W3p2hOMs+38HeHpnA6PdFp64bgrXT/KRYZL52xct/G5HHfUdUb2n04f1nSmDFqgDU3VLz6K/9Z8398tD9OaNfS38ny01uqejdfB19hpEyn02Mi0G3u+zBmTn4VbynSY9KSlLEqMyLaohaAtz86v79FBcQ0dE30iosqkbRVF4/0iQiVk2HBYDJV4LB1pCeoI0mlD4/Fi3nvzVcjO9KXCZybQa9BAGqIOgFjLRwjc+m9pp9k97jlEXjPJeTZCmzhguiwG72YDbatCNSm0wQkGve8sgS0kvMtUTWbu7kYraTvKdZqoCIVpDcWIJdWC0mw14rIZ+g6RmRD5p7MZuljk3N4Oj7WFi8QSbq9swyhIXJ1doD5fcpOxzil3JAdvE2mvHcnlpqnHKspuYUeDgh1Oz+1WCZSbDr8PFZJApPE7rHe36uE/SiABqeKrPYJ+fNPR5rhN7cAZZwmSQkK5biPyrf0MynLnwVV9E76yzQLbuiaiDfn0witUo4R5mnFKbUR4NRo57U2trRLSy0XmlmViMsh4m0gxAdSDEhOyewUwLlRW4zEQTCdpDceIJBYMs0RGJc7gtog8K2ox3X3P3gLFigK0H26hpi/DP38jn4tFOsjKtNEU7uKwkUzcE4/zq6uODLSE+auhier495aEq9Vp5fV8r9cEoGSaZxs4YEmo1kpZD0IjEE7z8YRNt4TgfNXRxbq5drx7q7YkYZIkZhQ7eORTk396ppTuWYGqenQ+OtjG3z6A3xm1hx5EOnt3VQCiW4JOGLmYXuajviDLabaE9HOeLphCfHevmcFuEn87IAdTy0B01HWw90J6coYf4sL6TzkgCm1HWZ5u9+cE5fr4zztNvUMlzmmjutUbDazPy9uF2tDlARW0niqL08lRMNHfFaE+2K+ltlAHKfVb+ujdANJ7AZJA51hnltcoWrihzMzE7g1Xv1LInuV5FMxwXFDqxGlPl0u7jQ61hxvnVsJVamdbFWwfbuaDQMWg4ZqgUZZq5c1Yus4uc+mt926No/Gpu4YCvj01WWZ0pvBkmoPukPZHBkCWJW8/PpizfBwxtrZZktYF1eH32hovwRM4CVqOM22rQQx/1HRFyHP1nHkNFm1GeKCna1BXFKEv6wPnDqdl8f4pff79skLi4bkQy1ZyIQk+XVq3EUytB9mWY8NqMx02ub65up9hj4ZIxrpRzvqLcjQRMy7fzizkFyBL8ac8xguG43jpbozQ52FYFQlQmQzAKDNgDauuBdtrCcYyyxBv7WoknFDbub2N0pgVbH4Mzt9iFJKn9hQ63hnlmZwPd0YQeytIY7bYQDMf5sL4Lo9zjeTUmd5Ir99n4oqmbv3wewGmW9fBNSXI2XN8R5dJiF+P8Nj6s7+Ljhi4mZdsGTPI6zAZ95t0b7TVtxuvNMOpewvzSTD6q76S+I6r3SfJnGGnqivH+EdUL6muwynxqt1jtXN460I4CLJjgpTw5OdiR/Kw2MC6emcut03JSvqd3DqDAZdFzH/+x6wjt4TjzTjGUBWpYZn6pmwzT8I3Av1xcwG0zck984DDRPZHTaKi+VebmgtEnbpaZToQncpbIcZj0/ll1wWi/WeHJ4EiGpmqDJzAinTH8GcZBY6IemxF/silcb2raIsgS5DlM1AXVW0RdpawuNpMlUroKlw2QXFcUBUmSONwaZn8gpG8u1JtCl4XHrxxDvtOMxShzXq6dimR+QsuHaBS5LZhkif2BUEo30sOt4RRZEorC+s8DlHotTM7O4LXKFv7rs2ZqgxF+cUlBP8M9JcfO/72xXJf5UGuYurCRC7JTBwJtYCz2WCj32dh2sF2vdrtotAu31cC2Q+00H+nghkk+LEljVeLt8RRnjXLSFU3w8kfqAsRvl7k5GYo9FswGSd/mVPM4rp3oJc9pZuP+No60R/QQmS/DyCeNXbxW2cLoTAsTs1NnqJre9tR1UuazsvlAGxOzbOQ6zSiKgsti0PNFvdeF9MWZDJMqqGWshS4zsgSbvmjCYzUwtU/e4quKdj08p8kT+bJw1s52z549rF27lkQiwbx581iwYEHK+9FolCeffJLq6mqcTifLli0jOzubjz76iJdeeolYLIbRaOSWW25h8uTJANx///20tLRgNqsD8q9+9SsyM0991nMmyHGYk1tgqgPPtPxTe7DyXT0VWhv3t3JOjl0PmymKWsXS0Bk5YeO1Mp8txYs43Bbmb5UtTMiyYTLI+gxUq9Da29TNGLclJZRQ5rPy3pEOva3IZ41d/PqtI/zgnCyautQ1EHMGiYn37qU0p9jF7rpOCl3mfnsfGGWJMR4L+wMhZEkd1OuCEQ73KfvddbSDo+1q6KzUa+Uve1t46cMmyn1WLih0HFcXkiQxxmNlut9PU1PqSvNyv40ZBQ6+P8VPdUuIN6taky021GRvUdLIGGUppc262oZczW9k2U2cm2vXjchA+ZDj8a2xHmYUOPTw3YwCB7XtEb45VjVGJlkimugJZ/kzTHRGEhyIhLljZm4/A5plNzE9385/ftqML8PI0fYI/zCzp0qs3GdlV9KIHG9gNMhqC/u2cJxClxmTQabAZaamLcLcU1gb8mXD+zU1ImclnJVIJHj++ef5xS9+weOPP84777zDkSNHUo7ZvHkzdrudJ554gquuuoqXXnoJAKfTyfLly1m1ahVLlizhiSeeSPnc0qVLefTRR3n00UdHrAEByHeqPbB213YSiSsDhitO7vvUtSIf1nfyxI56vcqqOxrn568f5MZXvqCyKZSSnB2Icp+V+o4o7SG14d9DW49gMUrc9Q21/bj2QAS61RYhXzSF+uU+puU7kIA/f9xEQlGSex0keHZXA3/d28K0fPuQko0zC51kmGTOH8TAlnqtVAdCVDWHGO+3Uegy621iAA62hHhyRz05DhOzi5wUuMxqTyLglvOyTmmxldUo86u5hYz1WfVWJDuSyfIch4kSjxoqm1vsShlEJEli2YV5eglvmc+KzSjjMMsp1VdDwWSQyOlVjJHjMHPbjFwsRhmLUe7lgaR6Ki6LgUsGMeJ3zMrDapT53Y56zAaJb4zuyTmUJUOWg6176I0W0ipIrqXQPLfLSkfuM3m6mZpn5/pJPiYMkhv8qnJWTGZVVRW5ubnk5Kix1NmzZ7Nz504KC3sSYLt27eKGG9QSt1mzZvGHP/wBRVEoLi7Wjxk1ahSRSIRoNIrJdOZaG58Jvl3m4e9VbTzyP+r+A8Np/9CbfJeZTdVx/lDRiCypZbEf1HVS+XmQAy1hbpysLmqaUXD82bdWi17ZFGJDZYCmrhgPzh+ll5m6rWoL6pbuGIda1X1Rxvepky/xWvl2mZu/fdGCJMH+QJifXZjH/kCI1ypbuLx0aGEbm0nmd1cVD5qELfVaeSO5Q2O530o4luDjZFnpgZYQ/3tTDSZZ4r5LC/WQ163nZ/NJQ1e/HMupMNptQZbgvRq1qivXoc6+H79yzIBJ1fPze66BQZa4otyNfAZKL6cV2Nld19krJ6Jew2+XufXwWl88NiNLZuaycttRZo1ypuQctLzIUBLFmTYDhvaeisMryjyMy/Wc8kZiXyYyTIaUxYlfF86KEQkEAvh8Pv1/n8/Hvn37Bj3GYDCQkZFBMBjE5eqZQb333nuUlJSkGJCnnnoKWZaZOXMm11133YCzzY0bN7Jxo9pP5uGHH8bv9/c7ZigYjcZhf9YPPHKNncX/+TGgMLEoB797+DOW8QXAnmMcbA3zz3NLeXn3EZ6tOEZDe4jvTs7hZ/PKhvQ9M51upE01/PuuRpo7I9w7fywXT0hNPrpt1XQrJqo7VN1eWF6APzM1Sbtsnpv3j1bw170tTMhxcP2MEmRJ4n9dFCbLkTqQHE+Px1PvtIQV3qtX5R6bT8wQYOvBdixON//+90+wGA2suX4Khb306vfDjKGpYkjyaRR5ajgY6MYgS4wrUtcjDPXW+OfLh3cPnUjG651u4gYLF08Yhckgc5EnwW2dEteem4fTMvijfrXfj93hZGKuE7+zVw7H4YYtR8jJzDihPsbntqNIBnKz1UF0rh/mG43EYiNn46+BOJVn+mwx0mX80gTvampqeOmll/jlL3+pv7Z06VK8Xi/d3d2sWrWKbdu2MWfOnH6fnT9/PvPnz9f/7xvvHir+AWLlJ0OWAe6ancff97diinTQ1NR54g8Ngotkt1+niW/kGVEme/m37XV4M0x8b7zrpOQszFTj198Z52FWjrHfZ91WmQPH2tlWdUzNlUSCNDX1bxfy42nZ/G5HHT88x0ugWd3WVQKaQsGU44arR5eiYJQlzAYJe6ITv0kdoF56dz+VjR3cfkEO1ljnKel1qPIVOU0cDHSTlWGkJdB83GPPBIPJeM1YO20tPYswryqxEQ62Eg72OzSFKR4gHKSpz4Hj/DYK7fIJ9fH9CU4S450px53q83I2EDIOnfz8/AFfPytGxOv10tzc86A1Nzfj9XoHPMbn8xGPx+nq6sLpdOrHP/bYYyxZsoTc3NyUzwDYbDYuuugiqqqqBjQiI4kLi5xc2KvWfbjkOc1MzrZx7UQfhuRirv2BEPMmFuCwnNzs77KSTA4EwvxogAoqUDuS7k6uF1hxSfaguYULi5zMKHScsb2cTQY12ZthkpMLANXQySufNOG0GLi0+OzF38d4LGw7dOphyZHOw98sYihX0yBLnL3lbYKRxFkxIqWlpdTV1dHY2IjX62X79u0sXbo05Zhp06axdetWysvL2bFjB5MmTUKSJDo7O3n44Ye56aabGD9+vH58PB6ns7MTl8tFLBajoqKCKVOmnI3TGRGYDBIPXT5a/1+WJG6dloPf7z7pWcu1E33HfV9LFM8ucg66oFDjTBkQjXvnFOr7rmfZTViNanvuBRMGj/ufCbS+Vr0T3V9FznTLDMGXn7NiRAwGA7feeisPPfQQiUSCSy+9lFGjRvHKK69QWlrK9OnTueyyy3jyySe58847cTgcLFu2DIA33niD+vp6Xn31VV599VVALeW1WCw89NBDxONxEokEU6ZMSQlZCU4fuQ61Q+g/jYCkYe+kuyxJFGWaqW4Jc1X52V2QVeK1Iks9nV0Fgq8rknImtqUb4dTW1g7rcyMlNnk8zoSMoViCQFcspYHfqXA6ZXz/SJD2cFzfo+F0MFT5qppDjMo0n1UPSOPrei+eboSMQyetORHBlxurUT5tBuR0c0HhqeeXhotWHi0QfJ0RvbMEAoFAMGyEEREIBALBsBFGRCAQCATDRhgRgUAgEAwbYUQEAoFAMGyEEREIBALBsBFGRCAQCATDRhgRgUAgEAybr+WKdYFAIBCcHoQnchKsWLEi3SKcECHjqTPS5QMh4+lCyHjqCCMiEAgEgmEjjIhAIBAIho3h/vvvvz/dQnyZKCkpSbcIJ0TIeOqMdPlAyHi6EDKeGiKxLhAIBIJhI8JZAoFAIBg2wogIBAKBYNiITamGwJ49e1i7di2JRIJ58+axYMGCdItEU1MTa9asobW1FUmSmD9/PldeeSUdHR08/vjjHDt2jKysLH7+85/jcDjSKmsikWDFihV4vV5WrFhBY2Mjq1evJhgMUlJSwp133onRmL5bsbOzk6effpqamhokSeL2228nPz9/ROnxtddeY/PmzUiSxKhRo1i8eDGtra1p1eNTTz3F7t27yczMZNWqVQCD3n+KorB27Vo++OADLBYLixcvPitx/oFkfPHFF6moqMBoNJKTk8PixYux2+0ArFu3js2bNyPLMj/60Y8477zz0iKjxoYNG3jxxRf5/e9/j8vlSpsej4siOC7xeFy54447lPr6eiUajSp33323UlNTk26xlEAgoOzfv19RFEXp6upSli5dqtTU1Cgvvviism7dOkVRFGXdunXKiy++mE4xFUVRlA0bNiirV69WVq5cqSiKoqxatUp5++23FUVRlGeeeUZ588030yme8sQTTygbN25UFEVRotGo0tHRMaL02NzcrCxevFgJh8OKoqj627JlS9r1+Omnnyr79+9X7rrrLv21wfRWUVGhPPTQQ0oikVAqKyuVe++9N20y7tmzR4nFYrq8mow1NTXK3XffrUQiEaWhoUG54447lHg8nhYZFUVRjh07pjz44IPK7bffrrS1tSmKkj49Hg8RzjoBVVVV5ObmkpOTg9FoZPbs2ezcuTPdYuHxePQZiM1mo6CggEAgwM6dO5kzZw4Ac+bMSbuszc3N7N69m3nz5gGgKAqffvops2bNAmDu3LlplbGrq4vPP/+cyy67DACj0Yjdbh9xekwkEkQiEeLxOJFIBLfbnXY9Tpw4sZ93Npjedu3axSWXXIIkSZSXl9PZ2UlLS0taZDz33HMxGAwAlJeXEwgEdNlnz56NyWQiOzub3Nxcqqqq0iIjwB//+Ef+8R//EUmS9NfSpcfjIcJZJyAQCODz+fT/fT4f+/btS6NE/WlsbOTAgQOMHTuWtrY2PB4PAG63m7a2trTK9sILL3DzzTfT3d0NQDAYJCMjQ3+IvV6v/hCng8bGRlwuF0899RSHDh2ipKRY+yqCAAAHUUlEQVSEhQsXjig9er1evvOd73D77bdjNps599xzKSkpGVF61BhMb4FAAL/frx/n8/kIBAL6seli8+bNzJ49G1BlLCsr099Lp0537tyJ1+tlzJgxKa+PRD0KT+RLTigUYtWqVSxcuJCMjIyU9yRJSpnFnG0qKirIzMxMf8z2OMTjcQ4cOMA3v/lNfvOb32CxWFi/fn3KMenWY0dHBzt37mTNmjU888wzhEIh9uzZkzZ5hkq69XYi/vu//xuDwcDFF1+cblFSCIfDrFu3ju9973vpFmVICE/kBHi9Xpqbm/X/m5ub8Xq9aZSoh1gsxqpVq7j44ouZOXMmAJmZmbS0tODxeGhpacHlcqVNvsrKSnbt2sUHH3xAJBKhu7ubF154ga6uLuLxOAaDgUAgkFZ9+nw+fD6fPgOdNWsW69evH1F6/Pjjj8nOztZlmDlzJpWVlSNKjxqD6c3r9dLU1KQfl+7naOvWrVRUVHDffffphq7vs54unTY0NNDY2Mg999wDqLpavnw5K1euHHF6BOGJnJDS0lLq6upobGwkFouxfft2pk+fnm6xUBSFp59+moKCAq6++mr99enTp/PWW28B8NZbbzFjxox0ichNN93E008/zZo1a1i2bBmTJ09m6dKlTJo0iR07dgDqw5xOfbrdbnw+H7W1tYA6YBcWFo4oPfr9fvbt20c4HEZRFF3GkaRHjcH0Nn36dLZt24aiKHzxxRdkZGSkLQSzZ88e/vKXv7B8+XIsFkuK7Nu3bycajdLY2EhdXR1jx4496/IVFRXx+9//njVr1rBmzRp8Ph+PPPIIbrd7ROlRQ6xYHwK7d+/mj3/8I4lEgksvvZRrr7023SKxd+9e7rvvPoqKivSZ1A9+8APKysp4/PHHaWpqGhGlqRqffvopGzZsYMWKFTQ0NLB69Wo6OjooLi7mzjvvxGQypU22gwcP8vTTTxOLxcjOzmbx4sUoijKi9PjnP/+Z7du3YzAYGDNmDD/96U8JBAJp1ePq1av57LPPCAaDZGZmcuONNzJjxowB9aYoCs8//zwffvghZrOZxYsXU1pamhYZ161bRywW069nWVkZt912G6CGuLZs2YIsyyxcuJCpU6emRUat0ANgyZIlrFy5Ui/xTYcej4cwIgKBQCAYNiKcJRAIBIJhI4yIQCAQCIaNMCICgUAgGDbCiAgEAoFg2AgjIhAIBIJhI4yIQDCCufHGG6mvr0+3GALBoIgV6wLBEFmyZAmtra3Ics/ca+7cuSxatCiNUg3Mm2++SXNzMzfddBP/+q//yq233sro0aPTLZbgK4gwIgLBSbB8+XLOOeecdItxQqqrqzn//PNJJBIcPXqUwsLCdIsk+IoijIhAcBrYunUrmzZtYsyYMWzbtg2Px8OiRYuYMmUKoPZheu6559i7dy8Oh4NrrrmG+fPnA2qb9/Xr17Nlyxba2trIy8vjnnvu0bu1fvTRR/z617+mvb2diy66iEWLFp2wsWF1dTXXX389tbW1ZGVl6d1+BYLTjTAiAsFpYt++fcycOZPnn3+e999/n8cee4w1a9bgcDj47W9/y6hRo3jmmWeora3lgQceIDc3l8mTJ/Paa6/xzjvvcO+995KXl8ehQ4dSejrt3r2blStX0t3dzfLly5k+ffqAO+5Fo1F+/OMfoygKoVCIe+65h1gsRiKRYOHChXz3u98dES17BF8thBERCE6CRx99NGVWf/PNN+seRWZmJldddRWSJDF79mw2bNjA7t27mThxInv37mXFihWYzWbGjBnDvHnzeOutt5g8eTKbNm3i5ptvJj8/H6DfHhILFizAbrdjt9uZNGkSBw8eHNCImEwmXnjhBTZt2kRNTQ0LFy7kwQcf5Pvf/35aGgkKvh4IIyIQnAT33HPPoDkRr9ebEmbKysoiEAjQ0tKCw+HAZrPp7/n9fvbv3w+o7bxzcnIG/U23263/bbFYCIVCAx63evVq9uzZQzgcxmQysWXLFkKhEFVVVeTl5bFy5cqTOleBYCgIIyIQnCYCgQCKouiGpKmpienTp+PxeOjo6KC7u1s3JE1NTfo+ED6fj4aGBoqKik7p95ctW0YikeC2227j2WefpaKignfffZelS5ee2okJBMdBrBMRCE4TbW1tvP7668RiMd59912OHj3K1KlT8fv9jBs3jpdffplIJMKhQ4fYsmWLvqPevHnzeOWVV6irq0NRFA4dOkQwGByWDEePHiUnJwdZljlw4EDa24QLvvoIT0QgOAkeeeSRlHUi55xzjr4DXVlZGXV1dSxatAi3281dd92F0+kE4Gc/+xnPPfccP/nJT3A4HNxwww16WOzqq68mGo3y4IMPEgwGKSgo4O677x6WfNXV1RQXF+t/X3PNNadyugLBCRH7iQgEpwGtxPeBBx5ItygCwVlFhLMEAoFAMGyEEREIBALBsBHhLIFAIBAMG+GJCAQCgWDYCCMiEAgEgmEjjIhAIBAIho0wIgKBQCAYNsKICAQCgWDY/H/MU4VCIsQm0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs_img), img_model_grafica.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs_img), img_model_grafica.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CsXPf19o2cW"
      },
      "source": [
        "**MÉTRICAS MODELO CONVUNSIONAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fXKhzVjrfYK",
        "outputId": "c22b23b3-40cc-4cc4-9dc6-17e37ba38042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "Porcentaje medio de diferencia del GT: 43.51 % - Desviación típica: 43.51\n",
            "Error medio: 26.53€\n"
          ]
        }
      ],
      "source": [
        "y_predict_img = img_model.predict(X_test_resized)\n",
        "y_pred_img_denorm = y_predict_img[:, 0] *  y_reg.max()\n",
        "\n",
        "diferencia_img = y_pred_img_denorm.flatten() - y_test_denorm\n",
        "porcentaje_diferencia_img = (diferencia_img / y_test_denorm) * 100\n",
        "abs_porcentaje_diferencia_img = np.abs(porcentaje_diferencia_img)\n",
        "\n",
        "error_denorm_img = np.abs(y_pred_img_denorm - y_test_denorm)\n",
        "mean_img = np.mean(abs_porcentaje_diferencia_img)\n",
        "std_img = np.std(abs_porcentaje_diferencia_img)\n",
        "\n",
        "print('Porcentaje medio de diferencia del GT: {0:.2f} % - Desviación típica: {0:.2f}'.format(mean_img ,std_img))\n",
        "print('Error medio: {0:.2f}€'.format(error_denorm_img.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mhEpCpgisp7"
      },
      "source": [
        "El modelo se puede mejorar bastante, aunque habiendo probado diferentes hiperparámetros he visto que es bastante complicado para el modelo generalizar, al tener solo 1500 imágenes, y la complicación que tiene predecir el precio de apartamentos solo con fotos, los resultados no son óptimos. Hay apartamentos no muy estilosos en barrios de alta clase, y su precio sube bastante, así como otros apartamentos modernos y bien amueblados en barrios más humildes, sus precios bajan.\n",
        "Usando los hiperparámetros dado por el optimizador ha mejorado el modelo en más de un 10 %."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A4G1DCoSIka"
      },
      "outputs": [],
      "source": [
        "## Comentarios del profesor ###\n",
        "La arquitectura convolucional está bien pero quizá la podrías mejorar con los siguientes consejos:\n",
        "    - Utilizar un global MaxPooling en lugar de una capa flatten y quitar la densa después de la flatten\n",
        "    - Aumentar el número de filtros conforme aumentamos el número de capas convolucionales\n",
        "    -Disminuir un poco el dropout.\n",
        "    -Uitlizar redes preentrenadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVleErk-kegf"
      },
      "source": [
        "**CREAMOS EL MODELO HÍBRIDO PERO ESTA VEZ CREAMOS LA RED CONVUNSIONAL DE UNA RED PREENTRENADA**\n",
        "\n",
        "Compruebo primero que tanto me mejora el modelo preentrenado respecto al anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOoII7CVzYc2",
        "outputId": "d49f53a2-d42b-4d00-d45c-c1256bdf49f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# creamos el modelo base\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Q0ogYS2pDi",
        "outputId": "934dc178-f18c-4eb0-9d73-58aa95b7e17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Capa input_12 congelada.\n",
            "Capa block1_conv1 congelada.\n",
            "Capa block1_conv2 congelada.\n",
            "Capa block1_pool congelada.\n",
            "Capa block2_conv1 congelada.\n",
            "Capa block2_conv2 congelada.\n",
            "Capa block2_pool congelada.\n",
            "Capa block3_conv1 congelada.\n",
            "Capa block3_conv2 congelada.\n",
            "Capa block3_conv3 congelada.\n",
            "Capa block3_pool congelada.\n",
            "Capa block4_conv1 congelada.\n",
            "Capa block4_conv2 congelada.\n",
            "Capa block4_conv3 congelada.\n",
            "Capa block4_pool congelada.\n",
            "Capa block5_conv1 congelada.\n",
            "Capa block5_conv2 congelada.\n",
            "Capa block5_conv3 congelada.\n",
            "Capa block5_pool congelada.\n"
          ]
        }
      ],
      "source": [
        "n_epochs_img_VGG = 130\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "  print('Capa ' + layer.name + ' congelada.')\n",
        "\n",
        "\n",
        "# cogemos la última capa del model y le añadimos nuestro (top_model)\n",
        "last = base_model.layers[-1].output\n",
        "img_model_2_output = Flatten()(last)\n",
        "img_model_2_output = Dense(64, activation='relu')(img_model_2_output)\n",
        "img_model_2_output = BatchNormalization()(img_model_2_output)\n",
        "img_model_2_output = Dropout(0.5)(img_model_2_output)\n",
        "img_model_2_output = Dense(32, activation='relu')(img_model_2_output)\n",
        "img_model_2_output = BatchNormalization()(img_model_2_output)\n",
        "img_model_2_output = Dropout(0.5)(img_model_2_output)\n",
        "\n",
        "img_model_2_output = Dense(1, activation = 'sigmoid')(img_model_2_output)\n",
        "\n",
        "#Modelo de imágenes del que usaremos en el híbrido\n",
        "img_model_2 = Model(base_model.input, img_model_2_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eHxjGKgzSg9",
        "outputId": "9462a1ca-16e3-4ca6-82a6-e74dbc621440"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "img_model_2.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(lr=0.001, decay = 1e-6), metrics=['mean_absolute_error'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIFBKDHzbPX",
        "outputId": "17197bb5-7fc1-47f6-9315-8cf7c9bd8255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/130\n",
            "15/15 [==============================] - 2s 68ms/step - loss: 0.1301 - mean_absolute_error: 0.2948 - val_loss: 0.0474 - val_mean_absolute_error: 0.1921\n",
            "Epoch 2/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0944 - mean_absolute_error: 0.2478 - val_loss: 0.0339 - val_mean_absolute_error: 0.1580\n",
            "Epoch 3/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0793 - mean_absolute_error: 0.2214 - val_loss: 0.0314 - val_mean_absolute_error: 0.1509\n",
            "Epoch 4/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0643 - mean_absolute_error: 0.1952 - val_loss: 0.0318 - val_mean_absolute_error: 0.1518\n",
            "Epoch 5/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0617 - mean_absolute_error: 0.1915 - val_loss: 0.0308 - val_mean_absolute_error: 0.1483\n",
            "Epoch 6/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0558 - mean_absolute_error: 0.1848 - val_loss: 0.0284 - val_mean_absolute_error: 0.1396\n",
            "Epoch 7/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0529 - mean_absolute_error: 0.1796 - val_loss: 0.0281 - val_mean_absolute_error: 0.1381\n",
            "Epoch 8/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0527 - mean_absolute_error: 0.1799 - val_loss: 0.0291 - val_mean_absolute_error: 0.1414\n",
            "Epoch 9/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0518 - mean_absolute_error: 0.1740 - val_loss: 0.0307 - val_mean_absolute_error: 0.1464\n",
            "Epoch 10/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0487 - mean_absolute_error: 0.1710 - val_loss: 0.0308 - val_mean_absolute_error: 0.1471\n",
            "Epoch 11/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0485 - mean_absolute_error: 0.1679 - val_loss: 0.0312 - val_mean_absolute_error: 0.1476\n",
            "Epoch 12/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0475 - mean_absolute_error: 0.1681 - val_loss: 0.0304 - val_mean_absolute_error: 0.1449\n",
            "Epoch 13/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0470 - mean_absolute_error: 0.1688 - val_loss: 0.0308 - val_mean_absolute_error: 0.1460\n",
            "Epoch 14/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0435 - mean_absolute_error: 0.1614 - val_loss: 0.0314 - val_mean_absolute_error: 0.1473\n",
            "Epoch 15/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0439 - mean_absolute_error: 0.1641 - val_loss: 0.0316 - val_mean_absolute_error: 0.1474\n",
            "Epoch 16/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0428 - mean_absolute_error: 0.1599 - val_loss: 0.0305 - val_mean_absolute_error: 0.1442\n",
            "Epoch 17/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0400 - mean_absolute_error: 0.1542 - val_loss: 0.0304 - val_mean_absolute_error: 0.1443\n",
            "Epoch 18/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0432 - mean_absolute_error: 0.1625 - val_loss: 0.0301 - val_mean_absolute_error: 0.1437\n",
            "Epoch 19/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0403 - mean_absolute_error: 0.1557 - val_loss: 0.0305 - val_mean_absolute_error: 0.1448\n",
            "Epoch 20/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0395 - mean_absolute_error: 0.1534 - val_loss: 0.0316 - val_mean_absolute_error: 0.1482\n",
            "Epoch 21/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0397 - mean_absolute_error: 0.1560 - val_loss: 0.0316 - val_mean_absolute_error: 0.1482\n",
            "Epoch 22/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0415 - mean_absolute_error: 0.1606 - val_loss: 0.0312 - val_mean_absolute_error: 0.1471\n",
            "Epoch 23/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0396 - mean_absolute_error: 0.1558 - val_loss: 0.0311 - val_mean_absolute_error: 0.1468\n",
            "Epoch 24/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0374 - mean_absolute_error: 0.1503 - val_loss: 0.0309 - val_mean_absolute_error: 0.1467\n",
            "Epoch 25/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0371 - mean_absolute_error: 0.1524 - val_loss: 0.0305 - val_mean_absolute_error: 0.1457\n",
            "Epoch 26/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0371 - mean_absolute_error: 0.1504 - val_loss: 0.0297 - val_mean_absolute_error: 0.1432\n",
            "Epoch 27/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0374 - mean_absolute_error: 0.1495 - val_loss: 0.0297 - val_mean_absolute_error: 0.1434\n",
            "Epoch 28/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0387 - mean_absolute_error: 0.1529 - val_loss: 0.0292 - val_mean_absolute_error: 0.1415\n",
            "Epoch 29/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0362 - mean_absolute_error: 0.1503 - val_loss: 0.0291 - val_mean_absolute_error: 0.1411\n",
            "Epoch 30/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0353 - mean_absolute_error: 0.1454 - val_loss: 0.0293 - val_mean_absolute_error: 0.1417\n",
            "Epoch 31/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0375 - mean_absolute_error: 0.1508 - val_loss: 0.0290 - val_mean_absolute_error: 0.1411\n",
            "Epoch 32/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0376 - mean_absolute_error: 0.1511 - val_loss: 0.0289 - val_mean_absolute_error: 0.1409\n",
            "Epoch 33/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0385 - mean_absolute_error: 0.1541 - val_loss: 0.0285 - val_mean_absolute_error: 0.1397\n",
            "Epoch 34/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0382 - mean_absolute_error: 0.1533 - val_loss: 0.0279 - val_mean_absolute_error: 0.1380\n",
            "Epoch 35/130\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.0352 - mean_absolute_error: 0.1472 - val_loss: 0.0271 - val_mean_absolute_error: 0.1352\n",
            "Epoch 36/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0366 - mean_absolute_error: 0.1488 - val_loss: 0.0277 - val_mean_absolute_error: 0.1372\n",
            "Epoch 37/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0347 - mean_absolute_error: 0.1450 - val_loss: 0.0277 - val_mean_absolute_error: 0.1371\n",
            "Epoch 38/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0373 - mean_absolute_error: 0.1530 - val_loss: 0.0283 - val_mean_absolute_error: 0.1389\n",
            "Epoch 39/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0365 - mean_absolute_error: 0.1493 - val_loss: 0.0282 - val_mean_absolute_error: 0.1384\n",
            "Epoch 40/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0371 - mean_absolute_error: 0.1498 - val_loss: 0.0284 - val_mean_absolute_error: 0.1387\n",
            "Epoch 41/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0355 - mean_absolute_error: 0.1468 - val_loss: 0.0283 - val_mean_absolute_error: 0.1386\n",
            "Epoch 42/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0347 - mean_absolute_error: 0.1457 - val_loss: 0.0285 - val_mean_absolute_error: 0.1391\n",
            "Epoch 43/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0356 - mean_absolute_error: 0.1456 - val_loss: 0.0282 - val_mean_absolute_error: 0.1382\n",
            "Epoch 44/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0340 - mean_absolute_error: 0.1424 - val_loss: 0.0282 - val_mean_absolute_error: 0.1379\n",
            "Epoch 45/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0349 - mean_absolute_error: 0.1431 - val_loss: 0.0281 - val_mean_absolute_error: 0.1377\n",
            "Epoch 46/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0350 - mean_absolute_error: 0.1453 - val_loss: 0.0283 - val_mean_absolute_error: 0.1385\n",
            "Epoch 47/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0337 - mean_absolute_error: 0.1440 - val_loss: 0.0277 - val_mean_absolute_error: 0.1365\n",
            "Epoch 48/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0335 - mean_absolute_error: 0.1418 - val_loss: 0.0276 - val_mean_absolute_error: 0.1361\n",
            "Epoch 49/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0343 - mean_absolute_error: 0.1434 - val_loss: 0.0279 - val_mean_absolute_error: 0.1372\n",
            "Epoch 50/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0348 - mean_absolute_error: 0.1447 - val_loss: 0.0280 - val_mean_absolute_error: 0.1374\n",
            "Epoch 51/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0339 - mean_absolute_error: 0.1441 - val_loss: 0.0275 - val_mean_absolute_error: 0.1355\n",
            "Epoch 52/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0332 - mean_absolute_error: 0.1421 - val_loss: 0.0272 - val_mean_absolute_error: 0.1346\n",
            "Epoch 53/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0350 - mean_absolute_error: 0.1453 - val_loss: 0.0269 - val_mean_absolute_error: 0.1336\n",
            "Epoch 54/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0337 - mean_absolute_error: 0.1427 - val_loss: 0.0268 - val_mean_absolute_error: 0.1330\n",
            "Epoch 55/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0333 - mean_absolute_error: 0.1417 - val_loss: 0.0267 - val_mean_absolute_error: 0.1325\n",
            "Epoch 56/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0329 - mean_absolute_error: 0.1394 - val_loss: 0.0266 - val_mean_absolute_error: 0.1320\n",
            "Epoch 57/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0335 - mean_absolute_error: 0.1408 - val_loss: 0.0268 - val_mean_absolute_error: 0.1326\n",
            "Epoch 58/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0335 - mean_absolute_error: 0.1416 - val_loss: 0.0270 - val_mean_absolute_error: 0.1332\n",
            "Epoch 59/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0324 - mean_absolute_error: 0.1398 - val_loss: 0.0273 - val_mean_absolute_error: 0.1348\n",
            "Epoch 60/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0331 - mean_absolute_error: 0.1413 - val_loss: 0.0277 - val_mean_absolute_error: 0.1368\n",
            "Epoch 61/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0321 - mean_absolute_error: 0.1382 - val_loss: 0.0279 - val_mean_absolute_error: 0.1371\n",
            "Epoch 62/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0332 - mean_absolute_error: 0.1412 - val_loss: 0.0279 - val_mean_absolute_error: 0.1373\n",
            "Epoch 63/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0321 - mean_absolute_error: 0.1384 - val_loss: 0.0278 - val_mean_absolute_error: 0.1369\n",
            "Epoch 64/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0329 - mean_absolute_error: 0.1391 - val_loss: 0.0279 - val_mean_absolute_error: 0.1373\n",
            "Epoch 65/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0323 - mean_absolute_error: 0.1385 - val_loss: 0.0273 - val_mean_absolute_error: 0.1355\n",
            "Epoch 66/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0330 - mean_absolute_error: 0.1414 - val_loss: 0.0274 - val_mean_absolute_error: 0.1358\n",
            "Epoch 67/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0332 - mean_absolute_error: 0.1412 - val_loss: 0.0270 - val_mean_absolute_error: 0.1341\n",
            "Epoch 68/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0328 - mean_absolute_error: 0.1411 - val_loss: 0.0271 - val_mean_absolute_error: 0.1345\n",
            "Epoch 69/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0324 - mean_absolute_error: 0.1396 - val_loss: 0.0273 - val_mean_absolute_error: 0.1356\n",
            "Epoch 70/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0315 - mean_absolute_error: 0.1383 - val_loss: 0.0268 - val_mean_absolute_error: 0.1332\n",
            "Epoch 71/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0317 - mean_absolute_error: 0.1381 - val_loss: 0.0270 - val_mean_absolute_error: 0.1336\n",
            "Epoch 72/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0320 - mean_absolute_error: 0.1385 - val_loss: 0.0267 - val_mean_absolute_error: 0.1319\n",
            "Epoch 73/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0318 - mean_absolute_error: 0.1375 - val_loss: 0.0268 - val_mean_absolute_error: 0.1319\n",
            "Epoch 74/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0322 - mean_absolute_error: 0.1394 - val_loss: 0.0270 - val_mean_absolute_error: 0.1330\n",
            "Epoch 75/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0317 - mean_absolute_error: 0.1376 - val_loss: 0.0270 - val_mean_absolute_error: 0.1321\n",
            "Epoch 76/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0315 - mean_absolute_error: 0.1380 - val_loss: 0.0268 - val_mean_absolute_error: 0.1308\n",
            "Epoch 77/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0308 - mean_absolute_error: 0.1364 - val_loss: 0.0266 - val_mean_absolute_error: 0.1291\n",
            "Epoch 78/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0313 - mean_absolute_error: 0.1364 - val_loss: 0.0263 - val_mean_absolute_error: 0.1280\n",
            "Epoch 79/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0323 - mean_absolute_error: 0.1402 - val_loss: 0.0268 - val_mean_absolute_error: 0.1303\n",
            "Epoch 80/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0313 - mean_absolute_error: 0.1373 - val_loss: 0.0270 - val_mean_absolute_error: 0.1313\n",
            "Epoch 81/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0308 - mean_absolute_error: 0.1359 - val_loss: 0.0273 - val_mean_absolute_error: 0.1332\n",
            "Epoch 82/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0309 - mean_absolute_error: 0.1355 - val_loss: 0.0279 - val_mean_absolute_error: 0.1357\n",
            "Epoch 83/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0321 - mean_absolute_error: 0.1386 - val_loss: 0.0274 - val_mean_absolute_error: 0.1326\n",
            "Epoch 84/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0315 - mean_absolute_error: 0.1376 - val_loss: 0.0272 - val_mean_absolute_error: 0.1324\n",
            "Epoch 85/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0314 - mean_absolute_error: 0.1384 - val_loss: 0.0273 - val_mean_absolute_error: 0.1318\n",
            "Epoch 86/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0308 - mean_absolute_error: 0.1361 - val_loss: 0.0270 - val_mean_absolute_error: 0.1303\n",
            "Epoch 87/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0303 - mean_absolute_error: 0.1343 - val_loss: 0.0267 - val_mean_absolute_error: 0.1267\n",
            "Epoch 88/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0314 - mean_absolute_error: 0.1360 - val_loss: 0.0269 - val_mean_absolute_error: 0.1286\n",
            "Epoch 89/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0310 - mean_absolute_error: 0.1352 - val_loss: 0.0272 - val_mean_absolute_error: 0.1299\n",
            "Epoch 90/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0306 - mean_absolute_error: 0.1336 - val_loss: 0.0273 - val_mean_absolute_error: 0.1309\n",
            "Epoch 91/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0311 - mean_absolute_error: 0.1376 - val_loss: 0.0276 - val_mean_absolute_error: 0.1318\n",
            "Epoch 92/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0313 - mean_absolute_error: 0.1370 - val_loss: 0.0273 - val_mean_absolute_error: 0.1313\n",
            "Epoch 93/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0298 - mean_absolute_error: 0.1326 - val_loss: 0.0277 - val_mean_absolute_error: 0.1319\n",
            "Epoch 94/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0301 - mean_absolute_error: 0.1340 - val_loss: 0.0272 - val_mean_absolute_error: 0.1287\n",
            "Epoch 95/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0313 - mean_absolute_error: 0.1376 - val_loss: 0.0268 - val_mean_absolute_error: 0.1280\n",
            "Epoch 96/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0304 - mean_absolute_error: 0.1350 - val_loss: 0.0271 - val_mean_absolute_error: 0.1288\n",
            "Epoch 97/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0304 - mean_absolute_error: 0.1345 - val_loss: 0.0275 - val_mean_absolute_error: 0.1305\n",
            "Epoch 98/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0303 - mean_absolute_error: 0.1338 - val_loss: 0.0281 - val_mean_absolute_error: 0.1347\n",
            "Epoch 99/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0303 - mean_absolute_error: 0.1333 - val_loss: 0.0282 - val_mean_absolute_error: 0.1360\n",
            "Epoch 100/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0302 - mean_absolute_error: 0.1339 - val_loss: 0.0275 - val_mean_absolute_error: 0.1340\n",
            "Epoch 101/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0301 - mean_absolute_error: 0.1328 - val_loss: 0.0281 - val_mean_absolute_error: 0.1351\n",
            "Epoch 102/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0297 - mean_absolute_error: 0.1315 - val_loss: 0.0282 - val_mean_absolute_error: 0.1350\n",
            "Epoch 103/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0305 - mean_absolute_error: 0.1335 - val_loss: 0.0289 - val_mean_absolute_error: 0.1365\n",
            "Epoch 104/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0303 - mean_absolute_error: 0.1328 - val_loss: 0.0280 - val_mean_absolute_error: 0.1328\n",
            "Epoch 105/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0299 - mean_absolute_error: 0.1327 - val_loss: 0.0283 - val_mean_absolute_error: 0.1339\n",
            "Epoch 106/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0297 - mean_absolute_error: 0.1321 - val_loss: 0.0280 - val_mean_absolute_error: 0.1311\n",
            "Epoch 107/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0300 - mean_absolute_error: 0.1329 - val_loss: 0.0284 - val_mean_absolute_error: 0.1360\n",
            "Epoch 108/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0295 - mean_absolute_error: 0.1312 - val_loss: 0.0283 - val_mean_absolute_error: 0.1337\n",
            "Epoch 109/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0298 - mean_absolute_error: 0.1332 - val_loss: 0.0284 - val_mean_absolute_error: 0.1331\n",
            "Epoch 110/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0290 - mean_absolute_error: 0.1308 - val_loss: 0.0281 - val_mean_absolute_error: 0.1323\n",
            "Epoch 111/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0288 - mean_absolute_error: 0.1306 - val_loss: 0.0285 - val_mean_absolute_error: 0.1309\n",
            "Epoch 112/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0299 - mean_absolute_error: 0.1321 - val_loss: 0.0288 - val_mean_absolute_error: 0.1307\n",
            "Epoch 113/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0296 - mean_absolute_error: 0.1329 - val_loss: 0.0284 - val_mean_absolute_error: 0.1298\n",
            "Epoch 114/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0290 - mean_absolute_error: 0.1300 - val_loss: 0.0282 - val_mean_absolute_error: 0.1254\n",
            "Epoch 115/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0301 - mean_absolute_error: 0.1328 - val_loss: 0.0268 - val_mean_absolute_error: 0.1246\n",
            "Epoch 116/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0297 - mean_absolute_error: 0.1328 - val_loss: 0.0268 - val_mean_absolute_error: 0.1243\n",
            "Epoch 117/130\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0296 - mean_absolute_error: 0.1325 - val_loss: 0.0290 - val_mean_absolute_error: 0.1251\n",
            "Epoch 118/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0296 - mean_absolute_error: 0.1312 - val_loss: 0.0296 - val_mean_absolute_error: 0.1276\n",
            "Epoch 119/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0287 - mean_absolute_error: 0.1289 - val_loss: 0.0277 - val_mean_absolute_error: 0.1247\n",
            "Epoch 120/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0298 - mean_absolute_error: 0.1319 - val_loss: 0.0271 - val_mean_absolute_error: 0.1272\n",
            "Epoch 121/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0289 - mean_absolute_error: 0.1296 - val_loss: 0.0272 - val_mean_absolute_error: 0.1262\n",
            "Epoch 122/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0288 - mean_absolute_error: 0.1301 - val_loss: 0.0281 - val_mean_absolute_error: 0.1274\n",
            "Epoch 123/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0292 - mean_absolute_error: 0.1314 - val_loss: 0.0276 - val_mean_absolute_error: 0.1309\n",
            "Epoch 124/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0295 - mean_absolute_error: 0.1323 - val_loss: 0.0280 - val_mean_absolute_error: 0.1307\n",
            "Epoch 125/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0286 - mean_absolute_error: 0.1296 - val_loss: 0.0289 - val_mean_absolute_error: 0.1286\n",
            "Epoch 126/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0293 - mean_absolute_error: 0.1308 - val_loss: 0.0299 - val_mean_absolute_error: 0.1294\n",
            "Epoch 127/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0285 - mean_absolute_error: 0.1291 - val_loss: 0.0281 - val_mean_absolute_error: 0.1303\n",
            "Epoch 128/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0296 - mean_absolute_error: 0.1312 - val_loss: 0.0282 - val_mean_absolute_error: 0.1321\n",
            "Epoch 129/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0284 - mean_absolute_error: 0.1292 - val_loss: 0.0284 - val_mean_absolute_error: 0.1337\n",
            "Epoch 130/130\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.0294 - mean_absolute_error: 0.1303 - val_loss: 0.0277 - val_mean_absolute_error: 0.1287\n"
          ]
        }
      ],
      "source": [
        "img_model_2_grafic = img_model_2.fit(X_train_resized, y_train,\n",
        "          batch_size=64,\n",
        "          shuffle = True,\n",
        "          epochs=n_epochs_img_VGG,\n",
        "          validation_data=(X_validation_resized,y_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "rTpiIIazzoCA",
        "outputId": "a9e0da3e-8035-4a2a-8b91-4a64089d5eb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4e0ce04d60>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, n_epochs_img_VGG), img_model_2_grafic.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, n_epochs_img_VGG), img_model_2_grafic.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqRxwoE6riRQ",
        "outputId": "85662a25-6973-4e0c-bf93-104e9f69d6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 37ms/step\n",
            "Porcentaje medio de diferencia del GT: 41.93 % - Desviación típica: 41.93\n",
            "Error medio: 28.68€\n"
          ]
        }
      ],
      "source": [
        "y_predict_img_VGG = img_model_2.predict(X_test_resized)\n",
        "y_pred_img_denorm_VGG = y_predict_img_VGG[:, 0] *  y_reg.max()\n",
        "\n",
        "diferencia_img_VGG = y_pred_img_denorm_VGG.flatten() - y_test_denorm\n",
        "porcentaje_diferencia_img_VGG = (diferencia_img_VGG / y_test_denorm) * 100\n",
        "abs_porcentaje_diferencia_img_VGG = np.abs(porcentaje_diferencia_img_VGG)\n",
        "\n",
        "error_denorm_img_VGG = np.abs(y_pred_img_denorm_VGG - y_test_denorm)\n",
        "mean_img_VGG = np.mean(abs_porcentaje_diferencia_img_VGG)\n",
        "\n",
        "print('Porcentaje medio de diferencia del GT: {0:.2f} % - Desviación típica: {0:.2f}'.format(mean_img_VGG ))\n",
        "print('Error medio: {0:.2f}€'.format(error_denorm_img_VGG.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X5s-JqDkpTN"
      },
      "source": [
        "Sin usar el optimizador debido al tiempo de espera requerido ya vemos una mejora de casi el 2% con unos parámetros al azar. Con el optimizador muy seguramente podríamos obtener un resultado mejor.\n",
        "Optamos por elegir este modelo para la red híbrida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGnToTViLve8"
      },
      "source": [
        "**CONCADENAMOS LAS SALIDAS DE LAS DOS RAMAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH7RJkhd5APj"
      },
      "outputs": [],
      "source": [
        "from keras.layers.attention.multi_head_attention import activation\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import InputLayer\n",
        "\n",
        "\n",
        "ramas_fusionadas = concatenate([num_model_1.output, img_model_2.output ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWEovuDNY3z9"
      },
      "source": [
        "**CREAMOS LA RAMA DE SALIDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5yGAxKjNJee"
      },
      "outputs": [],
      "source": [
        "modelo_hybrido_output = Dense(4, activation = 'relu')(ramas_fusionadas)\n",
        "modelo_hybrido_output = Dense(1, activation = 'sigmoid')(modelo_hybrido_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh3D615MY-7p"
      },
      "source": [
        "**COMPILAMOS MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiy_a3ZVNo1o"
      },
      "outputs": [],
      "source": [
        "modelo_hybrido_final = Model(inputs=[num_model_1.input, img_model_2.input ], outputs = modelo_hybrido_output)\n",
        "modelo_hybrido_final.compile(optimizer= Adam(lr=0.001, decay = 1e-6), loss = 'mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39AbjaxJZMW9"
      },
      "source": [
        "**ENTRENAMOS MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8AG9_VKxRA",
        "outputId": "0a73fda4-ef8a-4449-ebd6-3a34fcf6e0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "8/8 [==============================] - 3s 100ms/step - loss: 0.1463 - val_loss: 0.1317\n",
            "Epoch 2/120\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.1381 - val_loss: 0.1206\n",
            "Epoch 3/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.1316 - val_loss: 0.1102\n",
            "Epoch 4/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1225 - val_loss: 0.1006\n",
            "Epoch 5/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1162 - val_loss: 0.0941\n",
            "Epoch 6/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.1075 - val_loss: 0.0886\n",
            "Epoch 7/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.1030 - val_loss: 0.0836\n",
            "Epoch 8/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0965 - val_loss: 0.0789\n",
            "Epoch 9/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0923 - val_loss: 0.0740\n",
            "Epoch 10/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0861 - val_loss: 0.0700\n",
            "Epoch 11/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0824 - val_loss: 0.0667\n",
            "Epoch 12/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0785 - val_loss: 0.0621\n",
            "Epoch 13/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0740 - val_loss: 0.0578\n",
            "Epoch 14/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0695 - val_loss: 0.0536\n",
            "Epoch 15/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0665 - val_loss: 0.0503\n",
            "Epoch 16/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0605 - val_loss: 0.0474\n",
            "Epoch 17/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0587 - val_loss: 0.0441\n",
            "Epoch 18/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0554 - val_loss: 0.0409\n",
            "Epoch 19/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0512 - val_loss: 0.0379\n",
            "Epoch 20/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0482 - val_loss: 0.0355\n",
            "Epoch 21/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0460 - val_loss: 0.0334\n",
            "Epoch 22/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0430 - val_loss: 0.0313\n",
            "Epoch 23/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0395 - val_loss: 0.0291\n",
            "Epoch 24/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0365 - val_loss: 0.0273\n",
            "Epoch 25/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0353 - val_loss: 0.0259\n",
            "Epoch 26/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0330 - val_loss: 0.0249\n",
            "Epoch 27/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0311 - val_loss: 0.0236\n",
            "Epoch 28/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0297 - val_loss: 0.0228\n",
            "Epoch 29/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0282 - val_loss: 0.0221\n",
            "Epoch 30/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0274 - val_loss: 0.0213\n",
            "Epoch 31/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0264 - val_loss: 0.0204\n",
            "Epoch 32/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0244 - val_loss: 0.0198\n",
            "Epoch 33/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0231 - val_loss: 0.0193\n",
            "Epoch 34/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0228 - val_loss: 0.0189\n",
            "Epoch 35/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0227 - val_loss: 0.0186\n",
            "Epoch 36/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0220 - val_loss: 0.0186\n",
            "Epoch 37/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0217 - val_loss: 0.0186\n",
            "Epoch 38/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0213 - val_loss: 0.0184\n",
            "Epoch 39/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0205 - val_loss: 0.0179\n",
            "Epoch 40/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0204 - val_loss: 0.0175\n",
            "Epoch 41/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0202 - val_loss: 0.0174\n",
            "Epoch 42/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0196 - val_loss: 0.0170\n",
            "Epoch 43/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0198 - val_loss: 0.0165\n",
            "Epoch 44/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0193 - val_loss: 0.0163\n",
            "Epoch 45/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0194 - val_loss: 0.0164\n",
            "Epoch 46/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0187 - val_loss: 0.0166\n",
            "Epoch 47/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0183 - val_loss: 0.0165\n",
            "Epoch 48/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0184 - val_loss: 0.0163\n",
            "Epoch 49/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0180 - val_loss: 0.0161\n",
            "Epoch 50/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0185 - val_loss: 0.0160\n",
            "Epoch 51/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0182 - val_loss: 0.0159\n",
            "Epoch 52/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0184 - val_loss: 0.0160\n",
            "Epoch 53/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0184 - val_loss: 0.0158\n",
            "Epoch 54/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0177 - val_loss: 0.0157\n",
            "Epoch 55/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0171 - val_loss: 0.0156\n",
            "Epoch 56/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0179 - val_loss: 0.0154\n",
            "Epoch 57/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0175 - val_loss: 0.0152\n",
            "Epoch 58/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0167 - val_loss: 0.0152\n",
            "Epoch 59/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0172 - val_loss: 0.0152\n",
            "Epoch 60/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0171 - val_loss: 0.0152\n",
            "Epoch 61/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0171 - val_loss: 0.0152\n",
            "Epoch 62/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0172 - val_loss: 0.0151\n",
            "Epoch 63/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0174 - val_loss: 0.0151\n",
            "Epoch 64/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0169 - val_loss: 0.0149\n",
            "Epoch 65/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0164 - val_loss: 0.0148\n",
            "Epoch 66/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0169 - val_loss: 0.0146\n",
            "Epoch 67/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0169 - val_loss: 0.0144\n",
            "Epoch 68/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0162 - val_loss: 0.0143\n",
            "Epoch 69/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0164 - val_loss: 0.0144\n",
            "Epoch 70/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.0148\n",
            "Epoch 71/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0162 - val_loss: 0.0151\n",
            "Epoch 72/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0161 - val_loss: 0.0148\n",
            "Epoch 73/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0168 - val_loss: 0.0148\n",
            "Epoch 74/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0162 - val_loss: 0.0149\n",
            "Epoch 75/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0163 - val_loss: 0.0150\n",
            "Epoch 76/120\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0156 - val_loss: 0.0152\n",
            "Epoch 77/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0159 - val_loss: 0.0151\n",
            "Epoch 78/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0164 - val_loss: 0.0151\n",
            "Epoch 79/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0153 - val_loss: 0.0151\n",
            "Epoch 80/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0161 - val_loss: 0.0151\n",
            "Epoch 81/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0155 - val_loss: 0.0146\n",
            "Epoch 82/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0160 - val_loss: 0.0143\n",
            "Epoch 83/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.0143\n",
            "Epoch 84/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0160 - val_loss: 0.0144\n",
            "Epoch 85/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0154 - val_loss: 0.0145\n",
            "Epoch 86/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0153 - val_loss: 0.0146\n",
            "Epoch 87/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0158 - val_loss: 0.0146\n",
            "Epoch 88/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0157 - val_loss: 0.0150\n",
            "Epoch 89/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0145 - val_loss: 0.0147\n",
            "Epoch 90/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0151 - val_loss: 0.0145\n",
            "Epoch 91/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0147 - val_loss: 0.0145\n",
            "Epoch 92/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0157 - val_loss: 0.0148\n",
            "Epoch 93/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0152 - val_loss: 0.0147\n",
            "Epoch 94/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0149 - val_loss: 0.0147\n",
            "Epoch 95/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0146 - val_loss: 0.0146\n",
            "Epoch 96/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0145 - val_loss: 0.0145\n",
            "Epoch 97/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0150 - val_loss: 0.0145\n",
            "Epoch 98/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0145 - val_loss: 0.0148\n",
            "Epoch 99/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0153 - val_loss: 0.0149\n",
            "Epoch 100/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0150 - val_loss: 0.0147\n",
            "Epoch 101/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0145 - val_loss: 0.0149\n",
            "Epoch 102/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.0150\n",
            "Epoch 103/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0145 - val_loss: 0.0149\n",
            "Epoch 104/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0157 - val_loss: 0.0147\n",
            "Epoch 105/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0146 - val_loss: 0.0145\n",
            "Epoch 106/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0146 - val_loss: 0.0142\n",
            "Epoch 107/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0142 - val_loss: 0.0142\n",
            "Epoch 108/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.0140\n",
            "Epoch 109/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.0138\n",
            "Epoch 110/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.0138\n",
            "Epoch 111/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0142 - val_loss: 0.0141\n",
            "Epoch 112/120\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0146 - val_loss: 0.0146\n",
            "Epoch 113/120\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.0143 - val_loss: 0.0143\n",
            "Epoch 114/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0136 - val_loss: 0.0145\n",
            "Epoch 115/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0137 - val_loss: 0.0145\n",
            "Epoch 116/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0138 - val_loss: 0.0142\n",
            "Epoch 117/120\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0132 - val_loss: 0.0142\n",
            "Epoch 118/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0137 - val_loss: 0.0140\n",
            "Epoch 119/120\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0142 - val_loss: 0.0138\n",
            "Epoch 120/120\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0138 - val_loss: 0.0138\n"
          ]
        }
      ],
      "source": [
        "H = modelo_hybrido_final.fit(x = [X_train, X_train_resized],y = y_train, validation_data = ([X_validation, X_validation_resized], y_validation), shuffle = True, epochs=120, batch_size= 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "uJ32rR6qJPnn",
        "outputId": "6a879d17-0e81-48a5-d55b-c230f914cdc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4db45d3910>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 120), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 120), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOglUaM2eExY",
        "outputId": "3f8fbd2e-c6a8-47e6-907f-94255d73fdfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = modelo_hybrido_final.predict([X_test, X_test_resized])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRr-LrIBqJXF",
        "outputId": "cbc98e89-7006-440f-d3e7-996c20aa09bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 12ms/step\n",
            "Porcentaje medio de diferencia del GT: 27.51 % - Desviación típica: 27.51\n",
            "Error medio: 19.08€\n"
          ]
        }
      ],
      "source": [
        "y_pred = modelo_hybrido_final.predict([X_test, X_test_resized])\n",
        "y_pred_denorm_hybrid =  y_pred[:, 0] *  y_reg.max()\n",
        "\n",
        "diferencia = y_pred_denorm_hybrid.flatten()- y_test_denorm\n",
        "porcentaje_diferencia = (diferencia / y_test_denorm) * 100\n",
        "abs_porcentaje_diferencia = np.abs(porcentaje_diferencia)\n",
        "\n",
        "error_denorm = np.abs(y_pred_denorm_hybrid - y_test_denorm)\n",
        "mean = np.mean(abs_porcentaje_diferencia)\n",
        "std = np.std(abs_porcentaje_diferencia)\n",
        "\n",
        "print('Porcentaje medio de diferencia del GT: {0:.2f} % - Desviación típica: {0:.2f}'.format(mean ,std))\n",
        "print('Error medio: {0:.2f}€'.format(error_denorm.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfAUc01hlQU9"
      },
      "source": [
        "Obtenemos un resultado peor que el modelo numérico, pero mejor que los modelos 2D.\n",
        "Seguramente podríamos optimizar los parámetros del modelo de imágenes, y posteriormente del híbrido obteniendo resultados mucho más óptimos.\n",
        "\n",
        " Vemos que con solo 1500 datos, las variables numéricas son más precisas, pues influyen notablemente sobre el precio de los apartamentos variables como la ubicación del mismo, el número de baños y habitaciones etc.\n",
        "\n",
        "Personalmente, viendo los diferentes modelos y resultados, creo que la capacidad que tienen de precisión es muy alta, visto el poco número de datos usados para su entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAfHy8uarMfk"
      },
      "source": [
        "**Gráfica de dispersión entre el GT y las predicciones del modelo híbrido y el numérico**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "27XtjRNQb5Zl",
        "outputId": "0abd57d6-2e91-4a56-f71d-f55acf937b8e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Gráfica de dispersión entre y_test y el modelo híbrido y numérico\n",
        "\n",
        "plt.scatter(y_pred_numeric_denorm, y_test_denorm, color='green', marker = 'o', label='y_predict_numeric')\n",
        "plt.scatter(y_pred_denorm_hybrid, y_test_denorm, color='blue', marker = 'h', label='y_pred_hybrid')\n",
        "\n",
        "\n",
        "plt.xlabel('y_predict')\n",
        "plt.ylabel('y_test')\n",
        "plt.title('Gráfico de dispersion')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97xJDi4Entdt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOV2GgsXrZE7"
      },
      "source": [
        "**Gráfica de dispersión entre el GT y las predicciones del modelo híbrido y el de imágenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EIINdEwh9kKl",
        "outputId": "49c1ebe5-eaf3-4566-c2da-e000a4d83bd2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(y_pred_img_denorm, y_test_denorm, color='red', marker = 'o', label='y_predict_img')\n",
        "plt.scatter(y_pred_denorm_hybrid, y_test_denorm, color='blue', marker = 'h', label='y_pred_hybrid')\n",
        "plt.xlabel('y_predict')\n",
        "plt.ylabel('y_test')\n",
        "plt.title('Gráfico de dispersion')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEbvBLMJoBM4"
      },
      "source": [
        "En las gráficas de dispersión podemos ver como el peso del modelo numérico hace que la precisión en la predicción sea mejor.\n",
        "En conclusión, entrenando con más datos el modelo de imágenes y mejorando los hiperparámetros vemos como podríamos hacer un modelo híbrido excelente con un error más bajo y mejor capacidad de generalización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm7uJr3wSROh",
        "outputId": "c6de70e3-bd7b-434a-eff7-220ecfd45393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 48, 48, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 48, 48, 64)   1792        ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 48, 48, 64)   36928       ['block1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 24, 24, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 24, 24, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 24, 24, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 12, 12, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 12, 12, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 12, 12, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 12, 12, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 6, 6, 256)    0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 6, 6, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 6, 6, 512)    2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 6, 6, 512)    2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_50 (Dense)               (None, 128)          3328        ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 3, 3, 512)    0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 128)         512         ['dense_50[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 3, 3, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)           (None, 128)          0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 3, 3, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_51 (Dense)               (None, 64)           8256        ['dropout_40[0][0]']             \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 3, 3, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 64)          256         ['dense_51[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 1, 1, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_41 (Dropout)           (None, 64)           0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (None, 512)          0           ['block5_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense_52 (Dense)               (None, 32)           2080        ['dropout_41[0][0]']             \n",
            "                                                                                                  \n",
            " dense_94 (Dense)               (None, 64)           32832       ['flatten_12[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 32)          128         ['dense_52[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 64)          256         ['dense_94[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_42 (Dropout)           (None, 32)           0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_104 (Dropout)          (None, 64)           0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " dense_53 (Dense)               (None, 16)           528         ['dropout_42[0][0]']             \n",
            "                                                                                                  \n",
            " dense_95 (Dense)               (None, 32)           2080        ['dropout_104[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 16)          64          ['dense_53[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 32)          128         ['dense_95[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_43 (Dropout)           (None, 16)           0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_105 (Dropout)          (None, 32)           0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " dense_54 (Dense)               (None, 1)            17          ['dropout_43[0][0]']             \n",
            "                                                                                                  \n",
            " dense_96 (Dense)               (None, 1)            33          ['dropout_105[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 2)            0           ['dense_54[0][0]',               \n",
            "                                                                  'dense_96[0][0]']               \n",
            "                                                                                                  \n",
            " dense_97 (Dense)               (None, 4)            12          ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_98 (Dense)               (None, 1)            5           ['dense_97[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,765,203\n",
            "Trainable params: 49,843\n",
            "Non-trainable params: 14,715,360\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Observamos la estructura de nuestro modelo híbrido y la cantidad de parámetros entrenables.\n",
        "modelo_hybrido_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFN44kXdSIkh"
      },
      "outputs": [],
      "source": [
        "## Comentarios del profesor ##\n",
        "Quizá se podía haber mejorado la parte de imágenes si no pones tantas densas en el top model. De todas formas,\n",
        "la práctica está genial, enhorabuena por el trabajo realizado.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}